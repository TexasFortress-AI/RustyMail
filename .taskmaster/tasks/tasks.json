{
  "master": {
    "tasks": [
      {
        "id": "1",
        "title": "Create database migration for AI model configurations",
        "description": "Add ai_model_configurations table to store tool-calling and drafting model settings",
        "details": "Create migrations/004_create_ai_model_config.sql with table schema for role, provider, model_name, base_url, api_key, additional_config. Include default entries for qwen2.5:7b (tool-calling) and llama3.3:70b (drafting)",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "complexity": 4,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Break down the systematic removal of imap-types dependency: 1) Remove from Cargo.toml, 2) Find and eliminate all imap-types imports across 80+ Rust files, 3) Replace imap-types types with async-imap equivalents in client.rs and session.rs, 4) Update type conversions and error handling, 5) Verify compilation succeeds"
      },
      {
        "id": "2",
        "title": "Create model configuration service module",
        "description": "Implement model_config.rs for managing AI model configurations in database",
        "details": "Create src/dashboard/services/ai/model_config.rs with ModelConfiguration struct, get_model_config(), set_model_config(), and database CRUD operations. Support both 'tool_calling' and 'drafting' roles.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "1"
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 3,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Address specific compilation errors: 1) Fix missing lifetime specifier in api/sse.rs Context type around line 80-90, 2) Add missing validate_api_key function in api/rest.rs (referenced but not implemented), 3) Add missing Mutex import in imap/session.rs, 4) Run cargo check to verify all fixes"
      },
      {
        "id": "3",
        "title": "Create high-level tools definitions module",
        "description": "Implement high_level_tools.rs with tool definitions and routing",
        "details": "Create src/dashboard/api/high_level_tools.rs with get_mcp_high_level_tools_jsonrpc_format() returning 10-12 tool definitions: process_email_instructions, draft_reply, draft_email, list_accounts, list_folders_hierarchical, list_cached_emails, get_email_by_uid, search_cached_emails, get_folder_stats, get_model_configurations, set_tool_calling_model, set_drafting_model. Include execute_high_level_tool() router function.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "2"
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 6,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Refactor IMAP client architecture: 1) Update client.rs to use only async-imap types, 2) Remove dual-library type conversion functions, 3) Standardize AsyncImapSessionWrapper pattern in session.rs, 4) Update connection handling in client.rs lines 90-155, 5) Map async-imap errors to domain errors, 6) Update all IMAP operations to use async-imap exclusively, 7) Test connection lifecycle and operations"
      },
      {
        "id": "4",
        "title": "Implement model configuration MCP tools",
        "description": "Create handlers for get_model_configurations, set_tool_calling_model, set_drafting_model",
        "details": "Implement the three configuration tools that read/write to ai_model_configurations table. Validate model configurations and test connectivity before saving.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "2",
          "3"
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 7,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Design atomic IMAP command sequences: 1) Research IMAP atomic operation patterns, 2) Implement SELECT-COPY-STORE-EXPUNGE sequence for moves, 3) Add transaction-like error handling with rollback, 4) Track folder selection state in AsyncImapSessionWrapper, 5) Implement operation state management, 6) Add concurrent access protection, 7) Create atomic operation tests, 8) Verify ACID properties in error scenarios"
      },
      {
        "id": "5",
        "title": "Wire up browsing tools to high-level variant",
        "description": "Connect existing read-only browsing tools to high-level tool router",
        "details": "Reuse existing handlers for list_accounts, list_folders_hierarchical, list_cached_emails, get_email_by_uid, search_cached_emails, get_folder_stats. Add routing logic in execute_high_level_tool() to call these handlers.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "3"
        ],
        "priority": "medium",
        "subtasks": [],
        "complexity": 5,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Implement comprehensive error system: 1) Define error code ranges (-32700 to -32099) following JSON-RPC 2.0 spec, 2) Create error mapping from async-imap errors to JSON-RPC codes, 3) Implement consistent error response format across REST/MCP interfaces, 4) Add structured error details with operation context, 5) Update existing error handling in rest.rs and mcp modules, 6) Test error propagation through all interface layers"
      },
      {
        "id": "6",
        "title": "Create email drafter service",
        "description": "Implement email_drafter.rs for generating email drafts using configured model",
        "details": "Create src/dashboard/services/ai/email_drafter.rs with EmailDrafter struct, draft_reply() and draft_email() methods. Use model_config to get drafting model settings, call Ollama API to generate text. Include context from original email for replies.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "2"
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 8,
        "recommendedSubtasks": 10,
        "expansionPrompt": "Implement comprehensive IMAP operations: 1) Complete folder listing with hierarchical structure, 2) Implement server-side search using async-imap search methods, 3) Add message fetching with MIME part handling, 4) Complete atomic move operations with guarantees, 5) Implement delete operations with proper flag handling, 6) Add EXPUNGE operations, 7) Create integration tests for each operation, 8) Test with multiple IMAP server types (Gmail, Outlook), 9) Optimize for performance requirements (<500ms folder list, <200ms email fetch), 10) Add comprehensive error handling for each operation"
      },
      {
        "id": "7",
        "title": "Implement draft_reply and draft_email tools",
        "description": "Create MCP tool handlers for email drafting",
        "details": "Implement handlers that fetch email content, construct prompts, call EmailDrafter service, and return formatted draft text. Handle errors gracefully.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "6"
        ],
        "priority": "medium",
        "subtasks": [],
        "complexity": 7,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Build robust connection management: 1) Design connection pool using Arc<TokioMutex<>> pattern, 2) Implement session lifecycle tracking and cleanup, 3) Add connection health checking mechanisms, 4) Implement automatic reconnection logic, 5) Add session timeout handling, 6) Support concurrent session handling up to 100+ connections, 7) Create connection leak prevention, 8) Add performance monitoring and load testing for concurrent connections"
      },
      {
        "id": "8",
        "title": "Create MCP to Ollama tool converter",
        "description": "Implement tool_converter.rs for converting MCP tool schemas to Ollama format",
        "details": "Create src/dashboard/services/ai/tool_converter.rs with mcp_to_ollama_tools() function. Convert MCP JSON Schema inputSchema to Ollama's tool format. Handle type conversions and required fields.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "complexity": 6,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Replace custom MCP implementation with official SDK: 1) Remove custom MCP transport implementations in legacy.rs, 2) Integrate rmcp dependency from rust-sdk (already in Cargo.toml), 3) Study official SDK patterns and API, 4) Update service definitions using SDK tooling, 5) Migrate stdio transport to use SDK patterns, 6) Migrate SSE transport to use SDK patterns, 7) Ensure backward compatibility with existing MCP clients and test integration"
      },
      {
        "id": "9",
        "title": "Create agent executor with Ollama tool calling",
        "description": "Implement agent_executor.rs for running sub-agent with iterative tool calling",
        "details": "Create src/dashboard/services/ai/agent_executor.rs with AgentExecutor struct and execute_with_tools() method. Implement iterative loop: send instruction with tools to Ollama, handle tool_calls response, execute requested tools using existing handlers, send results back, repeat until completion. Aggregate results and return formatted response with actions_taken list.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "8"
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 6,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Finish REST API development: 1) Complete remaining REST endpoints for folder operations, 2) Implement email search, fetch, move, and delete endpoints, 3) Add API key authentication middleware (validate_api_key function missing), 4) Add request validation and rate limiting, 5) Implement proper HTTP status codes following REST conventions, 6) Create comprehensive OpenAPI/Swagger documentation, 7) Add end-to-end tests for all endpoints, 8) Performance test under load conditions"
      },
      {
        "id": "10",
        "title": "Implement process_email_instructions tool",
        "description": "Create MCP tool handler for complex email workflow execution",
        "details": "Implement handler that takes natural language instruction, gets tool-calling model config, converts all low-level MCP tools to Ollama format, calls AgentExecutor, formats result. Include logic to detect when user feedback is needed and return questions in JSON format.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "9"
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 5,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Complete dashboard backend functionality: 1) Complete metrics collection service using sysinfo crate, 2) Implement client management service for tracking active connections, 3) Add configuration service for runtime settings, 4) Create SSE event broadcasting system for real-time updates, 5) Implement system health monitoring, 6) Test metrics accuracy and SSE broadcasting with multiple clients"
      },
      {
        "id": "11",
        "title": "Add high-level variant support to MCP HTTP backend",
        "description": "Modify mcp_http.rs to support ?variant=high-level query parameter",
        "details": "Update tools/list handler to check for variant parameter and return high-level tools when variant=high-level. Update tools/call handler to route to execute_high_level_tool() for high-level variant. Store variant in session data.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "3",
          "10"
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 4,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Complete frontend integration: 1) Build React frontend using Vite in frontend/rustymail-app-main/ directory, 2) Configure build output for production, 3) Integrate static files with Actix backend using actix-files middleware, 4) Configure SSE EventSource connections for real-time updates, 5) Test frontend build process and backend integration across different browsers"
      },
      {
        "id": "12",
        "title": "Create high-level MCP stdio binary",
        "description": "Create rustymail-mcp-stdio-high-level binary",
        "details": "Create src/bin/mcp_stdio_high_level.rs that connects to backend with ?variant=high-level parameter. Can be copy of mcp_stdio.rs with modified default URL, or same binary with --mode flag. Add binary to Cargo.toml.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "11"
        ],
        "priority": "medium",
        "subtasks": [],
        "complexity": 5,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Complete SSE implementation: 1) Finish SSE implementation in dashboard/api/sse.rs, 2) Add event broadcasting for metrics updates and client connections, 3) Implement proper SSE connection lifecycle management, 4) Add event filtering and subscription management, 5) Ensure browser reconnection handling, 6) Test SSE stability under network conditions and with multiple concurrent clients"
      },
      {
        "id": "13",
        "title": "Test high-level MCP variant with Claude Desktop",
        "description": "Integration testing of complete high-level tool flow",
        "status": "deferred",
        "dependencies": [
          "12"
        ],
        "priority": "medium",
        "details": "Configure Claude Desktop to use rustymail-mcp-stdio-high-level binary. Migration 004 (ai_model_configurations table) has been applied with default models: qwen2.5:7b for tool_calling and llama3.3:70b for drafting. Test workflow: 1) Use set_tool_calling_model and set_drafting_model tools to configure actual models instead of defaults, 2) Test browsing tools (list_accounts, list_folders_hierarchical, get_email_by_uid), 3) Test configuration tools (get_model_configurations), 4) Test drafting tools (draft_reply, draft_email), 5) Test process_email_instructions with simple workflows. Verify tool count is ~12 instead of 26+. Process_email_instructions tool should now work properly after database migration fix.",
        "testStrategy": "Configure Claude Desktop with rustymail-mcp-stdio-high-level, verify 12 tools available instead of 26+. First configure models using configuration tools, then test each tool category: browsing (list accounts/folders/emails), drafting (generate replies/emails), and workflow execution (process_email_instructions). Confirm all tools work without database errors.",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure Claude Desktop with high-level MCP binary",
            "description": "Set up Claude Desktop to use rustymail-mcp-stdio-high-level binary and verify connection",
            "dependencies": [],
            "details": "Update Claude Desktop configuration to point to target/release/rustymail-mcp-stdio-high-level binary. Ensure server is running on configured port. Verify Claude Desktop shows ~12 tools available instead of 26+.",
            "status": "pending",
            "testStrategy": "Check Claude Desktop shows correct tool count and can connect to MCP server",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Configure AI models using configuration tools",
            "description": "Use set_tool_calling_model and set_drafting_model to replace default configurations",
            "dependencies": [
              1
            ],
            "details": "Migration 004 created default configurations (qwen2.5:7b for tool_calling, llama3.3:70b for drafting). Use the MCP configuration tools to set actual models the user wants to use. Test get_model_configurations to verify settings are saved correctly.",
            "status": "pending",
            "testStrategy": "Verify model configurations are saved and retrieved correctly from ai_model_configurations table",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Test browsing tools functionality",
            "description": "Test list_accounts, list_folders_hierarchical, list_cached_emails, and get_email_by_uid tools",
            "dependencies": [
              2
            ],
            "details": "Verify all browsing tools work correctly with high-level MCP variant. Test that these tools provide the same functionality as the low-level variant but through the simplified interface.",
            "status": "pending",
            "testStrategy": "Execute each browsing tool and verify expected data structure and content returned",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Test drafting tools functionality",
            "description": "Test draft_reply and draft_email tools using configured drafting model",
            "dependencies": [
              2
            ],
            "details": "Verify AI-powered drafting tools work with the configured drafting model from step 2. Test that drafts are generated with appropriate quality and relevance to input context.",
            "status": "pending",
            "testStrategy": "Generate sample drafts and verify they are contextually appropriate and well-formatted",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Test process_email_instructions workflow execution",
            "description": "Test the main workflow tool with simple email management instructions",
            "dependencies": [
              2,
              3
            ],
            "details": "Test process_email_instructions with simple workflows like 'list unread emails in INBOX' or 'show folder statistics'. Should now work correctly after ai_model_configurations table migration fix. Verify the tool uses other available tools to complete the workflow.",
            "status": "pending",
            "testStrategy": "Execute simple instructions and verify workflow completion without database errors",
            "parentId": "undefined"
          }
        ],
        "complexity": 3,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Initialize AI integration framework: 1) Add RIG dependency to Cargo.toml, 2) Configure OpenAI and OpenRouter providers in dashboard/services/ai/ modules, 3) Set up LLM model selection and API key management, 4) Create provider abstraction layer and test connectivity with configured providers",
        "updatedAt": "2026-01-23T11:46:31.369Z"
      },
      {
        "id": "14",
        "title": "Create WebUI settings page for AI model configuration",
        "description": "Add /settings/ai-models page to dashboard",
        "details": "Create UI for configuring tool-calling and drafting models. Include provider dropdown, model name input with autocomplete, base URL input, API key input, test connection button, save button. Display current configurations. Wire up to backend API endpoints.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "4"
        ],
        "priority": "low",
        "subtasks": [],
        "complexity": 6,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Build NLP to MCP pipeline: 1) Design natural language processing pipeline using RIG, 2) Create prompt templates for common email operations ('show unread emails', 'emails from sender', 'move emails to folder'), 3) Implement intent recognition and mapping to MCP method calls, 4) Add conversation context tracking for follow-up queries, 5) Create query parsing and validation, 6) Test natural language understanding with various query formats, 7) Verify correct MCP operation mapping and context maintenance",
        "updatedAt": "2026-01-24T14:18:15.055Z"
      },
      {
        "id": "15",
        "title": "Document high-level MCP variant in README",
        "description": "Add documentation for new high-level variant",
        "details": "Update README with: explanation of two variants, configuration examples for both, tool list comparison, when to use each variant, model configuration instructions.",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          "13"
        ],
        "priority": "low",
        "subtasks": [],
        "complexity": 4,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Complete chatbot interface: 1) Extend existing ChatbotPanel.tsx component with full conversation interface, 2) Add message history and conversation state management, 3) Implement typing indicators and response streaming, 4) Connect to backend AI service via SSE or WebSocket, 5) Add conversation export and history features, and test UI responsiveness"
      },
      {
        "id": "16",
        "title": "Fix compose dialog appearing on hard refresh",
        "description": "Prevent the SendMailDialog from automatically opening when the web UI is hard-refreshed (F5 or Ctrl+F5)",
        "status": "done",
        "dependencies": [
          "4"
        ],
        "priority": "medium",
        "details": "SPECIFIC BUG IDENTIFIED: The dialog is appearing on page load with `data-state=\"open\"` in the DOM. The `composeDialogOpen` state is correctly initialized as `false` in EmailList.tsx:71, but something is triggering it to become `true` during component mount. Debug logging has been added at EmailList.tsx:74-76 to track state changes. The visual confusion is compounded by placeholder text in input fields (recipient@example.com, cc@example.com, etc.) that appears gray but looks like actual values. ROOT CAUSE INVESTIGATION NEEDED: 1) Trace what's calling setComposeDialogOpen(true) during initialization - check browser dev tools console for debug logs, 2) Verify if any useEffect hooks or props are triggering dialog open on mount, 3) Check if Radix UI Dialog component has any default behavior causing auto-open, 4) Investigate if URL parameters, localStorage, or sessionStorage are influencing initial state, 5) Ensure the Dialog component's `open` prop is properly controlled by the `composeDialogOpen` state variable",
        "testStrategy": "Test by: 1) Adding more granular debug logging to track exactly when and why setComposeDialogOpen(true) is called, 2) Performing a hard refresh (F5 or Ctrl+F5) and checking browser console for debug output, 3) Verifying dialog does not appear on hard refresh after fix, 4) Testing soft refresh and normal navigation to ensure functionality still works, 5) Testing actual compose dialog triggers (Compose button, Reply, Forward) to ensure they still work correctly, 6) Cross-browser testing in Chrome, Firefox, Safari to ensure consistent behavior, 7) Verify placeholder text styling doesn't create visual confusion about empty vs filled fields",
        "subtasks": [
          {
            "id": 1,
            "title": "Add comprehensive debug logging to track dialog state changes",
            "description": "Implement detailed logging to identify what triggers setComposeDialogOpen(true) during component initialization",
            "dependencies": [],
            "details": "Add console.log statements at all locations where setComposeDialogOpen is called, including stack traces. Log component mount/unmount cycles and prop changes. Add logging in useEffect hooks that might influence dialog state. Check EmailList.tsx:162 (handleComposeRequest) and EmailList.tsx:590 (Compose button click) for unexpected calls.",
            "status": "done",
            "testStrategy": "Open browser dev tools console, perform hard refresh, and verify detailed logs show exact sequence of state changes and what triggers dialog opening",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Investigate Radix UI Dialog component behavior on mount",
            "description": "Check if Radix UI Dialog has any default open behavior or hydration issues",
            "dependencies": [
              1
            ],
            "details": "Examine the Dialog component in components/ui/dialog.tsx and its usage in SendMailDialog.tsx:211. Verify the `open` prop is properly bound to composeDialogOpen state. Check if DialogPrimitive.Root has any default state that could cause auto-opening. Review Radix UI documentation for known hydration or SSR issues that might cause initial open state.",
            "status": "done",
            "testStrategy": "Test with different initial values for the open prop and verify the Dialog component respects the controlled state properly",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add hard refresh detection to prevent unwanted dialog opening",
            "description": "Implement logic to detect hard refresh and ensure dialog remains closed",
            "dependencies": [
              1,
              2
            ],
            "details": "Add a useEffect hook in EmailList component that detects if the page was loaded fresh (hard refresh) vs navigated to. Use performance.navigation.type or window.performance.getEntriesByType('navigation') to detect refresh. Set a flag to prevent dialog from opening on fresh page loads. Ensure this doesn't interfere with legitimate compose dialog triggers.",
            "status": "done",
            "testStrategy": "Test hard refresh (F5/Ctrl+F5) vs normal navigation and verify dialog only opens when explicitly triggered by user actions",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Fix placeholder text styling to reduce visual confusion",
            "description": "Update input placeholder styling to be more clearly distinguishable from actual values",
            "dependencies": [],
            "details": "Modify placeholder text in SendMailDialog.tsx:235, 250, 261 to be more obviously placeholders. Consider using lighter gray color, italic styling, or different placeholder text that's clearly not a real email address. Update CSS classes if needed to make placeholders more visually distinct from user input.",
            "status": "done",
            "testStrategy": "Verify placeholder text is clearly distinguishable from actual input values and doesn't contribute to the perception that fields are pre-filled",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 12,
        "expansionPrompt": "Implement full testing strategy: 1) Create unit tests for all IMAP operations using mock servers, 2) Set up mock IMAP server infrastructure, 3) Implement integration tests using real IMAP adapters for Gmail, 4) Add integration tests for Outlook servers, 5) Add integration tests for standard IMAP servers, 6) Create end-to-end tests covering complete user workflows through REST interface, 7) Create end-to-end tests for MCP interface workflows, 8) Set up performance benchmarks for concurrent connection handling, 9) Achieve >90% code coverage across all modules, 10) Test all error scenarios and edge cases, 11) Implement performance tests meeting requirements (<500ms folder list, <200ms email fetch, 100+ concurrent connections), 12) Set up continuous testing infrastructure"
      },
      {
        "id": "17",
        "title": "Fix email body rendering issues - HTML/image artifacts showing as raw text instead of being properly rendered",
        "description": "Fix the frontend EmailBody component to properly render HTML content and display images/links correctly instead of showing raw text",
        "details": "The current implementation in EmailBody.tsx:303 only displays the plain text body (email.body_text) using whitespace-pre-wrap styling, which causes HTML content and embedded images to appear as raw text/artifacts. The fix involves: 1) Check if email.html_body is available from the backend (already stored in cache.rs and available via the REST API), 2) Modify the EmailBody component to conditionally render HTML content using dangerouslySetInnerHTML when HTML is available, with proper sanitization, 3) Add CSS styles to handle image display, link styling, and proper HTML formatting, 4) Implement a toggle between HTML and plain text views for user preference, 5) Add security measures to sanitize HTML content before rendering to prevent XSS attacks, 6) Update the email fetching logic to include html_body field in the API response. The backend already stores both text_body and html_body in the database (migrations/001_create_schema.sql:101-102) and the IMAP parsing extracts both via mail_parser (imap/types.rs:737-738).",
        "testStrategy": "Test by: 1) Sending HTML emails with embedded images and links to test accounts, 2) Verify HTML content renders properly with images displayed and links clickable, 3) Test the plain text fallback when no HTML is available, 4) Verify HTML/plain text toggle functionality works, 5) Test with malicious HTML content to ensure sanitization prevents XSS, 6) Test responsive display on different screen sizes, 7) Verify that emails without HTML content still display plain text correctly, 8) Test performance with large HTML emails containing multiple images",
        "status": "done",
        "dependencies": [
          "4"
        ],
        "priority": "medium",
        "subtasks": [],
        "complexity": 5,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Set up automated development pipeline: 1) Configure GitHub Actions or similar CI/CD system, 2) Set up automated testing on multiple Rust versions and platforms, 3) Add security scanning and dependency vulnerability checks, 4) Configure automated releases with proper semantic versioning, 5) Add Docker image building and container registry publishing, 6) Test CI/CD pipeline with pull requests and verify deployment automation"
      },
      {
        "id": "18",
        "title": "Add 'Show Images' button to email viewer for privacy protection",
        "description": "Implement a privacy-focused image loading control in the email viewer with an optional button similar to Thunderbird, where images are blocked by default to prevent tracking.",
        "details": "Based on the current EmailBody.tsx implementation that only displays plain text (line 303 uses whitespace-pre-wrap on email.body_text), add image privacy controls when displaying HTML emails: 1) Add a state variable `showImages` (default false) to control image display, 2) When rendering HTML content using email.html_body (which is already available from the backend as seen in cache.rs), implement a two-stage rendering approach: first render HTML with all img src attributes stripped/blocked, 3) Add a 'Show Images' button (using existing Button component and Eye/EyeOff icons from lucide-react) that appears when HTML content contains images, 4) When clicked, re-render the HTML with images enabled, 5) Use DOMParser to safely detect and modify img tags before dangerouslySetInnerHTML rendering, 6) Add user preference persistence via localStorage to remember the choice per sender/domain, 7) Style the button consistently with existing Reply/Forward buttons in the header area (lines 262-284), 8) Ensure the feature works with the existing HTML/text toggle functionality mentioned in Task 17",
        "testStrategy": "Test by: 1) Sending HTML emails with embedded images and tracking pixels to test accounts, 2) Verify images are blocked by default and 'Show Images' button appears, 3) Test button functionality enables images properly, 4) Test localStorage persistence remembers preference, 5) Verify no external requests are made when images are blocked (check network tab), 6) Test with various email clients (Gmail, Outlook, etc.) to ensure compatibility, 7) Test the feature works alongside Task 17's HTML rendering improvements, 8) Verify button styling matches existing UI components",
        "status": "done",
        "dependencies": [
          "17"
        ],
        "priority": "medium",
        "subtasks": [],
        "complexity": 3,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Complete deployment resources: 1) Create deployment guides for standalone binary, Docker, and Kubernetes, 2) Document all configuration options and environment variables, 3) Create deployment scripts and Docker Compose files, 4) Add monitoring, logging configuration examples, and security best practices documentation"
      },
      {
        "id": "19",
        "title": "Add tabs to MCP Email Tools widget in web UI - one tab for low-level MCP tools, another tab for high-level AI-powered MCP tools",
        "description": "Enhance the existing McpTools component to display two separate tabs: one showing all the existing low-level MCP tools and another showing the high-level AI-powered MCP tools",
        "details": "Modify the existing McpTools.tsx component (src/dashboard/components/McpTools.tsx) to use Radix UI Tabs component from components/ui/tabs.tsx. The component should: 1) Import and use Tabs, TabsList, TabsTrigger, and TabsContent from '../ui/tabs', 2) Create two tab triggers: 'Low-Level Tools' and 'AI Tools', 3) Move existing tool fetching and display logic into the 'Low-Level Tools' tab content, 4) Add a new API endpoint fetch to get high-level tools from the backend endpoint '/dashboard/mcp/high-level-tools' (which needs to be implemented to call get_mcp_high_level_tools_jsonrpc_format() from high_level_tools.rs), 5) Display the high-level tools in the 'AI Tools' tab with the same UI pattern as existing tools, 6) Maintain all existing functionality including parameter auto-filling, execution, and result display for both tool types, 7) Update the header to show total tools from both tabs, 8) Ensure proper state management so expanding/collapsing tools, parameters, and results work independently between tabs. The backend route handler should call execute_high_level_tool() for AI tool executions and existing execute_mcp_tool_inner() for low-level tools.",
        "testStrategy": "Test by: 1) Verifying both tabs are visible and clickable in the MCP Tools widget, 2) Confirming the 'Low-Level Tools' tab shows existing tools with unchanged functionality, 3) Verifying the 'AI Tools' tab displays the 12 high-level tools (process_email_instructions, draft_reply, draft_email, list_accounts, etc.), 4) Testing parameter auto-filling works in both tabs based on current email context, 5) Testing tool execution works correctly for both low-level and high-level tools with proper API routing, 6) Verifying results display properly in both tabs, 7) Testing tab switching preserves expanded tool states and parameter values, 8) Confirming the total tool count in header updates correctly when switching tabs",
        "status": "done",
        "dependencies": [
          "3",
          "5"
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": "20",
        "title": "Add MCP server enable/disable controls to Email Assistant chatbot widget",
        "description": "Implement checkboxes/dropdown controls in ChatbotPanel to enable/disable individual MCP servers (low-level and high-level) for the AI assistant to use during conversations.",
        "details": "Based on the current ChatbotPanel.tsx (lines 334-677) and McpTools.tsx components, add MCP server configuration controls to the chatbot: 1) Add a settings dropdown menu next to the debug toggle button in the ChatbotPanel header (around line 364), 2) Create a new state for tracking enabled/disabled MCP servers with localStorage persistence similar to debugMode (line 72-74), 3) Add a collapsible settings panel that shows two sections: 'Low-Level Tools' and 'High-Level AI Tools', 4) For low-level tools, fetch from existing '/dashboard/mcp/tools' endpoint (line 98 in McpTools.tsx), 5) For high-level tools, create new endpoint '/dashboard/mcp/high-level-tools' that calls get_mcp_high_level_tools_jsonrpc_format() from high_level_tools.rs:11, 6) Display each tool as a checkbox with the tool name and description, allowing users to individually enable/disable tools, 7) Pass the enabled tools list to the chatbot query (in the ChatbotQuery interface) so the backend can filter available tools during AI conversations, 8) Use consistent UI patterns from the existing codebase: Radix UI components (checkbox.tsx, collapsible.tsx), similar styling to the debug panel (lines 549-644), and localStorage persistence pattern.",
        "testStrategy": "Test by: 1) Verifying the settings dropdown appears in the chatbot header and is functional, 2) Confirming both low-level and high-level tools are fetched and displayed correctly with checkboxes, 3) Testing that individual tool enable/disable states persist across browser sessions via localStorage, 4) Verifying the enabled tools list is correctly passed to chatbot queries and affects AI responses, 5) Testing the UI responsiveness and proper styling consistency with existing components, 6) Ensuring the new high-level tools endpoint returns the expected tool definitions from the backend.",
        "status": "done",
        "dependencies": [
          "19"
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": "21",
        "title": "Disable thinking mode in Qwen3 model by setting enable_thinking=False in Ollama provider configuration",
        "description": "Modify Ollama provider to support additional_config parameters and update Qwen3 model configuration to disable thinking mode for faster response times.",
        "details": "Update the Ollama provider implementation to read and apply additional_config parameters from the ai_model_configurations table: 1) Modify OllamaChatRequest struct in src/dashboard/services/ai/provider/ollama.rs to include optional additional parameters field, 2) Update OllamaAdapter::generate_response() method to fetch model configuration using get_model_config() and parse additional_config JSON to extract provider-specific parameters, 3) Add logic to merge additional_config parameters into the Ollama API request payload, 4) Use set_model_config() to update the Qwen3 model configuration with additional_config JSON: {\"enable_thinking\": false}, 5) Test that the parameter is properly passed to Ollama API and that thinking blocks are no longer generated in responses. The additional_config field should be parsed as JSON and merged into the request body sent to Ollama's /v1/chat/completions endpoint.",
        "testStrategy": "Test by: 1) Verifying that the Ollama provider properly reads additional_config from database and parses JSON parameters, 2) Confirming that enable_thinking=false parameter is included in API requests to Ollama for Qwen3 model, 3) Testing that Qwen3 responses no longer contain <think> blocks and show improved response speed, 4) Verifying that other models without this configuration continue to work normally, 5) Testing configuration updates through MCP tools to ensure the additional_config field can be modified and persisted correctly.",
        "status": "done",
        "dependencies": [
          "2",
          "4"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-01-24T14:18:16.982Z"
      },
      {
        "id": "22",
        "title": "Fix permissive CORS configuration in main.rs",
        "description": "Replace the permissive CORS configuration that allows any origin, method, and header with a secure whitelist-based approach using environment variables to prevent CSRF attacks.",
        "details": "Update the CORS configuration in src/main.rs (lines 270-277) to implement a secure origin whitelist:\n\n1) Add a new environment variable ALLOWED_ORIGINS that accepts a comma-separated list of allowed origins (e.g., \"http://localhost:3000,https://dashboard.example.com\")\n\n2) Replace the current permissive configuration:\n   ```rust\n   Cors::default()\n       .allow_any_origin()\n       .allow_any_method()\n       .allow_any_header()\n   ```\n\n3) With a secure configuration:\n   ```rust\n   let allowed_origins = std::env::var(\"ALLOWED_ORIGINS\")\n       .unwrap_or_else(|_| \"http://localhost:3000\".to_string())\n       .split(',')\n       .map(|s| s.trim().to_string())\n       .collect::<Vec<String>>();\n   \n   let cors = Cors::default()\n       .allowed_origins(\n           allowed_origins\n               .iter()\n               .map(|origin| origin.parse::<HeaderValue>().unwrap())\n               .collect::<Vec<_>>()\n               .as_slice()\n       )\n       .allowed_methods(vec![\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"])\n       .allowed_headers(vec![\n           header::CONTENT_TYPE,\n           header::AUTHORIZATION,\n           header::ACCEPT,\n       ])\n       .supports_credentials()\n       .max_age(3600);\n   ```\n\n4) Update the .env.example file to include the new ALLOWED_ORIGINS variable with sensible defaults\n\n5) Add validation to ensure at least one origin is configured and that origins are valid URLs\n\n6) Consider adding a warning log if ALLOWED_ORIGINS is not set, defaulting to localhost only for development safety\n\n7) Ensure the CORS middleware properly handles preflight OPTIONS requests\n\n8) Update any deployment documentation to specify the ALLOWED_ORIGINS configuration requirement",
        "testStrategy": "Verify the CORS fix by:\n\n1) Start the server without ALLOWED_ORIGINS set and confirm it defaults to localhost:3000 only\n2) Set ALLOWED_ORIGINS=\"http://localhost:3000,http://localhost:5173\" and restart the server\n3) Test that requests from allowed origins work correctly:\n   - Make API calls from http://localhost:3000 and verify they succeed\n   - Make API calls from http://localhost:5173 and verify they succeed\n4) Test that requests from non-allowed origins are blocked:\n   - Use curl or a browser from http://localhost:8080 and verify CORS error\n   - Try making requests from https://evil.com and confirm they're rejected\n5) Verify preflight OPTIONS requests are handled correctly for allowed origins\n6) Test with credentials (cookies/auth headers) to ensure supports_credentials() works\n7) Check server logs for appropriate warnings when ALLOWED_ORIGINS is not configured\n8) Verify that malformed origins in ALLOWED_ORIGINS cause server startup to fail with clear error message",
        "status": "done",
        "dependencies": [
          "32"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-23T10:44:12.311Z"
      },
      {
        "id": "23",
        "title": "Fix origin validation bypass in MCP HTTP backend",
        "description": "Fix critical security vulnerability in src/api/mcp_http.rs (lines 171-189) where origin validation accepts any domain containing 'localhost' and allows requests with no Origin header, enabling CSRF attacks.",
        "details": "Update the origin validation logic in src/api/mcp_http.rs to implement secure origin checking:\n\n1) **Fix substring matching vulnerability** (line ~175-180):\n   - Replace the current logic that accepts any origin containing 'localhost' (e.g., evil.localhost.com)\n   - Implement exact string matching for allowed origins\n   - Use a whitelist approach with full origin strings including protocol and port\n\n2) **Require Origin header on all requests**:\n   - Remove the logic that allows requests with missing Origin headers\n   - Return 403 Forbidden for requests without Origin header\n   - Add proper error message: \"Origin header required\"\n\n3) **Implement secure origin validation**:\n   ```rust\n   // Add at top of file\n   use std::env;\n   \n   // In the origin validation section\n   let allowed_origins = env::var(\"ALLOWED_MCP_ORIGINS\")\n       .unwrap_or_else(|_| \"http://localhost:3000\".to_string())\n       .split(',')\n       .map(|s| s.trim().to_string())\n       .collect::<Vec<String>>();\n   \n   // Validate origin\n   if let Some(origin) = req.headers().get(\"Origin\") {\n       let origin_str = origin.to_str().unwrap_or(\"\");\n       if !allowed_origins.contains(&origin_str.to_string()) {\n           return Ok(Response::builder()\n               .status(StatusCode::FORBIDDEN)\n               .body(Body::from(\"Origin not allowed\"))\n               .unwrap());\n       }\n   } else {\n       return Ok(Response::builder()\n           .status(StatusCode::FORBIDDEN)\n           .body(Body::from(\"Origin header required\"))\n           .unwrap());\n   }\n   ```\n\n4) **Add environment variable configuration**:\n   - Support ALLOWED_MCP_ORIGINS environment variable\n   - Accept comma-separated list of full origins (e.g., \"http://localhost:3000,http://localhost:5173,https://app.example.com\")\n   - Default to \"http://localhost:3000\" if not set\n\n5) **Update CORS headers in response**:\n   - Set Access-Control-Allow-Origin to the specific requesting origin (not \"*\")\n   - Only set it if the origin is in the allowed list\n\n6) **Consider preflight requests**:\n   - Ensure OPTIONS requests also validate origins\n   - Return appropriate CORS headers only for allowed origins",
        "testStrategy": "Verify the security fix with comprehensive testing:\n\n1) **Test substring matching fix**:\n   - Send request with Origin: http://evil.localhost.com - should be rejected (403)\n   - Send request with Origin: http://localhost.attacker.com - should be rejected (403)\n   - Send request with Origin: http://localhost:3000 - should be allowed (200)\n\n2) **Test missing Origin header enforcement**:\n   - Use curl without Origin header: `curl http://localhost:8080/mcp/tools/list` - should be rejected (403)\n   - Use curl with valid Origin: `curl -H \"Origin: http://localhost:3000\" http://localhost:8080/mcp/tools/list` - should work\n\n3) **Test environment variable configuration**:\n   - Set ALLOWED_MCP_ORIGINS=\"http://localhost:3000,http://localhost:5173\"\n   - Verify requests from localhost:3000 work\n   - Verify requests from localhost:5173 work\n   - Verify requests from localhost:8080 are rejected\n\n4) **Test exact matching with ports**:\n   - Origin: http://localhost:3000 with ALLOWED_MCP_ORIGINS=\"http://localhost:3001\" - should fail\n   - Origin: http://localhost:3001 with ALLOWED_MCP_ORIGINS=\"http://localhost:3001\" - should work\n\n5) **Test CORS response headers**:\n   - Verify Access-Control-Allow-Origin is set to the specific origin (not \"*\")\n   - Verify it's only set when origin is allowed\n\n6) **Test preflight OPTIONS requests**:\n   - Send OPTIONS request with valid origin - should return proper CORS headers\n   - Send OPTIONS request with invalid origin - should be rejected",
        "status": "done",
        "dependencies": [
          "22"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-23T11:04:42.187Z"
      },
      {
        "id": "24",
        "title": "Remove hardcoded test credentials and require configured API keys",
        "description": "Remove all hardcoded test API keys and credentials from the codebase, require explicit configuration of all API keys, add key expiration support, and update documentation for secure key generation.",
        "details": "Fix critical security vulnerabilities in API key management by removing all hardcoded credentials and test keys:\n\n1) **Remove hardcoded test key initialization in src/api/auth.rs**:\n   - Delete or comment out the ApiKeyStore::init_with_defaults() method that seeds a test key with Admin scope at startup\n   - Ensure no API keys are automatically created when the application starts\n   - Modify the initialization logic to require explicit key configuration through environment variables or secure configuration files\n\n2) **Remove test credentials from .env.example**:\n   - Remove the line `RUSTYMAIL_API_KEY=test-rustymail-key-2024` from .env.example\n   - Replace with a placeholder like `RUSTYMAIL_API_KEY=your-secure-api-key-here`\n   - Add comments explaining that users must generate their own secure API keys\n\n3) **Implement API key expiration support**:\n   - Add an `expires_at` field to the API key storage structure (likely in ApiKeyStore)\n   - Modify the key validation logic to check expiration timestamps\n   - Return 401 Unauthorized for expired keys with appropriate error messages\n   - Consider adding a configurable default expiration period (e.g., 90 days)\n\n4) **Remove any hardcoded IMAP credentials**:\n   - Search the codebase for any hardcoded IMAP usernames, passwords, or server configurations\n   - Ensure all IMAP credentials must be provided through secure configuration\n   - Update any test configurations to use environment variables instead\n\n5) **Add secure key generation documentation**:\n   - Create a new section in the README or a separate SECURITY.md file\n   - Document how to generate cryptographically secure API keys (e.g., using openssl rand -hex 32)\n   - Explain the importance of key rotation and expiration\n   - Provide examples of secure key storage practices\n   - Document the required scopes and permissions for different API operations\n\n6) **Update application startup logic**:\n   - Add validation to ensure required API keys are configured before the application starts\n   - Provide clear error messages if required keys are missing\n   - Consider implementing a setup wizard or initialization script for first-time configuration",
        "testStrategy": "Verify the security improvements with comprehensive testing:\n\n1) **Test removal of hardcoded keys**:\n   - Start the application with a clean environment (no API keys configured)\n   - Verify the application refuses to start or enters a safe mode without any pre-configured keys\n   - Confirm no test keys are accessible through the API\n\n2) **Test API key expiration**:\n   - Create an API key with a short expiration time (e.g., 1 minute in the future)\n   - Make successful API calls with the key\n   - Wait for the key to expire\n   - Verify subsequent API calls return 401 Unauthorized with an \"expired key\" error message\n\n3) **Test IMAP credential requirements**:\n   - Attempt to use IMAP functionality without configuring credentials\n   - Verify appropriate error messages are returned\n   - Configure valid IMAP credentials through environment variables\n   - Confirm IMAP functionality works correctly with configured credentials\n\n4) **Test .env.example changes**:\n   - Copy .env.example to .env\n   - Verify the application doesn't start with placeholder values\n   - Replace placeholders with valid keys and confirm successful startup\n\n5) **Security audit**:\n   - Search the entire codebase for strings like \"test\", \"default\", \"admin\" in authentication contexts\n   - Verify no hardcoded credentials remain in any source files\n   - Check that all authentication-related configuration comes from environment variables or secure config files\n\n6) **Documentation verification**:\n   - Follow the new secure key generation documentation to create API keys\n   - Verify the generated keys work correctly with the application\n   - Confirm all security best practices are clearly explained",
        "status": "done",
        "dependencies": [
          "22",
          "23"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-23T11:07:28.410Z"
      },
      {
        "id": "25",
        "title": "Add API-key and scope validation to all MCP endpoints",
        "description": "Implement mandatory API-key validation middleware for all MCP routes in mcp_http.rs with per-tool scope requirements and proper error responses for authentication/authorization failures.",
        "details": "Modify src/api/mcp_http.rs to add comprehensive security to mcp_post_handler and mcp_get_handler which currently rely only on weak origin checks:\n\n1) Create a new middleware module src/api/auth/api_key_middleware.rs with:\n   - ApiKey struct containing key, scopes, and metadata\n   - validate_api_key() function that checks against a database table or config file\n   - extract_api_key_from_request() to get key from Authorization header (Bearer token) or X-API-Key header\n   - ApiKeyMiddleware that intercepts all MCP requests before handlers\n\n2) Define scope requirements for each MCP tool:\n   - Low-level tools: email:read, email:write, folder:read, etc.\n   - High-level tools: ai:execute, model:configure, email:draft\n   - Create a tool_scopes mapping in high_level_tools.rs and regular tools module\n\n3) Update mcp_post_handler and mcp_get_handler:\n   - Remove or supplement weak origin check with API key validation\n   - Extract requested tool from the JSON-RPC request\n   - Look up required scopes for the tool\n   - Validate API key has all required scopes\n   - Pass validated API key context to downstream handlers\n\n4) Implement proper error responses:\n   - 401 Unauthorized for missing or invalid API keys\n   - 403 Forbidden for valid key but insufficient scopes\n   - Include WWW-Authenticate header with realm=\"MCP API\"\n   - Return JSON-RPC error format with descriptive messages\n\n5) Create database schema for API keys:\n   ```sql\n   CREATE TABLE api_keys (\n     id SERIAL PRIMARY KEY,\n     key_hash VARCHAR(255) UNIQUE NOT NULL,\n     name VARCHAR(255),\n     scopes TEXT[], -- Array of scope strings\n     created_at TIMESTAMP DEFAULT NOW(),\n     last_used_at TIMESTAMP,\n     is_active BOOLEAN DEFAULT true\n   );\n   ```\n\n6) Add configuration for API key validation:\n   - Environment variable to enable/disable in development\n   - Option to load keys from config file for testing\n   - Rate limiting per API key to prevent abuse",
        "testStrategy": "Test the API key validation thoroughly:\n\n1) Unit tests for api_key_middleware.rs:\n   - Test API key extraction from different header formats\n   - Test scope validation logic with various scope combinations\n   - Test database queries for API key lookup\n\n2) Integration tests for MCP endpoints:\n   - Test requests without API key return 401\n   - Test requests with invalid API key return 401\n   - Test requests with valid key but missing scopes return 403\n   - Test successful requests with proper API key and scopes\n   - Test both mcp_post_handler and mcp_get_handler paths\n\n3) Test each tool's scope requirements:\n   - Verify low-level tools require appropriate read/write scopes\n   - Verify high-level AI tools require elevated scopes\n   - Test scope inheritance (e.g., email:write includes email:read)\n\n4) Security testing:\n   - Attempt to bypass with malformed headers\n   - Test SQL injection in API key lookup\n   - Verify timing attacks don't reveal key existence\n   - Test rate limiting prevents brute force\n\n5) End-to-end testing:\n   - Create test API keys with different scope sets\n   - Verify frontend MCP client can authenticate properly\n   - Test error handling in UI when authentication fails\n   - Verify performance impact is minimal",
        "status": "done",
        "dependencies": [
          "22",
          "23",
          "24"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-23T11:10:41.611Z"
      },
      {
        "id": "26",
        "title": "Implement encryption for stored credentials",
        "description": "Add encryption at rest for all sensitive credentials including IMAP/SMTP passwords in database and JSON config files, with support for application-level encryption or external KMS integration.",
        "details": "Implement a comprehensive encryption solution for all stored credentials:\n\n1) Create encryption module at src/dashboard/services/security/encryption.rs:\n   - Define CredentialEncryption trait with encrypt() and decrypt() methods\n   - Implement ApplicationLevelEncryption using AES-256-GCM with master key from ENCRYPTION_MASTER_KEY env var\n   - Implement KmsEncryption for AWS KMS/Azure Key Vault integration (configurable via ENCRYPTION_PROVIDER env var)\n   - Add EncryptionService that selects provider based on configuration\n\n2) Update database schema with migration 005_add_credential_encryption.sql:\n   ```sql\n   ALTER TABLE email_accounts \n   ADD COLUMN password_encrypted BYTEA,\n   ADD COLUMN encryption_metadata JSONB;\n   \n   ALTER TABLE ai_model_configurations\n   ADD COLUMN api_key_encrypted BYTEA,\n   ADD COLUMN encryption_metadata JSONB;\n   ```\n\n3) Modify src/dashboard/models/email_account.rs:\n   - Add password_encrypted and encryption_metadata fields\n   - Update create() and update() methods to encrypt password before storage\n   - Modify get_password() to decrypt on retrieval\n   - Keep backward compatibility during migration\n\n4) Update src/dashboard/models/ai_model_configuration.rs similarly for api_key field\n\n5) Create migration script src/dashboard/services/security/migrate_credentials.rs:\n   - Scan all email_accounts and ai_model_configurations records\n   - For each plaintext credential, encrypt and store in new columns\n   - Verify decryption works correctly\n   - Once verified, null out plaintext columns\n\n6) Update JSON config handling in src/config/mod.rs:\n   - Detect plaintext credentials in config files\n   - Encrypt and rewrite config with encrypted values\n   - Add encryption_metadata to track encryption method\n\n7) Add key rotation support:\n   - Implement rotate_encryption_key() method\n   - Re-encrypt all credentials with new key\n   - Update encryption_metadata with rotation timestamp",
        "testStrategy": "Verify encryption implementation with comprehensive testing:\n\n1) Unit tests for encryption module:\n   - Test AES-256-GCM encryption/decryption with known test vectors\n   - Verify different length passwords encrypt correctly\n   - Test error handling for invalid keys or corrupted data\n   - Mock KMS integration tests\n\n2) Integration tests for database operations:\n   - Create email account with password, verify it's stored encrypted\n   - Retrieve account and confirm password decrypts correctly\n   - Test migration script on test data with mix of plaintext/encrypted records\n   - Verify AI model API keys are encrypted similarly\n\n3) End-to-end testing:\n   - Set ENCRYPTION_MASTER_KEY and restart application\n   - Create new email account via API/UI\n   - Query database directly to confirm password_encrypted is populated and password is null\n   - Use account for IMAP/SMTP operations to verify decryption works\n   - Test with missing ENCRYPTION_MASTER_KEY to ensure proper error handling\n\n4) Security validation:\n   - Verify encrypted values are different even for same plaintext (due to random IV)\n   - Confirm encryption metadata includes algorithm version for future compatibility\n   - Test key rotation functionality with multiple credentials",
        "status": "done",
        "dependencies": [
          "24"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-01-23T11:54:41.880Z"
      },
      {
        "id": "27",
        "title": "Fix path traversal vulnerability in attachment_storage.rs",
        "description": "Implement secure path canonicalization and containment checks in attachment_storage.rs to prevent directory traversal attacks via malicious file paths or symlinks.",
        "details": "Fix the path traversal vulnerability in attachment_storage.rs by implementing comprehensive path security measures:\n\n1) **Add path canonicalization**:\n   - Import std::fs::canonicalize() to resolve all symbolic links and relative path components\n   - Before any file operation, canonicalize both the requested path and the storage root directory\n   - Handle canonicalization errors gracefully (non-existent paths, permission issues)\n\n2) **Implement strict containment validation**:\n   - Create a validate_path_containment() function that:\n     - Canonicalizes the requested file path\n     - Canonicalizes the attachments storage root directory\n     - Uses path.starts_with() to ensure the resolved path is within the storage root\n     - Returns Result<PathBuf, SecurityError> with the safe canonicalized path or error\n   \n3) **Update all file operations**:\n   - Modify save_attachment(), get_attachment(), delete_attachment() to use validate_path_containment()\n   - Replace current basic path component checks with the new validation\n   - Ensure all Path/PathBuf constructions go through validation before use\n\n4) **Handle edge cases**:\n   - Reject null bytes in filenames\n   - Validate against Windows reserved names (CON, PRN, AUX, etc.) if cross-platform\n   - Handle Unicode normalization attacks (different representations of same character)\n   - Prevent TOCTOU attacks by using the validated canonical path for operations\n\n5) **Example implementation**:\n   ```rust\n   use std::path::{Path, PathBuf};\n   use std::fs;\n   \n   #[derive(Debug, thiserror::Error)]\n   enum PathSecurityError {\n       #[error(\"Path traversal attempt detected\")]\n       PathTraversal,\n       #[error(\"Invalid path: {0}\")]\n       InvalidPath(String),\n       #[error(\"Canonicalization failed: {0}\")]\n       CanonicalizationError(#[from] std::io::Error),\n   }\n   \n   fn validate_path_containment(\n       storage_root: &Path,\n       requested_path: &Path\n   ) -> Result<PathBuf, PathSecurityError> {\n       // Canonicalize the storage root\n       let canonical_root = fs::canonicalize(storage_root)?;\n       \n       // Construct full path and canonicalize\n       let full_path = storage_root.join(requested_path);\n       let canonical_path = fs::canonicalize(&full_path)\n           .or_else(|_| {\n               // If file doesn't exist, canonicalize parent and append filename\n               let parent = full_path.parent()\n                   .ok_or_else(|| PathSecurityError::InvalidPath(\"No parent directory\".into()))?;\n               let filename = full_path.file_name()\n                   .ok_or_else(|| PathSecurityError::InvalidPath(\"No filename\".into()))?;\n               \n               let canonical_parent = fs::canonicalize(parent)?;\n               Ok(canonical_parent.join(filename))\n           })?;\n       \n       // Verify the canonical path is within the storage root\n       if !canonical_path.starts_with(&canonical_root) {\n           return Err(PathSecurityError::PathTraversal);\n       }\n       \n       Ok(canonical_path)\n   }\n   ```\n\n6) **Add security logging**:\n   - Log all path traversal attempts with source IP/user info\n   - Include the malicious path in logs for security monitoring\n   - Consider rate limiting after multiple traversal attempts",
        "testStrategy": "Verify the path traversal fix with comprehensive security testing:\n\n1) **Unit tests for path validation**:\n   - Test basic traversal attempts: \"../../../etc/passwd\", \"..\\\\..\\\\windows\\\\system32\"\n   - Test encoded traversals: \"%2e%2e%2f\", \"..%252f\", \"%c0%ae%c0%ae/\"\n   - Test symlink traversal: create symlink pointing outside storage, verify rejection\n   - Test absolute paths: \"/etc/passwd\", \"C:\\\\Windows\\\\System32\"\n   - Test null bytes: \"file.txt\\x00.pdf\"\n   - Test Unicode tricks: \"le.txt\" (ligature), different normalization forms\n\n2) **Integration tests**:\n   - Create test storage directory with known structure\n   - Attempt to save files with malicious paths, verify all are rejected\n   - Test legitimate nested paths work correctly: \"user123/2024/invoice.pdf\"\n   - Verify error messages don't leak system paths\n\n3) **Edge case testing**:\n   - Test very long paths (near filesystem limits)\n   - Test special filenames: \".\", \"..\", \"~\", \"$file\"\n   - Test Windows reserved names: \"CON\", \"PRN\", \"AUX\", \"NUL\"\n   - Test case sensitivity issues on case-insensitive filesystems\n\n4) **TOCTOU race condition test**:\n   - Create a legitimate file\n   - In parallel thread, try to replace it with symlink during validation\n   - Verify the operation uses the validated canonical path\n\n5) **Performance testing**:\n   - Measure overhead of canonicalization on typical operations\n   - Test with deeply nested directory structures\n   - Ensure no significant performance regression\n\n6) **Security audit checklist**:\n   - Verify all file operations use validate_path_containment()\n   - Check no direct Path construction from user input\n   - Confirm error messages don't reveal system structure\n   - Review logs for attempted traversals during testing",
        "status": "done",
        "dependencies": [
          "32"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-01-23T11:20:23.188Z"
      },
      {
        "id": "28",
        "title": "Wire rate limiting into REST and MCP API paths",
        "description": "Integrate the existing rate limiting validation from validation.rs into all REST API endpoints and MCP handlers, implementing per-IP and per-API-key limits with proper 429 responses and rate limit headers.",
        "details": "Implement comprehensive rate limiting across all API surfaces:\n\n1) **Create rate limiting middleware for REST APIs**:\n   - Create src/dashboard/middleware/rate_limit.rs\n   - Import existing rate limiting logic from validation.rs\n   - Implement RateLimitMiddleware that extracts client IP and API key from requests\n   - Use a token bucket or sliding window algorithm for tracking request counts\n   - Store rate limit state in memory with Arc<Mutex<HashMap>> or use Redis for distributed deployments\n\n2) **Configure rate limits via environment variables**:\n   - Add RATE_LIMIT_PER_MINUTE (default: 60)\n   - Add RATE_LIMIT_PER_HOUR (default: 1000)\n   - Add RATE_LIMIT_PER_IP_MINUTE (default: 30)\n   - Add RATE_LIMIT_PER_IP_HOUR (default: 500)\n   - Support different limits for authenticated (API key) vs anonymous requests\n\n3) **Integrate middleware into REST API routes**:\n   - In main.rs, wrap all API routes with rate limiting middleware\n   - Apply before authentication middleware to protect against auth bypass attempts\n   - Example:\n   ```rust\n   .wrap(RateLimitMiddleware::new(rate_limit_config))\n   .wrap(cors)\n   .wrap(Logger::default())\n   ```\n\n4) **Add rate limiting to MCP handlers**:\n   - In each MCP handler function, add rate limit check at the beginning\n   - Extract client identifier from MCP context (connection ID or client metadata)\n   - Use the same rate limiting logic but with MCP-specific limits\n   - Return appropriate MCP error response when rate limited\n\n5) **Implement 429 Too Many Requests responses**:\n   - For REST APIs: Return HTTP 429 status with JSON error body\n   - Include retry-after header indicating when client can retry\n   - Error response format:\n   ```json\n   {\n     \"error\": \"rate_limit_exceeded\",\n     \"message\": \"Too many requests. Please retry after 60 seconds.\",\n     \"retry_after\": 60\n   }\n   ```\n\n6) **Add rate limit headers to all responses**:\n   - X-RateLimit-Limit: Maximum requests allowed\n   - X-RateLimit-Remaining: Requests remaining in current window\n   - X-RateLimit-Reset: Unix timestamp when the rate limit resets\n   - Add these headers even for successful requests\n\n7) **Handle edge cases**:\n   - Properly extract real client IP behind proxies (X-Forwarded-For, X-Real-IP)\n   - Implement IP whitelist for internal services (via RATE_LIMIT_WHITELIST_IPS env var)\n   - Graceful degradation if rate limit storage fails\n   - Different rate limits for different API endpoints (e.g., higher for read, lower for write)",
        "testStrategy": "Verify rate limiting implementation with comprehensive testing:\n\n1) **Unit tests for rate limiting logic**:\n   - Test token bucket/sliding window algorithm correctness\n   - Verify per-minute and per-hour limits work independently\n   - Test IP-based vs API-key-based rate limiting\n   - Verify rate limit reset timing\n\n2) **Integration tests for REST API**:\n   - Send requests up to the limit and verify all succeed\n   - Send one more request and verify 429 response with correct headers\n   - Wait for rate limit reset and verify requests work again\n   - Test with different IPs and API keys to ensure isolation\n\n3) **MCP handler rate limiting tests**:\n   - Mock MCP requests and verify rate limiting applies\n   - Test that rate limited MCP calls return appropriate error responses\n   - Verify MCP rate limits are independent from REST API limits\n\n4) **Header validation tests**:\n   - Verify all responses include X-RateLimit-* headers\n   - Check header values decrease correctly with each request\n   - Verify Reset header contains valid future timestamp\n\n5) **Load testing**:\n   - Use Apache Bench or similar to send concurrent requests\n   - Verify rate limiting holds under high concurrency\n   - Test with multiple IPs to ensure no cross-contamination\n\n6) **Configuration tests**:\n   - Start server with custom rate limit env vars\n   - Verify limits match configured values\n   - Test with missing env vars to ensure defaults work\n\n7) **Security tests**:\n   - Attempt to bypass with spoofed headers\n   - Verify whitelisted IPs bypass rate limits\n   - Test rate limiting works before authentication",
        "status": "done",
        "dependencies": [
          "22"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-01-23T11:26:45.106Z"
      },
      {
        "id": "29",
        "title": "Pin git dependencies to specific commit SHAs",
        "description": "Update Cargo.toml to pin all git dependencies (including rmcp crate) to specific commit SHAs to prevent supply chain attacks, document the pinned versions, and establish a periodic review process for dependency updates.",
        "details": "Implement secure dependency pinning to protect against supply chain attacks by ensuring all git dependencies reference immutable commit SHAs:\n\n1) **Audit current git dependencies in Cargo.toml**:\n   - Search for all dependencies using git = \"...\" syntax\n   - Identify the rmcp crate and any other git-based dependencies\n   - For each dependency, determine the current branch/tag being tracked\n   - Clone each repository and identify the exact commit SHA currently in use\n\n2) **Pin dependencies to specific commit SHAs**:\n   - Replace branch/tag references with rev = \"SHA\" for each git dependency\n   - Example transformation:\n     ```toml\n     # Before (vulnerable to upstream changes):\n     rmcp = { git = \"https://github.com/example/rmcp\", branch = \"main\" }\n     \n     # After (pinned to specific commit):\n     rmcp = { git = \"https://github.com/example/rmcp\", rev = \"a1b2c3d4e5f6...\" }\n     ```\n   - Run `cargo update` to ensure the lock file reflects the pinned versions\n   - Verify the application builds and tests pass with pinned dependencies\n\n3) **Document pinned dependencies**:\n   - Create docs/dependency-pins.md with a table documenting:\n     - Dependency name\n     - Repository URL\n     - Pinned commit SHA\n     - Commit date and author\n     - Version/tag the commit corresponds to (if any)\n     - Brief description of why this specific commit was chosen\n     - Last review date\n   - Add comments in Cargo.toml above each pinned dependency explaining the version\n\n4) **Establish review process**:\n   - Create .github/workflows/dependency-review.yml for monthly automated checks:\n     ```yaml\n     name: Dependency Review\n     on:\n       schedule:\n         - cron: '0 0 1 * *'  # Monthly on the 1st\n       workflow_dispatch:\n     \n     jobs:\n       review-git-deps:\n         runs-on: ubuntu-latest\n         steps:\n           - uses: actions/checkout@v3\n           - name: Check for updates\n             run: |\n               # Script to check each pinned repo for new commits\n               # Create issues for dependencies with updates available\n     ```\n   - Add a SECURITY.md section on dependency update procedures\n   - Document the review checklist:\n     - Check upstream repository for security advisories\n     - Review commit history since pinned version\n     - Test updates in isolated environment\n     - Update both Cargo.toml and docs/dependency-pins.md\n\n5) **Add CI validation**:\n   - Create a GitHub Action that fails if any git dependencies lack rev pins\n   - Add pre-commit hook to warn developers about unpinned dependencies\n   - Include dependency pinning in security audit checklist",
        "testStrategy": "Verify the dependency pinning implementation with comprehensive testing:\n\n1) **Validate all git dependencies are pinned**:\n   - Parse Cargo.toml and verify every git dependency has a `rev` field\n   - Ensure no git dependencies use `branch`, `tag`, or default to HEAD\n   - Run `cargo tree` to confirm resolved dependencies match pinned SHAs\n\n2) **Test build reproducibility**:\n   - Delete Cargo.lock and run `cargo build` on different machines\n   - Verify the exact same dependency versions are resolved\n   - Compare checksums of built artifacts to ensure deterministic builds\n\n3) **Verify documentation completeness**:\n   - Check docs/dependency-pins.md exists and contains all git dependencies\n   - Validate each entry has all required fields (SHA, date, reason, etc.)\n   - Cross-reference Cargo.toml pins with documentation\n\n4) **Test automated review process**:\n   - Manually trigger the dependency review workflow\n   - Verify it correctly identifies outdated dependencies\n   - Confirm it creates GitHub issues with appropriate labels and details\n   - Test the workflow with a intentionally outdated test dependency\n\n5) **Security validation**:\n   - Attempt to modify a git dependency to use a branch reference\n   - Verify CI pipeline fails with clear error message\n   - Test pre-commit hook warns about unpinned dependencies\n   - Simulate a supply chain attack by creating a malicious fork and verify pinning prevents it\n\n6) **Integration testing**:\n   - Run full test suite with pinned dependencies\n   - Deploy to staging environment and verify functionality\n   - Monitor for any performance or compatibility issues\n   - Test rollback procedure if a pinned dependency causes issues",
        "status": "done",
        "dependencies": [
          "32"
        ],
        "priority": "low",
        "subtasks": [],
        "updatedAt": "2026-01-23T11:57:58.341Z"
      },
      {
        "id": "30",
        "title": "Reduce unwrap/expect usage in request handlers",
        "description": "Replace 599 unwrap/expect calls in request handlers with proper Result handling and error responses, focusing on handlers that process external input to prevent panics from unexpected data.",
        "details": "Systematically eliminate panic-inducing unwrap/expect calls from request handlers to improve application stability and security:\n\n1) **Audit and prioritize unwrap/expect usage**:\n   - Run `rg -c \"\\.unwrap\\(\\)|\\.expect\\(\" src/` to get current count and locations\n   - Focus on high-risk areas: src/api/, src/dashboard/handlers/, and MCP handlers\n   - Prioritize handlers that process external input: API endpoints, form submissions, file uploads\n   - Create a tracking spreadsheet with file, line number, risk level, and replacement strategy\n\n2) **Define proper error types**:\n   - Create src/errors/handler_errors.rs with custom error types:\n   ```rust\n   #[derive(Debug, thiserror::Error)]\n   pub enum HandlerError {\n       #[error(\"Invalid input: {0}\")]\n       InvalidInput(String),\n       #[error(\"Database error: {0}\")]\n       Database(#[from] sqlx::Error),\n       #[error(\"Serialization error: {0}\")]\n       Serialization(#[from] serde_json::Error),\n       #[error(\"IO error: {0}\")]\n       Io(#[from] std::io::Error),\n       #[error(\"Authentication failed\")]\n       Unauthorized,\n       #[error(\"Resource not found\")]\n       NotFound,\n   }\n   ```\n   - Implement ResponseError trait for automatic HTTP response conversion\n\n3) **Replace unwrap/expect in API handlers**:\n   - Convert unwrap() to ? operator where possible\n   - Replace expect() with map_err() to provide context:\n   ```rust\n   // Before\n   let user_id = req.param(\"id\").unwrap().parse::<i32>().unwrap();\n   \n   // After\n   let user_id = req.param(\"id\")\n       .ok_or(HandlerError::InvalidInput(\"Missing user ID\".into()))?\n       .parse::<i32>()\n       .map_err(|_| HandlerError::InvalidInput(\"Invalid user ID format\".into()))?;\n   ```\n\n4) **Handle JSON parsing safely**:\n   - Replace serde_json::from_str().unwrap() with proper error handling:\n   ```rust\n   // Before\n   let config: Config = serde_json::from_str(&body).unwrap();\n   \n   // After\n   let config: Config = serde_json::from_str(&body)\n       .map_err(|e| HandlerError::InvalidInput(format!(\"Invalid JSON: {}\", e)))?;\n   ```\n\n5) **Fix database query handling**:\n   - Replace query unwraps with proper Result propagation:\n   ```rust\n   // Before\n   let user = sqlx::query_as!(User, \"SELECT * FROM users WHERE id = $1\", id)\n       .fetch_one(&pool)\n       .await\n       .unwrap();\n   \n   // After\n   let user = sqlx::query_as!(User, \"SELECT * FROM users WHERE id = $1\", id)\n       .fetch_one(&pool)\n       .await\n       .map_err(|e| match e {\n           sqlx::Error::RowNotFound => HandlerError::NotFound,\n           _ => HandlerError::Database(e),\n       })?;\n   ```\n\n6) **Update MCP handlers**:\n   - Focus on mcp_http.rs handlers that process tool calls\n   - Replace unwrap in JSON-RPC parsing and response building\n   - Add proper error responses following JSON-RPC error format\n\n7) **Implement error response middleware**:\n   - Create middleware to convert HandlerError to appropriate HTTP responses\n   - Include error details in development, sanitized messages in production\n   - Add request ID for error tracking",
        "testStrategy": "Verify the unwrap/expect reduction with comprehensive testing:\n\n1) **Static analysis verification**:\n   - Run `rg -c \"\\.unwrap\\(\\)|\\.expect\\(\" src/api/ src/dashboard/handlers/` before and after\n   - Verify significant reduction in count (target: 80%+ reduction in these directories)\n   - Use clippy with `#![warn(clippy::unwrap_used, clippy::expect_used)]` on modified files\n\n2) **Unit tests for error handling**:\n   - Test each HandlerError variant converts to correct HTTP status code\n   - Verify error messages are properly formatted and sanitized\n   - Test error context preservation through map_err chains\n\n3) **Integration tests for API endpoints**:\n   - Send malformed JSON to endpoints, verify 400 Bad Request responses\n   - Test with invalid IDs, verify 404 Not Found responses\n   - Send requests missing required fields, verify descriptive error messages\n   - Test database connection failures return 500 Internal Server Error\n\n4) **Panic testing**:\n   - Set up panic hook to log and alert on any remaining panics\n   - Run fuzzing tests on API endpoints with random/malformed input\n   - Monitor application logs during testing for any panic messages\n\n5) **Load testing for stability**:\n   - Run load tests with mix of valid and invalid requests\n   - Verify no panics occur under high load with bad input\n   - Check error rates remain consistent without crashes",
        "status": "done",
        "dependencies": [
          "25"
        ],
        "priority": "low",
        "subtasks": [],
        "updatedAt": "2026-01-23T12:00:09.734Z"
      },
      {
        "id": "31",
        "title": "Replace unsafe process checks in sync.rs",
        "description": "Replace unsafe blocks used for process state checking in sync.rs with safe Rust alternatives using proper synchronization primitives, documenting any truly necessary unsafe code with safety invariants.",
        "details": "Eliminate unsafe code in sync.rs by implementing safe alternatives for process state checking:\n\n1) **Audit current unsafe usage in sync.rs**:\n   - Identify all unsafe blocks and their purposes (likely checking process states, shared memory access, or FFI calls)\n   - Document what each unsafe block is trying to achieve\n   - Determine if the unsafe code is for performance, FFI, or working around Rust's safety checks\n   - Create a list of safety invariants that the current code assumes\n\n2) **Replace with safe synchronization primitives**:\n   - For shared state access, use Arc<Mutex<T>> or Arc<RwLock<T>> instead of raw pointers\n   - For atomic operations, use std::sync::atomic types (AtomicBool, AtomicUsize, etc.)\n   - For cross-thread communication, use channels (mpsc, crossbeam) instead of shared memory\n   - For process state tracking, consider using a state machine pattern with enums\n\n3) **Implement safe process state management**:\n   ```rust\n   use std::sync::{Arc, RwLock};\n   use std::sync::atomic::{AtomicBool, Ordering};\n   \n   #[derive(Debug, Clone)]\n   enum ProcessState {\n       Idle,\n       Running { pid: u32 },\n       Completed { exit_code: i32 },\n       Failed { error: String },\n   }\n   \n   struct ProcessManager {\n       state: Arc<RwLock<ProcessState>>,\n       is_active: Arc<AtomicBool>,\n   }\n   \n   impl ProcessManager {\n       fn check_state(&self) -> ProcessState {\n           self.state.read().unwrap().clone()\n       }\n       \n       fn update_state(&self, new_state: ProcessState) {\n           *self.state.write().unwrap() = new_state;\n       }\n   }\n   ```\n\n4) **Handle truly necessary unsafe code**:\n   - If interfacing with C libraries or system calls, wrap unsafe code in safe abstractions\n   - Document safety invariants with comments explaining:\n     - What assumptions the unsafe code makes\n     - What conditions must be met for the code to be safe\n     - Why safe alternatives cannot be used\n   - Example documentation:\n   ```rust\n   // SAFETY: The pointer `ptr` is guaranteed to be valid and aligned because:\n   // 1. It comes from a Box allocation which ensures proper alignment\n   // 2. We hold an exclusive lock preventing concurrent access\n   // 3. The lifetime 'a ensures the data outlives this function\n   unsafe {\n       // Minimal unsafe code here\n   }\n   ```\n\n5) **Create safe abstractions for system interactions**:\n   - If checking process status via system calls, use nix or libc crates with safe wrappers\n   - Implement error handling for all system operations\n   - Example safe wrapper:\n   ```rust\n   use nix::sys::wait::{waitpid, WaitStatus};\n   use nix::unistd::Pid;\n   \n   fn check_process_status(pid: i32) -> Result<ProcessStatus, Error> {\n       match waitpid(Pid::from_raw(pid), None) {\n           Ok(WaitStatus::Exited(_, code)) => Ok(ProcessStatus::Exited(code)),\n           Ok(WaitStatus::Signaled(_, sig, _)) => Ok(ProcessStatus::Signaled(sig)),\n           Ok(_) => Ok(ProcessStatus::Running),\n           Err(e) => Err(Error::SystemError(e)),\n       }\n   }\n   ```\n\n6) **Refactor concurrent access patterns**:\n   - Replace manual memory synchronization with channels or actors\n   - Use parking_lot for performance-critical locks if needed\n   - Implement timeout mechanisms to prevent deadlocks",
        "testStrategy": "Verify the unsafe code replacement with comprehensive testing:\n\n1) **Static analysis verification**:\n   - Run `grep -n \"unsafe\" src/sync.rs` before and after changes\n   - Verify significant reduction in unsafe blocks (target: 90%+ reduction)\n   - Use `cargo clippy` with pedantic lints to catch potential issues\n   - Run `cargo miri test` if applicable to detect undefined behavior\n\n2) **Unit tests for process state management**:\n   - Test concurrent access to process state from multiple threads\n   - Verify no data races occur under high contention\n   - Test state transitions are atomic and consistent\n   - Example test:\n   ```rust\n   #[test]\n   fn test_concurrent_state_updates() {\n       let manager = Arc::new(ProcessManager::new());\n       let handles: Vec<_> = (0..100).map(|i| {\n           let mgr = manager.clone();\n           thread::spawn(move || {\n               mgr.update_state(ProcessState::Running { pid: i });\n           })\n       }).collect();\n       \n       for handle in handles {\n           handle.join().unwrap();\n       }\n       \n       // Verify final state is valid\n   }\n   ```\n\n3) **Integration tests for process synchronization**:\n   - Spawn actual child processes and verify state tracking\n   - Test edge cases: process crashes, signals, zombie processes\n   - Verify no resource leaks occur over many iterations\n   - Test timeout handling and cleanup\n\n4) **Performance benchmarks**:\n   - Compare performance before and after unsafe removal\n   - Ensure synchronization overhead is acceptable\n   - Use criterion.rs for micro-benchmarks of critical paths\n   - Target: Less than 10% performance regression\n\n5) **Safety documentation review**:\n   - For any remaining unsafe blocks, verify comprehensive safety comments\n   - Ensure all invariants are documented and testable\n   - Review with another developer familiar with unsafe Rust\n\n6) **Stress testing**:\n   - Run the sync module under heavy load for extended periods\n   - Use tools like ThreadSanitizer to detect race conditions\n   - Monitor for panics, deadlocks, or resource exhaustion",
        "status": "done",
        "dependencies": [
          "30"
        ],
        "priority": "low",
        "subtasks": [],
        "updatedAt": "2026-01-23T12:01:56.488Z"
      },
      {
        "id": "32",
        "title": "Add comprehensive test coverage for security-affected areas",
        "description": "Create extensive test suite covering all security-critical functionality including CORS, origin validation, API authentication, path traversal, and rate limiting before implementing security fixes.",
        "details": "Create a comprehensive security test suite in tests/integration/security_tests.rs that establishes baseline behavior for all security-critical areas. This must be completed before any security hardening begins.\n\n**1. CORS Configuration Tests (for Task 22):**\n```rust\n#[cfg(test)]\nmod cors_tests {\n    use actix_web::{test, App, http::header};\n    \n    #[actix_web::test]\n    async fn test_cors_blocks_unauthorized_origins() {\n        // Test that requests from non-whitelisted origins are blocked\n        let app = test::init_service(create_app()).await;\n        let req = test::TestRequest::get()\n            .uri(\"/api/emails\")\n            .header(header::ORIGIN, \"https://evil.com\")\n            .to_request();\n        let resp = test::call_service(&app, req).await;\n        // Initially may pass (document current behavior)\n    }\n    \n    #[actix_web::test]\n    async fn test_cors_allows_configured_origins() {\n        // Test that ALLOWED_ORIGINS are properly accepted\n        std::env::set_var(\"ALLOWED_ORIGINS\", \"http://localhost:3000,http://localhost:5173\");\n        // Test requests from these origins succeed\n    }\n    \n    #[actix_web::test]\n    async fn test_preflight_options_requests() {\n        // Test OPTIONS preflight requests work correctly\n        // Check Access-Control headers in response\n    }\n    \n    #[actix_web::test]\n    async fn test_cors_credentials_mode() {\n        // Test Access-Control-Allow-Credentials header\n    }\n}\n```\n\n**2. Origin Validation Tests (for Task 23):**\n```rust\nmod origin_validation_tests {\n    #[actix_web::test]\n    async fn test_exact_origin_matching() {\n        // Test that \"evil.localhost.com\" doesn't match \"localhost.com\"\n        // Test substring matching is rejected\n    }\n    \n    #[actix_web::test]\n    async fn test_missing_origin_header() {\n        // Test requests without Origin header\n        // Document current behavior (may currently pass)\n    }\n    \n    #[actix_web::test]\n    async fn test_spoofed_origin_patterns() {\n        // Test various spoofing attempts:\n        // - \"localhost.evil.com\"\n        // - \"localhost.com.evil.com\"\n        // - \"localhost:3000.evil.com\"\n    }\n    \n    #[actix_web::test]\n    async fn test_port_number_validation() {\n        // Test that port numbers are validated\n        // \"localhost:3000\" != \"localhost:3001\"\n    }\n}\n```\n\n**3. API Key Authentication Tests (for Tasks 24, 25):**\n```rust\nmod api_auth_tests {\n    #[actix_web::test]\n    async fn test_mcp_endpoints_require_api_key() {\n        // Test all MCP endpoints reject requests without API key\n        let endpoints = vec![\n            \"/mcp/tools\",\n            \"/mcp/tools/list_emails/run\",\n            \"/mcp/tools/get_email/run\",\n            // ... all MCP endpoints\n        ];\n        \n        for endpoint in endpoints {\n            let req = test::TestRequest::post()\n                .uri(endpoint)\n                .to_request();\n            let resp = test::call_service(&app, req).await;\n            // Document current behavior\n        }\n    }\n    \n    #[actix_web::test]\n    async fn test_api_key_scope_enforcement() {\n        // Test that API keys with limited scopes are properly restricted\n        // Test read-only keys can't write\n        // Test MCP-only keys can't access REST endpoints\n    }\n    \n    #[actix_web::test]\n    async fn test_invalid_api_key_rejection() {\n        // Test expired keys, malformed keys, non-existent keys\n    }\n    \n    #[actix_web::test]\n    async fn test_no_test_credentials_seeded() {\n        // Verify database doesn't contain default test API keys\n        // Check for common test patterns: \"test\", \"demo\", \"example\"\n    }\n}\n```\n\n**4. Path Traversal Tests (for Task 27):**\n```rust\nmod path_traversal_tests {\n    #[actix_web::test]\n    async fn test_directory_traversal_patterns() {\n        // Test various traversal attempts:\n        let patterns = vec![\n            \"../../../etc/passwd\",\n            \"..\\\\..\\\\windows\\\\system32\",\n            \"%2e%2e%2f\",\n            \"..%252f\",\n            \"%c0%ae%c0%ae/\",\n            \"....//\",\n            \"..;/\",\n        ];\n        \n        for pattern in patterns {\n            // Test attachment download/upload with malicious paths\n            // Document current behavior\n        }\n    }\n    \n    #[actix_web::test]\n    async fn test_symlink_escape_attempts() {\n        // Create symlink pointing outside storage directory\n        // Test that following symlinks is blocked\n    }\n    \n    #[actix_web::test]\n    async fn test_path_canonicalization() {\n        // Test that paths are properly canonicalized\n        // Test relative paths are resolved\n    }\n    \n    #[actix_web::test]\n    async fn test_storage_directory_containment() {\n        // Verify all file operations stay within designated directory\n    }\n}\n```\n\n**5. Rate Limiting Tests (for Task 28):**\n```rust\nmod rate_limiting_tests {\n    #[actix_web::test]\n    async fn test_rest_api_rate_limits() {\n        // Test rate limiting on REST endpoints\n        // Make requests exceeding limit\n        // Verify 429 response\n    }\n    \n    #[actix_web::test]\n    async fn test_mcp_api_rate_limits() {\n        // Test rate limiting on MCP endpoints\n        // Ensure MCP routes are also protected\n    }\n    \n    #[actix_web::test]\n    async fn test_rate_limit_headers() {\n        // Check for X-RateLimit-Limit header\n        // Check for X-RateLimit-Remaining header\n        // Check for X-RateLimit-Reset header\n    }\n    \n    #[actix_web::test]\n    async fn test_rate_limit_429_response() {\n        // Verify proper 429 Too Many Requests response\n        // Check Retry-After header\n    }\n}\n```\n\n**Implementation Guidelines:**\n- Each test should first document CURRENT behavior (even if insecure)\n- Add clear comments indicating expected vs actual behavior\n- Tests should be designed to pass with current code\n- As security fixes are implemented, update tests to verify secure behavior\n- Use test fixtures and helper functions to reduce duplication\n- Include both positive and negative test cases\n- Test edge cases and boundary conditions",
        "testStrategy": "Verify comprehensive test coverage implementation:\n\n1. **Test File Creation:**\n   - Confirm tests/integration/security_tests.rs is created\n   - Verify all five test modules are present\n   - Check that tests compile without errors\n\n2. **CORS Tests Validation:**\n   - Run CORS tests and document current permissive behavior\n   - Verify tests check origin validation, preflight, and credentials\n   - Confirm tests are ready to validate Task 22 fixes\n\n3. **Origin Validation Tests:**\n   - Run origin tests documenting current behavior\n   - Verify exact matching tests (not substring)\n   - Confirm spoofing patterns are tested\n\n4. **API Authentication Tests:**\n   - Run auth tests on all MCP endpoints\n   - Document which endpoints currently lack authentication\n   - Verify scope enforcement tests are present\n\n5. **Path Traversal Tests:**\n   - Run traversal tests with various attack patterns\n   - Document current vulnerability status\n   - Verify symlink and canonicalization tests work\n\n6. **Rate Limiting Tests:**\n   - Run rate limit tests on both REST and MCP routes\n   - Document current rate limiting status\n   - Verify 429 response and header tests\n\n7. **Test Execution:**\n   ```bash\n   cargo test --test security_tests -- --nocapture\n   ```\n   - All tests should run (may fail documenting insecure behavior)\n   - Generate test report showing coverage gaps\n\n8. **Documentation Review:**\n   - Each test should have clear comments\n   - Current vs expected behavior documented\n   - Ready for updates as security fixes are applied",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-23T10:36:09.813Z"
      },
      {
        "id": "33",
        "title": "Add sampler configuration schema to database",
        "description": "Create a new database table 'ai_sampler_configs' to store per-model sampler settings including temperature, top_p, top_k, min_p, repeat_penalty, num_ctx (context window), think mode, stop sequences, and other provider-specific options.",
        "details": "Create a new database migration file migrations/005_create_ai_sampler_configs.sql with the following schema:\n\n```sql\nCREATE TABLE ai_sampler_configs (\n    id SERIAL PRIMARY KEY,\n    provider VARCHAR(255) NOT NULL,\n    model_name VARCHAR(255) NOT NULL,\n    temperature DECIMAL(3,2) DEFAULT 0.7,\n    top_p DECIMAL(3,2) DEFAULT 1.0,\n    top_k INTEGER DEFAULT NULL,\n    min_p DECIMAL(4,3) DEFAULT 0.01,\n    repeat_penalty DECIMAL(3,2) DEFAULT 1.0,\n    num_ctx INTEGER DEFAULT 2048,\n    think_mode BOOLEAN DEFAULT FALSE,\n    stop_sequences TEXT[] DEFAULT '{}',\n    provider_specific_options JSONB DEFAULT '{}',\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    UNIQUE(provider, model_name),\n    FOREIGN KEY (provider, model_name) REFERENCES ai_model_configurations(provider, model_name) ON DELETE CASCADE\n);\n\n-- Create trigger to update updated_at timestamp\nCREATE OR REPLACE FUNCTION update_updated_at_column()\nRETURNS TRIGGER AS $$\nBEGIN\n    NEW.updated_at = CURRENT_TIMESTAMP;\n    RETURN NEW;\nEND;\n$$ language 'plpgsql';\n\nCREATE TRIGGER update_ai_sampler_configs_updated_at BEFORE UPDATE\n    ON ai_sampler_configs FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n\n-- Insert default configurations for known models\nINSERT INTO ai_sampler_configs (provider, model_name, temperature, top_p, min_p, repeat_penalty, num_ctx, think_mode, stop_sequences, provider_specific_options)\nVALUES \n    ('ollama', 'qwen2.5:7b', 0.7, 1.0, 0.01, 1.0, 8192, FALSE, '{}', '{}'),\n    ('ollama', 'llama3.3:70b', 0.7, 1.0, 0.01, 1.0, 8192, FALSE, '{}', '{}'),\n    ('openai', 'gpt-4', 0.7, 1.0, NULL, NULL, 8192, FALSE, '{}', '{\"presence_penalty\": 0, \"frequency_penalty\": 0}'),\n    ('anthropic', 'claude-3-opus', 0.7, 1.0, NULL, NULL, 200000, FALSE, '{}', '{}'),\n    ('glm', 'GLM-4.7-Flash', 0.7, 1.0, 0.01, 1.0, 51200, FALSE, '{}', '{}');\n```\n\nKey implementation considerations:\n1. Use DECIMAL types for floating-point sampler values to ensure precision\n2. Make top_k nullable since not all providers support it\n3. Use TEXT[] for stop_sequences to support multiple stop strings\n4. Use JSONB for provider_specific_options to allow flexible storage of provider-unique settings\n5. Include composite foreign key to ai_model_configurations table\n6. Add unique constraint on (provider, model_name) to ensure one config per model\n7. Include sensible defaults for common models with their known optimal settings\n8. Add timestamps for audit trail",
        "testStrategy": "1. Run the migration and verify table creation:\n   ```sql\n   \\d ai_sampler_configs\n   ```\n   Confirm all columns exist with correct types and constraints\n\n2. Test foreign key constraint:\n   - Try inserting a config for a non-existent model and verify it fails\n   - Insert a valid model in ai_model_configurations first, then add its sampler config\n\n3. Test unique constraint:\n   - Try inserting duplicate (provider, model_name) combinations and verify it fails\n\n4. Verify default values:\n   - Insert a row with minimal data and check that defaults are applied correctly\n\n5. Test the update trigger:\n   - Update a row and verify updated_at changes while created_at remains the same\n\n6. Query the default configurations:\n   ```sql\n   SELECT * FROM ai_sampler_configs ORDER BY provider, model_name;\n   ```\n   Verify all 5 default model configurations are present with correct values\n\n7. Test JSONB operations on provider_specific_options:\n   ```sql\n   UPDATE ai_sampler_configs \n   SET provider_specific_options = '{\"custom_param\": \"value\"}'::jsonb \n   WHERE provider = 'ollama' AND model_name = 'qwen2.5:7b';\n   ```\n\n8. Test cascade delete:\n   - Delete a model from ai_model_configurations and verify its sampler config is also deleted",
        "status": "done",
        "dependencies": [
          "1"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-24T19:35:58.183Z"
      },
      {
        "id": "34",
        "title": "Create Rust service layer for sampler configurations",
        "description": "Implement a SamplerConfigService in Rust that manages sampler configurations in the database, providing methods to get/save configs and integrate with existing AI provider adapters to apply sampler settings dynamically.",
        "details": "Create src/dashboard/services/ai/sampler_config.rs with the following components:\n\n1. Define SamplerConfiguration struct with fields:\n   - id: i64\n   - provider: String (ollama, llamacpp, etc.)\n   - model_name: String\n   - temperature: Option<f32>\n   - top_p: Option<f32>\n   - top_k: Option<i32>\n   - repeat_penalty: Option<f32>\n   - seed: Option<i64>\n   - max_tokens: Option<i32>\n   - stop_sequences: Option<Vec<String>>\n   - created_at: DateTime\n   - updated_at: DateTime\n\n2. Implement SamplerConfigService with methods:\n   - async fn get_config_for_model(provider: &str, model: &str) -> Result<Option<SamplerConfiguration>>\n   - async fn save_config(config: SamplerConfiguration) -> Result<SamplerConfiguration>\n   - async fn list_configs() -> Result<Vec<SamplerConfiguration>>\n   - async fn get_default_config_for_provider(provider: &str) -> Result<SamplerConfiguration>\n   - async fn delete_config(id: i64) -> Result<()>\n\n3. Create database migration migrations/005_create_sampler_configs.sql:\n   ```sql\n   CREATE TABLE sampler_configurations (\n       id INTEGER PRIMARY KEY AUTOINCREMENT,\n       provider TEXT NOT NULL,\n       model_name TEXT NOT NULL,\n       temperature REAL,\n       top_p REAL,\n       top_k INTEGER,\n       repeat_penalty REAL,\n       seed INTEGER,\n       max_tokens INTEGER,\n       stop_sequences TEXT, -- JSON array\n       created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n       updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n       UNIQUE(provider, model_name)\n   );\n   \n   -- Insert default configurations\n   INSERT INTO sampler_configurations (provider, model_name, temperature, top_p, top_k, max_tokens)\n   VALUES \n   ('ollama', 'default', 0.7, 0.9, 40, 2048),\n   ('llamacpp', 'default', 0.8, 0.95, 50, 4096);\n   ```\n\n4. Update existing AI provider adapters to use SamplerConfigService:\n   - Modify OllamaAdapter::generate_response() to fetch sampler config before API call\n   - Modify LlamaCppAdapter::generate_response() similarly\n   - Apply sampler settings to the request payload dynamically\n   - Fall back to provider defaults if no config found\n\n5. Add sampler config application logic:\n   ```rust\n   // In adapter's generate_response method\n   let sampler_config = self.sampler_service\n       .get_config_for_model(&self.provider, &model_name)\n       .await?\n       .or_else(|| self.sampler_service.get_default_config_for_provider(&self.provider).await.ok())?;\n   \n   // Apply to request\n   if let Some(temp) = sampler_config.temperature {\n       request.temperature = Some(temp);\n   }\n   // ... apply other settings\n   ```\n\n6. Ensure thread-safe access to SamplerConfigService using Arc<SamplerConfigService> in adapters.",
        "testStrategy": "1. Unit tests for SamplerConfigService:\n   - Test CRUD operations (create, read, update, delete configs)\n   - Test unique constraint on (provider, model_name)\n   - Test get_config_for_model returns correct config or None\n   - Test default config retrieval for each provider\n   - Test list_configs returns all configurations\n\n2. Integration tests with database:\n   - Create test database and run migration\n   - Verify default configs are inserted\n   - Test concurrent access patterns\n   - Test config updates reflect in subsequent reads\n\n3. Adapter integration tests:\n   - Mock SamplerConfigService in OllamaAdapter tests\n   - Verify generate_response applies sampler settings correctly\n   - Test fallback to defaults when no config exists\n   - Test that all sampler parameters are properly mapped to API request\n\n4. Manual testing:\n   - Create custom sampler config via direct DB insert\n   - Call generate_response and verify API logs show correct parameters\n   - Test with extreme values (temperature=0, temperature=2.0)\n   - Verify stop sequences are properly serialized/deserialized\n\n5. Performance testing:\n   - Measure overhead of config lookup on each generate_response call\n   - Consider caching strategy if lookup impacts performance",
        "status": "done",
        "dependencies": [
          "1",
          "2"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-24T19:39:45.270Z"
      },
      {
        "id": "35",
        "title": "Build WebUI sampler configuration panel",
        "description": "Create a React component in the dashboard settings page that allows users to configure sampler settings for each AI provider/model with provider-specific field visibility and test functionality.",
        "details": "Create src/dashboard/components/settings/SamplerConfigPanel.tsx with the following implementation:\n\n1. **Component Structure**:\n   ```tsx\n   interface SamplerConfig {\n     provider: string;\n     modelName: string;\n     temperature: number;\n     topP: number;\n     topK?: number;\n     minP?: number;\n     repeatPenalty: number;\n     numCtx: number;\n     thinkMode: boolean;\n     stopSequences: string[];\n   }\n   ```\n\n2. **Main Component Features**:\n   - Provider/Model selector dropdown that loads available models from the backend\n   - Temperature slider (0-2, step 0.1) with numeric display\n   - Top_p slider (0-1, step 0.01) with numeric display\n   - Top_k number input (optional, min 1)\n   - Min_p slider (0-1, step 0.001) - only shown for llama.cpp provider\n   - Repeat_penalty slider (0-2, step 0.1)\n   - Context window size (num_ctx) number input with provider-specific limits\n   - Think mode toggle switch\n   - Stop sequences text area with ability to add/remove sequences (one per line)\n\n3. **Provider-Specific Field Visibility**:\n   ```tsx\n   const providerFields = {\n     'ollama': ['temperature', 'topP', 'topK', 'repeatPenalty', 'numCtx', 'stopSequences'],\n     'llamacpp': ['temperature', 'topP', 'topK', 'minP', 'repeatPenalty', 'numCtx', 'stopSequences'],\n     'openai': ['temperature', 'topP', 'stopSequences', 'thinkMode']\n   };\n   ```\n\n4. **API Integration**:\n   - GET /api/sampler-configs/:provider/:model to load existing config\n   - POST /api/sampler-configs to save configuration\n   - GET /api/models to load available models per provider\n   - POST /api/sampler-configs/test to test configuration\n\n5. **Reset to Defaults Button**:\n   ```tsx\n   const defaultConfigs = {\n     'ollama': { temperature: 0.7, topP: 1.0, repeatPenalty: 1.0, numCtx: 2048 },\n     'llamacpp': { temperature: 0.7, topP: 1.0, minP: 0.01, repeatPenalty: 1.0, numCtx: 2048 },\n     'openai': { temperature: 0.7, topP: 1.0, thinkMode: false }\n   };\n   ```\n\n6. **Test Configuration Feature**:\n   - Modal dialog with test prompt input\n   - Sends request to backend with current config + test prompt\n   - Displays response and timing information\n   - Shows any errors or warnings\n\n7. **UI Components**:\n   - Use Material-UI or existing design system components\n   - Tooltips for each setting explaining its purpose\n   - Visual feedback for saving (loading spinner, success toast)\n   - Validation feedback (red borders for invalid values)\n\n8. **State Management**:\n   - Use React hooks (useState, useEffect) for local state\n   - Debounce slider changes to avoid excessive API calls\n   - Show unsaved changes indicator\n   - Confirm navigation away with unsaved changes",
        "testStrategy": "1. **Component Rendering Tests**:\n   - Verify component renders without errors\n   - Check all form fields are present for default provider\n   - Verify provider-specific fields show/hide correctly when switching providers\n   - Test that switching models loads the correct configuration\n\n2. **Field Interaction Tests**:\n   - Test temperature slider updates value correctly (0-2 range)\n   - Test top_p slider updates value correctly (0-1 range)\n   - Verify min_p field only appears for llama.cpp provider\n   - Test stop sequences can be added/removed\n   - Verify number inputs reject invalid values\n\n3. **API Integration Tests**:\n   - Mock GET /api/sampler-configs/:provider/:model and verify config loads\n   - Mock POST /api/sampler-configs and verify save functionality\n   - Test error handling for failed API calls\n   - Verify loading states display correctly\n\n4. **Reset Functionality Test**:\n   - Click \"Reset to Defaults\" and verify all fields update\n   - Ensure provider-specific defaults are applied correctly\n   - Verify unsaved changes indicator appears after reset\n\n5. **Test Configuration Feature**:\n   - Click \"Test Configuration\" and verify modal opens\n   - Enter test prompt and submit\n   - Mock POST /api/sampler-configs/test endpoint\n   - Verify response displays in modal\n   - Test error handling for failed test requests\n\n6. **Validation Tests**:\n   - Enter invalid values (negative numbers, out of range)\n   - Verify validation messages appear\n   - Ensure save is disabled with invalid values\n   - Test required field validation\n\n7. **Integration Test**:\n   - Load existing configuration\n   - Modify multiple fields\n   - Save configuration\n   - Reload page and verify changes persisted\n   - Test configuration with actual prompt",
        "status": "done",
        "dependencies": [
          "33",
          "34"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-24T19:45:28.706Z"
      },
      {
        "id": "36",
        "title": "Add sensible default sampler presets for common models",
        "description": "Research and implement default sampler configurations for popular models used with local inference, creating presets for GLM-4.7-Flash, Qwen, Llama, Mistral models and generic defaults for cloud providers, storing them as seed data in the database with documentation.",
        "details": "Create a database migration to seed the ai_sampler_configs table with well-researched default configurations:\n\n1. **Create migration file** migrations/006_seed_default_sampler_configs.sql:\n\n```sql\n-- GLM-4.7-Flash defaults (optimized for fast, coherent responses)\nINSERT INTO ai_sampler_configs (provider, model_name, temperature, top_p, min_p, repeat_penalty, num_ctx, think_mode, created_at, updated_at)\nVALUES \n    ('ollama', 'glm4:7b-flash', 0.7, 1.0, 0.01, 1.0, 51200, false, NOW(), NOW()),\n    -- Temperature 0.7: Balanced creativity without excessive randomness\n    -- top_p 1.0: No nucleus sampling restriction, model can use full vocabulary\n    -- min_p 0.01: Filters out tokens with <1% probability to reduce noise\n    -- repeat_penalty 1.0: No penalty, GLM models handle repetition well internally\n    -- num_ctx 51200: Large context window for complex email threads\n    -- think_mode false: Flash variant optimized for speed, not deep reasoning\n\n    -- Qwen models (optimized for instruction following)\n    ('ollama', 'qwen2.5:7b', 0.7, 0.95, 0.05, 1.1, 32768, false, NOW(), NOW()),\n    ('ollama', 'qwen2.5:14b', 0.7, 0.95, 0.05, 1.1, 32768, false, NOW(), NOW()),\n    ('ollama', 'qwen2.5:32b', 0.7, 0.95, 0.05, 1.1, 32768, false, NOW(), NOW()),\n    -- Temperature 0.7: Standard for instruction-following tasks\n    -- top_p 0.95: Slight nucleus sampling for more focused outputs\n    -- min_p 0.05: Higher threshold to ensure quality token selection\n    -- repeat_penalty 1.1: Slight penalty to encourage variety\n    -- num_ctx 32768: Qwen's native context size\n    -- think_mode false: Qwen models don't support CoT prompting\n\n    -- Llama 3.x models (optimized for general purpose)\n    ('ollama', 'llama3.2:3b', 0.8, 0.9, 0.05, 1.15, 8192, false, NOW(), NOW()),\n    ('ollama', 'llama3.2:7b', 0.8, 0.9, 0.05, 1.15, 8192, false, NOW(), NOW()),\n    ('ollama', 'llama3.1:70b', 0.7, 0.9, 0.05, 1.1, 131072, false, NOW(), NOW()),\n    -- Temperature 0.8/0.7: Higher for smaller models, lower for larger\n    -- top_p 0.9: Moderate nucleus sampling for coherence\n    -- min_p 0.05: Standard quality threshold\n    -- repeat_penalty 1.15/1.1: Higher for smaller models to reduce loops\n    -- num_ctx: Model-specific limits\n    \n    -- Mistral models (optimized for reasoning)\n    ('ollama', 'mistral:7b', 0.7, 0.95, 0.05, 1.1, 32768, false, NOW(), NOW()),\n    ('ollama', 'mixtral:8x7b', 0.7, 0.95, 0.05, 1.1, 32768, false, NOW(), NOW()),\n    ('ollama', 'mistral-large:123b', 0.6, 0.95, 0.05, 1.05, 32768, false, NOW(), NOW()),\n    -- Temperature 0.6-0.7: Lower for larger models\n    -- top_p 0.95: Consistent nucleus sampling\n    -- repeat_penalty: Lower for larger models\n    \n    -- Generic cloud provider defaults\n    ('openai', 'gpt-4-turbo', 0.7, 1.0, NULL, NULL, 128000, false, NOW(), NOW()),\n    ('openai', 'gpt-4o', 0.7, 1.0, NULL, NULL, 128000, false, NOW(), NOW()),\n    ('openai', 'gpt-3.5-turbo', 0.7, 1.0, NULL, NULL, 16384, false, NOW(), NOW()),\n    -- OpenAI models: Only temperature and top_p supported\n    -- num_ctx matches model's context window\n    \n    ('anthropic', 'claude-3-opus', 0.7, 1.0, NULL, NULL, 200000, false, NOW(), NOW()),\n    ('anthropic', 'claude-3-sonnet', 0.7, 1.0, NULL, NULL, 200000, false, NOW(), NOW()),\n    ('anthropic', 'claude-3-haiku', 0.7, 1.0, NULL, NULL, 200000, false, NOW(), NOW()),\n    -- Anthropic: Similar to OpenAI, large context windows\n    \n    -- LlamaCpp defaults (for self-hosted models)\n    ('llamacpp', 'default', 0.7, 0.95, 0.05, 1.1, 4096, false, NOW(), NOW());\n    -- Conservative defaults for unknown models\n```\n\n2. **Add rollback migration** for reversibility:\n```sql\n-- Rollback: Remove only the seeded defaults, preserve user configurations\nDELETE FROM ai_sampler_configs \nWHERE created_at = updated_at \nAND model_name IN (\n    'glm4:7b-flash', 'qwen2.5:7b', 'qwen2.5:14b', 'qwen2.5:32b',\n    'llama3.2:3b', 'llama3.2:7b', 'llama3.1:70b',\n    'mistral:7b', 'mixtral:8x7b', 'mistral-large:123b',\n    'gpt-4-turbo', 'gpt-4o', 'gpt-3.5-turbo',\n    'claude-3-opus', 'claude-3-sonnet', 'claude-3-haiku',\n    'default'\n);\n```\n\n3. **Create documentation file** docs/sampler-presets.md explaining the rationale:\n```markdown\n# Default Sampler Configurations\n\n## Overview\nThis document explains the default sampler settings for various AI models.\n\n## Parameter Explanations\n\n### Temperature (0.0 - 2.0)\n- Controls randomness in token selection\n- 0.0: Deterministic (always picks most likely token)\n- 0.7-0.8: Balanced creativity for general tasks\n- 1.0+: High creativity, may reduce coherence\n\n### Top-p (0.0 - 1.0)\n- Nucleus sampling: only consider tokens whose cumulative probability < top_p\n- 1.0: Consider all tokens\n- 0.9-0.95: Moderate filtering of unlikely tokens\n- <0.9: More focused, deterministic outputs\n\n### Min-p (0.0 - 1.0)\n- Minimum probability threshold for token consideration\n- Filters out tokens with probability < min_p\n- 0.01-0.05: Standard range for quality filtering\n\n### Repeat Penalty (1.0 - 2.0)\n- Penalizes tokens that have appeared recently\n- 1.0: No penalty\n- 1.1-1.15: Light penalty for variety\n- 1.5+: Strong penalty, may harm coherence\n\n## Model-Specific Rationales\n[Include detailed explanations for each model family]\n```\n\n4. **Update SamplerConfigService** to include a method for resetting to defaults:\n```rust\nimpl SamplerConfigService {\n    pub async fn reset_to_default(&self, provider: &str, model_name: &str) -> Result<()> {\n        // Query the seeded defaults where created_at = updated_at\n        // This identifies unchanged default configurations\n    }\n}\n```",
        "testStrategy": "1. **Migration Testing**:\n   - Run migration: `diesel migration run`\n   - Verify all default configurations are inserted:\n     ```sql\n     SELECT provider, model_name, temperature, top_p, min_p, repeat_penalty, num_ctx \n     FROM ai_sampler_configs \n     ORDER BY provider, model_name;\n     ```\n   - Confirm 17 rows inserted with correct values\n   - Test rollback removes only seeded data\n\n2. **Configuration Validation**:\n   - For each model, verify sampler settings are within valid ranges\n   - Test that NULL values are properly set for cloud providers (min_p, repeat_penalty)\n   - Verify num_ctx values match documented model limits\n\n3. **Integration Testing**:\n   - Start application and verify SamplerConfigService loads defaults\n   - Test get_config_for_model() returns correct preset for each model\n   - Verify WebUI displays presets correctly in dropdown\n   - Test that user modifications don't affect default lookup\n\n4. **Model Testing** (manual):\n   - For each model type, generate a test email draft\n   - Verify output quality matches expectations:\n     - GLM-4.7-Flash: Fast, coherent responses\n     - Qwen: Good instruction following\n     - Llama: Balanced general purpose output\n     - Mistral: Strong reasoning capability\n   - Compare outputs with/without presets to validate improvements\n\n5. **Documentation Verification**:\n   - Review docs/sampler-presets.md for accuracy\n   - Ensure all parameter choices are justified\n   - Verify model-specific notes are comprehensive",
        "status": "done",
        "dependencies": [
          "33",
          "34"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-01-24T20:11:35.462Z"
      },
      {
        "id": "37",
        "title": "Add LM Studio provider adapter",
        "description": "Create a new LM Studio adapter similar to the llama.cpp adapter since LM Studio uses an OpenAI-compatible API but may have specific quirks. Support the same sampler settings as llama.cpp (min_p, top_no, etc.).",
        "details": "Create src/dashboard/services/ai/providers/lmstudio.rs with the following implementation:\n\n1. Define LMStudioProvider struct that implements the AI provider trait:\n   - base_url: String (from LMSTUDIO_BASE_URL env var, default: \"http://localhost:1234\")\n   - api_key: Option<String> (LM Studio typically doesn't require auth)\n   - client: reqwest::Client\n\n2. Implement provider methods:\n   - new() - Initialize with base URL from env or default\n   - complete() - Send completion requests to /v1/chat/completions endpoint\n   - complete_with_tools() - Send tool-enabled requests (if LM Studio supports it)\n   - list_models() - Query /v1/models endpoint\n\n3. Support LM Studio-specific sampler parameters in requests:\n   - temperature, top_p, top_k (standard OpenAI params)\n   - min_p (minimum probability threshold)\n   - top_a (top-a sampling)\n   - typical_p (typical sampling)\n   - tfs_z (tail-free sampling)\n   - repeat_penalty\n   - repeat_last_n\n   - penalize_nl\n   - presence_penalty\n   - frequency_penalty\n   - mirostat, mirostat_tau, mirostat_eta\n   - seed\n   - stop sequences\n\n4. Handle LM Studio response format quirks:\n   - Parse streaming responses if different from OpenAI\n   - Handle any non-standard error formats\n   - Support both streaming and non-streaming modes\n\n5. Add provider registration:\n   - Update provider factory/registry to include \"lmstudio\" as a provider option\n   - Ensure SamplerConfigService can apply LM Studio-specific samplers\n\n6. Environment variable support:\n   - LMSTUDIO_BASE_URL (default: http://localhost:1234)\n   - LMSTUDIO_API_KEY (optional, for future compatibility)\n\n7. Error handling:\n   - Connection errors when LM Studio isn't running\n   - Model not loaded errors\n   - Invalid sampler parameter combinations\n   - Timeout handling for slow local models\n\nExample implementation structure:\n```rust\nuse crate::dashboard::services::ai::{AIProvider, CompletionRequest, CompletionResponse};\n\npub struct LMStudioProvider {\n    base_url: String,\n    client: reqwest::Client,\n}\n\nimpl LMStudioProvider {\n    pub fn new() -> Result<Self, Box<dyn std::error::Error>> {\n        let base_url = std::env::var(\"LMSTUDIO_BASE_URL\")\n            .unwrap_or_else(|_| \"http://localhost:1234\".to_string());\n        \n        Ok(Self {\n            base_url,\n            client: reqwest::Client::new(),\n        })\n    }\n    \n    fn apply_sampler_config(&self, request: &mut serde_json::Value, config: &SamplerConfiguration) {\n        // Apply LM Studio specific samplers\n        if let Some(min_p) = config.min_p {\n            request[\"min_p\"] = json!(min_p);\n        }\n        // ... other samplers\n    }\n}\n\nimpl AIProvider for LMStudioProvider {\n    async fn complete(&self, request: CompletionRequest) -> Result<CompletionResponse, Box<dyn std::error::Error>> {\n        // Implementation\n    }\n}\n```",
        "testStrategy": "1. Unit tests for LMStudioProvider:\n   - Test initialization with default and custom LMSTUDIO_BASE_URL\n   - Mock HTTP responses for completion requests\n   - Test all sampler parameters are correctly included in requests\n   - Test error handling for connection failures\n   - Test streaming vs non-streaming response parsing\n\n2. Integration tests (requires LM Studio running):\n   - Test actual completion requests with a loaded model\n   - Verify sampler parameters affect output (e.g., temperature 0 vs 1)\n   - Test model listing endpoint\n   - Test timeout handling with large prompts\n   - Test special characters and Unicode handling\n\n3. Manual testing checklist:\n   - Install LM Studio on Windows/macOS\n   - Load a model (e.g., Llama 3.3)\n   - Configure RustyMail to use lmstudio provider\n   - Test email drafting with various sampler settings\n   - Verify min_p, top_a, and other LM Studio-specific samplers work\n   - Test with different model architectures (Llama, Mistral, Qwen)\n   - Test error messages when LM Studio isn't running\n   - Verify performance with local models\n\n4. Compatibility testing:\n   - Test with latest LM Studio version\n   - Verify OpenAI compatibility layer works as expected\n   - Test any LM Studio-specific extensions or deviations\n   - Document any limitations or unsupported features",
        "status": "done",
        "dependencies": [
          "34"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-01-24T20:16:36.692Z"
      },
      {
        "id": "38",
        "title": "Wire sampler configuration from database to provider adapters",
        "description": "Modify all AI provider adapters (OllamaAdapter, LlamaAdapter, LMStudioAdapter, etc.) to fetch and apply sampler configurations from the database instead of using hardcoded defaults, implementing a priority system: database > environment variables > code defaults.",
        "details": "Update all provider adapters to integrate with the SamplerConfigService and apply configurations dynamically:\n\n1. **Update OllamaAdapter** (src/dashboard/services/ai/providers/ollama.rs):\n   ```rust\n   // Add sampler_config_service to the struct\n   struct OllamaAdapter {\n       base_url: String,\n       sampler_config_service: Arc<SamplerConfigService>,\n       // ... existing fields\n   }\n   \n   // In the complete() method, before making the request:\n   async fn complete(&self, request: CompletionRequest) -> Result<CompletionResponse> {\n       // Fetch sampler config from database\n       let sampler_config = self.sampler_config_service\n           .get_config_for_model(\"ollama\", &request.model)\n           .await?;\n       \n       // Build options with priority: DB > env > defaults\n       let mut options = json!({});\n       \n       if let Some(config) = sampler_config {\n           if let Some(temp) = config.temperature {\n               options[\"temperature\"] = json!(temp);\n           }\n           if let Some(top_p) = config.top_p {\n               options[\"top_p\"] = json!(top_p);\n           }\n           if let Some(top_k) = config.top_k {\n               options[\"top_k\"] = json!(top_k);\n           }\n           if let Some(repeat_penalty) = config.repeat_penalty {\n               options[\"repeat_penalty\"] = json!(repeat_penalty);\n           }\n           if let Some(num_ctx) = config.num_ctx {\n               options[\"num_ctx\"] = json!(num_ctx);\n           }\n           // Apply other sampler settings...\n       } else {\n           // Fall back to env vars or hardcoded defaults\n           options[\"temperature\"] = json!(env::var(\"OLLAMA_TEMPERATURE\")\n               .ok()\n               .and_then(|v| v.parse::<f32>().ok())\n               .unwrap_or(0.7));\n           // ... other defaults\n       }\n       \n       let ollama_request = json!({\n           \"model\": request.model,\n           \"prompt\": request.prompt,\n           \"options\": options,\n           \"stream\": request.stream.unwrap_or(false)\n       });\n       \n       // Make the API request...\n   }\n   ```\n\n2. **Update LlamaAdapter** (src/dashboard/services/ai/providers/llamacpp.rs):\n   ```rust\n   // Similar pattern but with llama.cpp specific parameters\n   let sampler_config = self.sampler_config_service\n       .get_config_for_model(\"llamacpp\", &request.model)\n       .await?;\n   \n   let mut body = json!({\n       \"prompt\": request.prompt,\n       \"n_predict\": request.max_tokens.unwrap_or(2048),\n       \"stream\": request.stream.unwrap_or(false)\n   });\n   \n   if let Some(config) = sampler_config {\n       // Apply llama.cpp specific parameters\n       if let Some(temp) = config.temperature {\n           body[\"temperature\"] = json!(temp);\n       }\n       if let Some(min_p) = config.min_p {\n           body[\"min_p\"] = json!(min_p);\n       }\n       if let Some(top_k) = config.top_k {\n           body[\"top_k\"] = json!(top_k);\n       }\n       // Handle stop sequences\n       if let Some(stop) = config.stop_sequences {\n           body[\"stop\"] = json!(stop);\n       }\n   }\n   ```\n\n3. **Update LMStudioAdapter** (src/dashboard/services/ai/providers/lmstudio.rs):\n   ```rust\n   // LM Studio uses OpenAI-compatible format but supports additional samplers\n   let sampler_config = self.sampler_config_service\n       .get_config_for_model(\"lmstudio\", &request.model)\n       .await?;\n   \n   // Build request with sampler settings\n   let mut lm_request = json!({\n       \"model\": request.model,\n       \"messages\": messages,\n       \"stream\": request.stream.unwrap_or(false)\n   });\n   \n   if let Some(config) = sampler_config {\n       // Apply OpenAI-style parameters\n       if let Some(temp) = config.temperature {\n           lm_request[\"temperature\"] = json!(temp);\n       }\n       if let Some(top_p) = config.top_p {\n           lm_request[\"top_p\"] = json!(top_p);\n       }\n       // LM Studio specific extensions\n       if let Some(min_p) = config.min_p {\n           lm_request[\"min_p\"] = json!(min_p);\n       }\n       if let Some(repeat_penalty) = config.repeat_penalty {\n           lm_request[\"frequency_penalty\"] = json!(repeat_penalty);\n       }\n   }\n   ```\n\n4. **Update provider factory** to inject SamplerConfigService:\n   ```rust\n   // In src/dashboard/services/ai/provider_factory.rs\n   pub fn create_provider(\n       provider_type: &str,\n       sampler_config_service: Arc<SamplerConfigService>,\n       // ... other params\n   ) -> Result<Box<dyn AIProvider>> {\n       match provider_type {\n           \"ollama\" => Ok(Box::new(OllamaAdapter::new(sampler_config_service)?)),\n           \"llamacpp\" => Ok(Box::new(LlamaAdapter::new(sampler_config_service)?)),\n           \"lmstudio\" => Ok(Box::new(LMStudioAdapter::new(sampler_config_service)?)),\n           _ => Err(anyhow!(\"Unknown provider type: {}\", provider_type))\n       }\n   }\n   ```\n\n5. **Add configuration caching** to reduce database queries:\n   ```rust\n   // In SamplerConfigService, add a cache layer\n   struct SamplerConfigService {\n       db_pool: Arc<DbPool>,\n       cache: Arc<RwLock<HashMap<(String, String), CachedConfig>>>,\n   }\n   \n   struct CachedConfig {\n       config: Option<SamplerConfiguration>,\n       expires_at: Instant,\n   }\n   \n   impl SamplerConfigService {\n       pub async fn get_config_for_model_cached(\n           &self,\n           provider: &str,\n           model_name: &str\n       ) -> Result<Option<SamplerConfiguration>> {\n           let key = (provider.to_string(), model_name.to_string());\n           \n           // Check cache first\n           {\n               let cache = self.cache.read().await;\n               if let Some(cached) = cache.get(&key) {\n                   if cached.expires_at > Instant::now() {\n                       return Ok(cached.config.clone());\n                   }\n               }\n           }\n           \n           // Fetch from database\n           let config = self.get_config_for_model(provider, model_name).await?;\n           \n           // Update cache\n           {\n               let mut cache = self.cache.write().await;\n               cache.insert(key, CachedConfig {\n                   config: config.clone(),\n                   expires_at: Instant::now() + Duration::from_secs(300), // 5 min cache\n               });\n           }\n           \n           Ok(config)\n       }\n   }\n   ```\n\n6. **Handle provider-specific parameter mappings**:\n   ```rust\n   // Create a trait for parameter mapping\n   trait SamplerParameterMapper {\n       fn map_config_to_request(&self, config: &SamplerConfiguration) -> serde_json::Value;\n   }\n   \n   // Implement for each provider with their specific parameter names\n   impl SamplerParameterMapper for OllamaAdapter {\n       fn map_config_to_request(&self, config: &SamplerConfiguration) -> serde_json::Value {\n           let mut params = json!({});\n           // Ollama uses \"num_ctx\" for context window\n           if let Some(num_ctx) = config.num_ctx {\n               params[\"num_ctx\"] = json!(num_ctx);\n           }\n           // ... map other parameters\n           params\n       }\n   }\n   ```",
        "testStrategy": "1. **Integration Tests for Each Provider**:\n   - Create test configurations in the database for each provider\n   - Mock provider API endpoints to capture the actual requests being sent\n   - Verify that sampler parameters from the database are correctly applied to requests\n   - Test fallback to environment variables when no DB config exists\n   - Test fallback to hardcoded defaults when neither DB nor env configs exist\n\n2. **Priority Order Testing**:\n   ```rust\n   #[tokio::test]\n   async fn test_config_priority_order() {\n       // Set up: Create DB config with temperature=0.5\n       let config = SamplerConfiguration {\n           provider: \"ollama\".to_string(),\n           model_name: \"llama2:7b\".to_string(),\n           temperature: Some(0.5),\n           // ...\n       };\n       sampler_service.save_config(config).await.unwrap();\n       \n       // Set environment variable to temperature=0.8\n       env::set_var(\"OLLAMA_TEMPERATURE\", \"0.8\");\n       \n       // Make completion request\n       let response = ollama_adapter.complete(request).await.unwrap();\n       \n       // Verify DB value (0.5) was used, not env value (0.8)\n       assert_eq!(captured_request[\"options\"][\"temperature\"], 0.5);\n   }\n   ```\n\n3. **Cache Performance Testing**:\n   - Measure database query count before and after implementing cache\n   - Verify cache expiration works correctly\n   - Test cache invalidation when configurations are updated\n   - Load test with multiple concurrent requests to ensure cache thread safety\n\n4. **Provider-Specific Parameter Testing**:\n   - Test Ollama-specific parameters (num_ctx, mirostat, etc.)\n   - Test llama.cpp-specific parameters (min_p, top_k, grammar, etc.)\n   - Test LM Studio OpenAI-compatible format with extensions\n   - Verify stop sequences are correctly formatted for each provider\n\n5. **Error Handling Tests**:\n   - Test behavior when database is unavailable (should fall back gracefully)\n   - Test invalid configuration values (e.g., temperature > 2.0)\n   - Test missing required parameters\n   - Verify error messages are helpful for debugging\n\n6. **End-to-End Testing**:\n   - Configure different sampler settings via the WebUI\n   - Make actual completion requests to each provider\n   - Verify response quality changes based on sampler settings\n   - Test with real models to ensure parameters are having expected effects",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-25T11:35:21.231Z"
      },
      {
        "id": "39",
        "title": "Persist Email Assistant provider/model selection to database",
        "description": "Save TopBar provider selection from in-memory ProviderManager to ai_model_configurations table with role='chatbot' and load on service startup to persist user's Email Assistant model choice across restarts.",
        "details": "Modify the Email Assistant to persist provider/model selection to the database instead of only storing in-memory:\n\n1. **Update ai_model_configurations table usage**:\n   - Use role='chatbot' for Email Assistant provider/model selection\n   - Store provider name, model name, and any provider-specific settings\n   - Ensure compatibility with existing 'tool_calling' and 'drafting' roles\n\n2. **Modify ProviderManager** (src/dashboard/services/ai/provider_manager.rs):\n   ```rust\n   // Add model_config_service dependency\n   struct ProviderManager {\n       providers: Arc<RwLock<HashMap<String, Box<dyn AIProvider>>>>,\n       current_provider: Arc<RwLock<String>>,\n       model_config_service: Arc<ModelConfigService>,\n   }\n   \n   // Update set_current_provider to persist to database\n   pub async fn set_current_provider(&self, provider_name: String, model_name: String) -> Result<()> {\n       // Update in-memory state\n       let mut current = self.current_provider.write().await;\n       *current = provider_name.clone();\n       \n       // Persist to database\n       let config = ModelConfiguration {\n           role: \"chatbot\".to_string(),\n           provider: provider_name,\n           model_name,\n           base_url: None, // Provider-specific, set if needed\n           api_key: None,  // Provider-specific, set if needed\n           additional_config: None,\n       };\n       \n       self.model_config_service.set_model_config(config).await?;\n       Ok(())\n   }\n   ```\n\n3. **Add startup initialization**:\n   ```rust\n   // In ProviderManager::new() or init()\n   pub async fn init(&self) -> Result<()> {\n       // Load saved chatbot configuration\n       if let Some(config) = self.model_config_service\n           .get_model_config(\"chatbot\").await? {\n           \n           // Set current provider from database\n           let mut current = self.current_provider.write().await;\n           *current = config.provider.clone();\n           \n           // Optionally validate provider exists\n           let providers = self.providers.read().await;\n           if !providers.contains_key(&config.provider) {\n               warn!(\"Saved provider {} not available, using default\", config.provider);\n               *current = \"ollama\".to_string(); // Or other default\n           }\n       }\n       Ok(())\n   }\n   ```\n\n4. **Update TopBar component integration**:\n   - Ensure TopBar calls the updated set_current_provider method\n   - Pass both provider and model name when selection changes\n   - Handle any UI state updates after persistence\n\n5. **Migration considerations**:\n   - Check if 'chatbot' role already exists in ai_model_configurations\n   - Handle upgrade path for users with existing in-memory selections\n   - Provide sensible defaults if no configuration exists\n\n6. **Error handling**:\n   - Gracefully handle database write failures (continue with in-memory)\n   - Log persistence errors without breaking provider switching\n   - Implement retry logic for transient database errors",
        "testStrategy": "1. **Unit tests for persistence logic**:\n   - Mock ModelConfigService and verify set_model_config is called with correct parameters\n   - Test that set_current_provider updates both in-memory and database state\n   - Verify error handling when database write fails\n\n2. **Integration tests for startup loading**:\n   - Insert test configuration with role='chatbot' into database\n   - Initialize ProviderManager and verify it loads the saved provider\n   - Test fallback behavior when saved provider doesn't exist\n   - Verify no configuration scenario uses appropriate defaults\n\n3. **End-to-end testing**:\n   - Start service and select a provider/model in TopBar\n   - Restart service and verify selection is preserved\n   - Test switching between different providers and models\n   - Verify other roles ('tool_calling', 'drafting') are not affected\n\n4. **Database verification**:\n   ```sql\n   -- Check chatbot configuration is saved\n   SELECT * FROM ai_model_configurations WHERE role = 'chatbot';\n   \n   -- Verify only one chatbot configuration exists\n   SELECT COUNT(*) FROM ai_model_configurations WHERE role = 'chatbot';\n   ```\n\n5. **Concurrency testing**:\n   - Simulate multiple provider switches in quick succession\n   - Verify final database state matches last selection\n   - Test simultaneous reads during provider switch",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-25T11:39:50.376Z"
      },
      {
        "id": "40",
        "title": "Extend agent_executor tool-calling to support all configured providers",
        "description": "Modify agent_executor.rs to support tool calling for all AI providers (OpenAI, Anthropic, etc.) beyond just Ollama, or restrict the UI to only show supported providers to prevent runtime errors.",
        "details": "Fix the limitation in src/dashboard/services/ai/agent_executor.rs line 189 where only 'ollama' provider is handled for tool calling:\n\n1. **Analyze current implementation**:\n   - Review the existing execute_with_tools() method that currently only supports Ollama\n   - Identify the tool-calling format differences between providers (Ollama uses custom format, OpenAI uses function calling, Anthropic uses tools API)\n   - Check how model configurations are loaded and which providers are configured\n\n2. **Implement provider-specific tool calling adapters**:\n   - Create a ToolCallingAdapter trait in agent_executor.rs with methods:\n     ```rust\n     trait ToolCallingAdapter {\n         fn format_tools(&self, tools: &[Tool]) -> Value;\n         fn parse_tool_calls(&self, response: &Value) -> Result<Vec<ToolCall>>;\n         fn format_tool_results(&self, results: &[ToolResult]) -> Value;\n     }\n     ```\n   - Implement OllamaToolAdapter (refactor existing code)\n   - Implement OpenAIToolAdapter for OpenAI function calling format\n   - Implement AnthropicToolAdapter for Anthropic tools API format\n   - Add placeholder adapters for other providers that return \"not supported\" error\n\n3. **Update AgentExecutor to use adapters**:\n   - Modify execute_with_tools() to select appropriate adapter based on provider:\n     ```rust\n     let adapter: Box<dyn ToolCallingAdapter> = match provider.as_str() {\n         \"ollama\" => Box::new(OllamaToolAdapter::new()),\n         \"openai\" => Box::new(OpenAIToolAdapter::new()),\n         \"anthropic\" => Box::new(AnthropicToolAdapter::new()),\n         _ => return Err(\"Unsupported tool-calling provider\")\n     };\n     ```\n   - Use adapter methods to format tools, parse responses, and format results\n   - Ensure error handling covers provider-specific edge cases\n\n4. **Add provider capability detection**:\n   - Create a supports_tool_calling() method in model configurations\n   - Add a tool_calling_capable boolean field to provider configs\n   - Update get_model_configurations tool to include this capability flag\n\n5. **Update UI/API to respect capabilities**:\n   - Modify the model selection endpoints to filter out non-tool-calling models when selecting tool-calling model\n   - Add validation in set_tool_calling_model to reject unsupported providers\n   - Return clear error messages when attempting to use unsupported providers\n\n6. **Handle provider-specific nuances**:\n   - OpenAI: Convert MCP tools to OpenAI function schema, handle function_call responses\n   - Anthropic: Format tools according to Anthropic's tool use format, parse tool_use blocks\n   - Add appropriate headers and API version parameters for each provider\n   - Handle streaming vs non-streaming responses appropriately",
        "testStrategy": "Verify multi-provider tool calling support with comprehensive testing:\n\n1. **Unit tests for tool adapters**:\n   - Test OllamaToolAdapter formats tools correctly and parses Ollama-style responses\n   - Test OpenAIToolAdapter converts MCP tools to OpenAI function schema\n   - Test AnthropicToolAdapter formats according to Anthropic tool use spec\n   - Verify error handling for malformed responses from each provider\n\n2. **Integration tests for AgentExecutor**:\n   - Mock responses from different providers and verify correct tool execution flow\n   - Test provider selection logic with various model configurations\n   - Verify fallback behavior for unsupported providers\n   - Test error propagation when provider returns unexpected format\n\n3. **End-to-end testing**:\n   - Test process_email_instructions with Ollama model (existing functionality)\n   - Test with OpenAI model configuration if available\n   - Test with Anthropic model configuration if available\n   - Verify UI correctly filters model selection based on capabilities\n\n4. **Manual testing scenarios**:\n   - Configure multiple providers in model_configurations\n   - Attempt to set each as tool-calling model via API\n   - Execute high-level tools and verify correct provider is used\n   - Confirm error messages are clear when selecting unsupported provider\n\n5. **Regression testing**:\n   - Ensure existing Ollama tool calling still works correctly\n   - Verify no breaking changes to high-level tool execution\n   - Test that email processing workflows continue to function",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-25T11:41:47.337Z"
      },
      {
        "id": "41",
        "title": "Extend email_drafter to support all configured providers",
        "description": "Modify email_drafter.rs to use the provider adapter abstraction consistently so any configured provider (not just Ollama and OpenAI) works for email drafting, preventing runtime errors when users select other providers in the UI.",
        "details": "Fix the provider limitation in src/dashboard/services/ai/email_drafter.rs where only 'ollama' and 'openai' providers are hardcoded:\n\n1. **Analyze current implementation**:\n   - Review the existing draft_reply() and draft_email() methods that currently only support Ollama and OpenAI\n   - Identify where provider-specific logic is hardcoded (likely in a match statement or if/else chain)\n   - Check how the provider adapter abstraction is used in other services (e.g., agent_executor.rs after Task 40)\n\n2. **Refactor to use provider adapter abstraction**:\n   ```rust\n   // Instead of hardcoding provider logic:\n   match provider_name.as_str() {\n       \"ollama\" => { /* Ollama-specific code */ }\n       \"openai\" => { /* OpenAI-specific code */ }\n       _ => return Err(\"Unsupported provider\")\n   }\n   \n   // Use the provider adapter pattern:\n   let provider = self.provider_manager.get_provider(&provider_name)?;\n   let response = provider.complete(CompletionRequest {\n       model: model_name,\n       messages: vec![\n           Message::system(\"You are an email drafting assistant...\"),\n           Message::user(&prompt)\n       ],\n       temperature: Some(0.7),\n       max_tokens: Some(1000),\n       stream: false,\n   }).await?;\n   ```\n\n3. **Update EmailDrafter struct**:\n   - Add provider_manager: Arc<ProviderManager> field\n   - Remove any provider-specific client fields (ollama_client, openai_client, etc.)\n   - Update the constructor to accept ProviderManager\n\n4. **Modify draft_reply() method**:\n   - Remove provider-specific branching logic\n   - Use provider_manager.get_provider() to get the appropriate adapter\n   - Build a unified CompletionRequest that works with all providers\n   - Handle the response uniformly regardless of provider\n\n5. **Modify draft_email() method**:\n   - Apply the same refactoring as draft_reply()\n   - Ensure consistent error handling across all providers\n\n6. **Update error handling**:\n   - Replace provider-specific error types with a generic error type\n   - Ensure meaningful error messages when a provider fails\n   - Add logging for debugging provider issues\n\n7. **Consider provider capabilities**:\n   - Some providers may have different token limits or features\n   - Use the provider adapter's capabilities to adjust request parameters\n   - Gracefully degrade functionality if a provider doesn't support certain features",
        "testStrategy": "Verify multi-provider email drafting support with comprehensive testing:\n\n1. **Unit tests for EmailDrafter**:\n   - Mock ProviderManager to return different provider adapters\n   - Test draft_reply() with mocked Ollama, OpenAI, Anthropic, LM Studio, and llama.cpp providers\n   - Test draft_email() with all supported providers\n   - Verify error handling when provider_manager.get_provider() fails\n   - Test with providers that have different capabilities/limitations\n\n2. **Integration tests with real providers**:\n   - Set up test configurations for multiple providers in ai_model_configurations\n   - Test actual email drafting with each configured provider\n   - Verify response quality and format consistency across providers\n   - Test error scenarios (invalid API keys, network failures, etc.)\n\n3. **Manual testing through UI**:\n   - Configure multiple providers in the system\n   - Select each provider in the Email Assistant UI\n   - Draft replies and new emails with each provider\n   - Verify no runtime errors occur regardless of selected provider\n   - Test switching between providers during a session\n\n4. **Performance testing**:\n   - Compare response times across different providers\n   - Ensure no performance regression from the refactoring\n   - Test concurrent drafting requests with different providers\n\n5. **Regression testing**:\n   - Ensure Ollama and OpenAI (previously working providers) still function correctly\n   - Verify email quality hasn't degraded with the abstraction\n   - Test edge cases like very long emails or special formatting",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-25T11:43:26.799Z"
      },
      {
        "id": "42",
        "title": "Add integration tests for AI subsystem configuration",
        "description": "Create comprehensive integration tests that verify sampler configuration persistence, provider functionality, and model selection across service restarts to prevent configuration-related bugs.",
        "details": "Create integration tests in tests/ai_configuration_integration.rs that verify the entire AI configuration subsystem works correctly:\n\n1. **Test Sampler Settings Application**:\n   ```rust\n   #[tokio::test]\n   async fn test_sampler_config_applied_to_requests() {\n       // Setup test database with custom sampler config\n       let sampler_config = SamplerConfig {\n           provider: \"ollama\",\n           model_name: \"llama3.3:70b\",\n           temperature: 0.3,\n           top_p: 0.95,\n           min_p: 0.05,\n           repeat_penalty: 1.2,\n           num_ctx: 4096,\n           // ... other settings\n       };\n       \n       // Save to database\n       sampler_service.upsert_config(sampler_config).await?;\n       \n       // Create mock Ollama server that captures requests\n       let mock_server = MockServer::start().await;\n       Mock::given(method(\"POST\"))\n           .and(path(\"/api/chat\"))\n           .respond_with(ResponseTemplate::new(200)\n               .set_body_json(json!({\"response\": \"test\"})))\n           .mount(&mock_server)\n           .await;\n       \n       // Make AI request through the system\n       let ai_service = create_ai_service_with_url(&mock_server.uri());\n       ai_service.complete(/* request */).await?;\n       \n       // Verify the request included our sampler settings\n       let received_requests = mock_server.received_requests().await;\n       let request_body: Value = serde_json::from_slice(&received_requests[0].body)?;\n       \n       assert_eq!(request_body[\"temperature\"], 0.3);\n       assert_eq!(request_body[\"top_p\"], 0.95);\n       assert_eq!(request_body[\"min_p\"], 0.05);\n       assert_eq!(request_body[\"repeat_penalty\"], 1.2);\n       assert_eq!(request_body[\"num_ctx\"], 4096);\n   }\n   ```\n\n2. **Test All Providers Can Process Requests**:\n   ```rust\n   #[tokio::test]\n   async fn test_all_ui_providers_functional() {\n       // Get list of providers shown in UI\n       let ui_providers = vec![\"ollama\", \"llamacpp\", \"lmstudio\", \"openai\", \"anthropic\"];\n       \n       for provider in ui_providers {\n           // Configure model for this provider\n           let model_config = ModelConfiguration {\n               role: \"tool_calling\",\n               provider: provider.to_string(),\n               model_name: get_test_model_for_provider(provider),\n               // ...\n           };\n           \n           model_service.set_model_config(model_config).await?;\n           \n           // Create mock server for provider\n           let mock = create_provider_mock(provider).await;\n           \n           // Attempt to make a request\n           let result = ai_service.complete(CompletionRequest {\n               prompt: \"Test prompt\",\n               // ...\n           }).await;\n           \n           // Verify request was successful\n           assert!(result.is_ok(), \"Provider {} failed to process request: {:?}\", \n                   provider, result.err());\n           \n           // Verify correct endpoint was called\n           mock.assert();\n       }\n   }\n   ```\n\n3. **Test Configuration Persistence Across Restarts**:\n   ```rust\n   #[tokio::test]\n   async fn test_config_persists_across_service_restart() {\n       // Set up initial configurations\n       let tool_model = ModelConfiguration {\n           role: \"tool_calling\",\n           provider: \"ollama\",\n           model_name: \"qwen2.5:7b\",\n       };\n       let draft_model = ModelConfiguration {\n           role: \"drafting\", \n           provider: \"lmstudio\",\n           model_name: \"llama3.3:70b\",\n       };\n       \n       // Save configurations\n       model_service.set_model_config(tool_model.clone()).await?;\n       model_service.set_model_config(draft_model.clone()).await?;\n       \n       // Save sampler configs\n       let sampler_config = SamplerConfig {\n           provider: \"ollama\",\n           model_name: \"qwen2.5:7b\",\n           temperature: 0.5,\n           think_mode: true,\n           // ...\n       };\n       sampler_service.upsert_config(sampler_config.clone()).await?;\n       \n       // Simulate service restart by dropping and recreating services\n       drop(model_service);\n       drop(sampler_service);\n       drop(ai_service);\n       \n       // Recreate services (simulating restart)\n       let model_service = ModelConfigService::new(db_pool.clone());\n       let sampler_service = SamplerConfigService::new(db_pool.clone());\n       let ai_service = create_ai_service(model_service.clone(), sampler_service.clone());\n       \n       // Verify configurations are still present\n       let loaded_tool_model = model_service.get_model_config(\"tool_calling\").await?;\n       assert_eq!(loaded_tool_model.provider, \"ollama\");\n       assert_eq!(loaded_tool_model.model_name, \"qwen2.5:7b\");\n       \n       let loaded_draft_model = model_service.get_model_config(\"drafting\").await?;\n       assert_eq!(loaded_draft_model.provider, \"lmstudio\");\n       assert_eq!(loaded_draft_model.model_name, \"llama3.3:70b\");\n       \n       let loaded_sampler = sampler_service.get_config(\"ollama\", \"qwen2.5:7b\").await?;\n       assert_eq!(loaded_sampler.temperature, 0.5);\n       assert_eq!(loaded_sampler.think_mode, true);\n   }\n   ```\n\n4. **Test Model Selection Respected in AI Calls**:\n   ```rust\n   #[tokio::test]\n   async fn test_model_selection_respected() {\n       // Configure specific models for each role\n       model_service.set_model_config(ModelConfiguration {\n           role: \"tool_calling\",\n           provider: \"ollama\",\n           model_name: \"mistral:7b\",\n       }).await?;\n       \n       model_service.set_model_config(ModelConfiguration {\n           role: \"drafting\",\n           provider: \"ollama\", \n           model_name: \"llama3.3:70b\",\n       }).await?;\n       \n       // Set up mocks that verify correct model is used\n       let tool_mock = Mock::given(method(\"POST\"))\n           .and(path(\"/api/chat\"))\n           .and(body_json_schema(json!({\n               \"model\": {\"const\": \"mistral:7b\"}\n           })))\n           .respond_with(ResponseTemplate::new(200))\n           .expect(1)\n           .mount(&mock_server)\n           .await;\n       \n       let draft_mock = Mock::given(method(\"POST\"))\n           .and(path(\"/api/chat\"))\n           .and(body_json_schema(json!({\n               \"model\": {\"const\": \"llama3.3:70b\"}\n           })))\n           .respond_with(ResponseTemplate::new(200))\n           .expect(1)\n           .mount(&mock_server)\n           .await;\n       \n       // Make tool calling request\n       tool_executor.execute(\"List my emails\").await?;\n       \n       // Make drafting request\n       email_drafter.draft_email(\"Write a test email\").await?;\n       \n       // Mocks will verify correct models were used\n   }\n   ```\n\n5. **Test Edge Cases and Error Scenarios**:\n   ```rust\n   #[tokio::test]\n   async fn test_missing_provider_configuration() {\n       // Remove all configurations\n       sqlx::query!(\"DELETE FROM ai_model_configurations\").execute(&db_pool).await?;\n       \n       // Attempt to use AI service - should use defaults or fail gracefully\n       let result = ai_service.complete(/* request */).await;\n       \n       // Verify appropriate error or default behavior\n       match result {\n           Ok(_) => {\n               // Should have used default configuration\n               let config = model_service.get_model_config(\"tool_calling\").await?;\n               assert_eq!(config.model_name, \"qwen2.5:7b\"); // Default from migration\n           },\n           Err(e) => {\n               // Should be a clear configuration error\n               assert!(e.to_string().contains(\"configuration\"));\n           }\n       }\n   }\n   ```\n\n6. **Test MCP Tool Integration**:\n   ```rust\n   #[tokio::test]\n   async fn test_mcp_tools_use_configured_models() {\n       // Configure models via MCP tools\n       let set_tool_result = mcp_handler.handle_tool_call(\n           \"set_tool_calling_model\",\n           json!({\"provider\": \"ollama\", \"model\": \"qwen2.5:7b\"})\n       ).await?;\n       \n       let set_draft_result = mcp_handler.handle_tool_call(\n           \"set_drafting_model\",\n           json!({\"provider\": \"lmstudio\", \"model\": \"llama3.3:70b\"})\n       ).await?;\n       \n       // Verify configurations were saved\n       let get_config_result = mcp_handler.handle_tool_call(\n           \"get_model_configurations\",\n           json!({})\n       ).await?;\n       \n       let configs: Vec<ModelConfiguration> = serde_json::from_value(get_config_result)?;\n       assert_eq!(configs.len(), 2);\n       \n       // Process email with configured models\n       let process_result = mcp_handler.handle_tool_call(\n           \"process_email_instructions\",\n           json!({\"instruction\": \"Reply to the latest email\"})\n       ).await?;\n       \n       // Verify correct models were used (check mock server logs)\n   }\n   ```",
        "testStrategy": "Run the integration test suite with the following verification steps:\n\n1. **Environment Setup**:\n   - Create a test database with all migrations applied\n   - Set up mock servers for each AI provider (Ollama, LM Studio, etc.)\n   - Configure test-specific environment variables for provider URLs\n\n2. **Run Individual Test Categories**:\n   ```bash\n   # Test sampler configuration application\n   cargo test test_sampler_config_applied_to_requests -- --nocapture\n   \n   # Test all providers\n   cargo test test_all_ui_providers_functional -- --nocapture\n   \n   # Test persistence\n   cargo test test_config_persists_across_service_restart -- --nocapture\n   \n   # Test model selection\n   cargo test test_model_selection_respected -- --nocapture\n   ```\n\n3. **Verify Mock Server Interactions**:\n   - Check that each test's mock server received the expected requests\n   - Verify request bodies contain correct model names and sampler parameters\n   - Ensure no unexpected API calls were made\n\n4. **Database State Verification**:\n   - After each test, query the database to verify configurations are correctly stored\n   - Check both ai_model_configurations and ai_sampler_configs tables\n   - Verify foreign key constraints are maintained\n\n5. **Error Scenario Testing**:\n   - Disconnect mock servers to test connection failures\n   - Corrupt database entries to test validation\n   - Remove configurations to test default fallbacks\n\n6. **Performance Testing**:\n   - Run tests with timing to ensure configuration lookups don't add significant latency\n   - Test with multiple concurrent requests to verify thread safety\n\n7. **Full Integration Test**:\n   ```bash\n   cargo test --test ai_configuration_integration -- --test-threads=1\n   ```\n   Run all tests sequentially to avoid database conflicts",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-01-25T11:45:53.552Z"
      },
      {
        "id": "43",
        "title": "Add Microsoft OAuth2 Environment Configuration",
        "description": "Implement R1: Add environment variables for Microsoft OAuth2 app registration and load them at startup",
        "details": "Add to `.env.example`:\n\n```\nMICROSOFT_CLIENT_ID=your_azure_app_client_id\nMICROSOFT_CLIENT_SECRET=your_azure_app_client_secret\nOAUTH_REDIRECT_BASE_URL=http://localhost:9780\n```\n\nIn `src/dashboard/config.rs`, use `config::Config` or `dotenvy` (v0.15) to load vars. Create `MicrosoftOAuthConfig` struct:\n\n```rust\n#[derive(Clone, Debug)]\npub struct MicrosoftOAuthConfig {\n    pub client_id: String,\n    pub client_secret: String,\n    pub redirect_base_url: String,\n    pub auth_url: &'static str,\n    pub token_url: &'static str,\n    pub scopes: Vec<String>,\n}\n\nimpl MicrosoftOAuthConfig {\n    pub fn new() -> Result<Self> {\n        Ok(Self {\n            client_id: env::var(\"MICROSOFT_CLIENT_ID\")?,\n            client_secret: env::var(\"MICROSOFT_CLIENT_SECRET\")?,\n            redirect_base_url: env::var(\"OAUTH_REDIRECT_BASE_URL\")?,\n            auth_url: \"https://login.microsoftonline.com/common/oauth2/v2.0/authorize\",\n            token_url: \"https://login.microsoftonline.com/common/oauth2/v2.0/token\",\n            scopes: vec![\n                \"https://outlook.office365.com/IMAP.AccessAsUser.All\".to_string(),\n                \"https://outlook.office365.com/SMTP.Send\".to_string(),\n                \"offline_access\".to_string(),\n            ],\n        })\n    }\n}\n```",
        "testStrategy": "Unit test config loading with mock env vars, verify scopes contain exact 3 required strings, test missing vars return proper errors",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-10T20:04:58.377Z"
      },
      {
        "id": "44",
        "title": "Create OAuth2 Service with PKCE Support",
        "description": "Implement R2: Create Rust service for OAuth2 authorization code flow with PKCE using oauth2 crate v4.4",
        "details": "Add to Cargo.toml: `oauth2 = \"4.4\"`, `rand = \"0.8\"`, `sha2 = \"0.10\"`, `base64 = \"0.21\"`\n\nCreate `src/dashboard/services/oauth_microsoft.rs`:\n\n```rust\nuse oauth2::{\n    AuthorizationCode, AuthUrl, ClientId, ClientSecret, CodeChallenge, CodeVerifier,\n    PkceCodeChallenge, RedirectUrl, Scope, TokenResponse, TokenUrl,\n};\nuse oauth2::basic::BasicClient;\nuse oauth2::reqwest::http::Request;\n\npub struct MicrosoftOAuthService {\n    client: BasicClient,\n}\n\nimpl MicrosoftOAuthService {\n    pub fn new(config: MicrosoftOAuthConfig) -> Self {\n        let client = BasicClient::new(\n            ClientId::new(config.client_id),\n            Some(ClientSecret::new(config.client_secret)),\n        )\n        .set_auth_uri(AuthUrl::new(config.auth_url.to_string()).unwrap())\n        .set_token_uri(TokenUrl::new(config.token_url.to_string()).unwrap())\n        .set_redirect_uri(\n            RedirectUrl::new(format!(\"{}/api/oauth/callback/microsoft\", config.redirect_base_url)).unwrap(),\n        );\n        Self { client }\n    }\n\n    pub fn authorize_url(&self, state: impl AsRef<str>) -> String {\n        let (pkce_challenge, pkce_verifier) = PkceCodeChallenge::new_random_sha256();\n        // Store pkce_verifier in session/redis with state\n        self.client\n            .authorize_url(AuthorizationCode::new(\"\".to_string()))\n            .add_extra_params(&[(\"state\", state.as_ref())])\n            .set_pkce_challenge(pkce_challenge)\n            .url().to_string()\n    }\n}\n```",
        "testStrategy": "Mock HTTP client, test authorize_url generates correct URL with PKCE challenge and required scopes, verify state parameter inclusion",
        "priority": "high",
        "dependencies": [
          "43"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-10T20:08:19.928Z"
      },
      {
        "id": "45",
        "title": "Implement OAuth2 API Endpoints",
        "description": "Implement R3: Add REST API endpoints for Microsoft OAuth authorize and callback",
        "details": "In `src/dashboard/api/oauth.rs`:\n\n```rust\n#[get(\"/api/oauth/microsoft/authorize?state=<state>\")]\npub async fn microsoft_authorize(\n    state: String,\n    oauth_service: web::Data<MicrosoftOAuthService>,\n) -> impl Responder {\n    let auth_url = oauth_service.authorize_url(&state);\n    HttpResponse::Ok().json(AuthUrlResponse { url: auth_url })\n}\n\n#[get(\"/api/oauth/callback/microsoft?code={code}&state={state}\")]\npub async fn microsoft_callback(\n    code: String,\n    state: String,\n    oauth_service: web::Data<MicrosoftOAuthService>,\n    account_store: web::Data<AccountStore>,\n) -> impl Responder {\n    let token_result = oauth_service\n        .exchange_code(AuthorizationCode::new(code))\n        .set_pkce_verifier(get_pkce_verifier(state)) // from session\n        .request_async(async_http_client).await;\n    // Encrypt and store tokens using existing encryption service\n    // Create/update account with oauth_provider = \"microsoft\"\n    HttpResponse::Ok().json(\"Account linked successfully\")\n}\n```",
        "testStrategy": "Integration tests with wiremock for OAuth endpoints, test auth URL generation, test token exchange with mock token response, verify account creation",
        "priority": "high",
        "dependencies": [
          "44"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-10T20:09:49.863Z"
      },
      {
        "id": "46",
        "title": "Implement XOAUTH2 Token Formatter and Refresh Logic",
        "description": "Implement R4,R5,R6: Create XOAUTH2 token formatter and automatic token refresh service",
        "details": "Create `src/dashboard/services/xoauth2.rs`:\n\n```rust\npub fn generate_xoauth2_token(email: &str, access_token: &str) -> String {\n    let token = format!(\"user={}\\x01auth=Bearer {}\\x01\\x01\", email, access_token);\n    base64::encode(token.as_bytes())\n}\n\npub async fn refresh_token_if_needed(\n    account: &mut Account,\n    oauth_service: &MicrosoftOAuthService,\n    encryption: &EncryptionService,\n) -> Result<bool> {\n    let expiry = account.oauth_token_expiry;\n    if expiry > Utc::now() + Duration::minutes(5) {\n        return Ok(false); // No refresh needed\n    }\n    let refresh_token = encryption.decrypt(&account.oauth_refresh_token)?;\n    let new_token = oauth_service\n        .refresh_token(&RefreshToken::new(refresh_token))\n        .request_async(async_http_client)\n        .await?;\n    account.oauth_access_token = encryption.encrypt(&new_token.access_token().secret())?;\n    account.oauth_refresh_token = encryption.encrypt(&new_token.refresh_token().unwrap().secret())?;\n    account.oauth_token_expiry = Utc::now() + Duration::seconds(new_token.expires_in().unwrap_or(3600) as i64);\n    account_store.update(account).await?;\n    Ok(true)\n}\n```",
        "testStrategy": "Unit tests for XOAUTH2 format (verify exact byte sequence), test refresh logic with mock token responses, test expiry threshold (5min buffer)",
        "priority": "high",
        "dependencies": [
          "44",
          "45"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-10T20:19:05.089Z"
      },
      {
        "id": "47",
        "title": "Update IMAP Client for XOAUTH2 Authentication",
        "description": "Implement R4: Modify async-imap client to use XOAUTH2 for Microsoft accounts",
        "details": "In IMAP connection logic (`src/dashboard/services/imap.rs`):\n\n```rust\npub async fn connect_imap(account: &mut Account, config: &Config) -> Result<ImapStream> {\n    let mut imap = async_imap::connect(config.imap_server, Office365ImapStream::new()).await?;\n    imap.login(\"\", \"\").await.map_err(|_| anyhow::anyhow!(\"Skip login\"))?;\n    \n    if account.oauth_provider == Some(\"microsoft\".to_string()) {\n        refresh_token_if_needed(account, &oauth_service, &encryption).await?;\n        let access_token = encryption.decrypt(&account.oauth_access_token)?;\n        let xoauth2_token = generate_xoauth2_token(&account.email, &access_token);\n        imap.authenticate(\"XOAUTH2\", xoauth2_token.as_bytes()).await?;\n    } else {\n        imap.login(&account.email, &account.imap_password).await?;\n    }\n    Ok(imap)\n}\n```",
        "testStrategy": "Integration test with imap test server (greenmail/docker), verify XOAUTH2 auth succeeds for microsoft accounts, test token refresh trigger",
        "priority": "high",
        "dependencies": [
          "46"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-10T20:15:59.498Z"
      },
      {
        "id": "48",
        "title": "Update SMTP Client for XOAUTH2 Authentication",
        "description": "Implement R5: Modify lettre SMTP client to use XOAUTH2 for Microsoft accounts",
        "details": "In SMTP logic (`src/dashboard/services/smtp.rs`):\n\n```rust\nuse lettre::transport::smtp::authentication::Xoauth2;\n\npub async fn create_smtp_transport(account: &mut Account) -> Result<SmtpTransport> {\n    if account.oauth_provider == Some(\"microsoft\".to_string()) {\n        refresh_token_if_needed(account, &oauth_service, &encryption).await?;\n        let access_token = encryption.decrypt(&account.oauth_access_token)?;\n        let xoauth2_token = generate_xoauth2_token(&account.email, &access_token);\n        \n        let auth = Xoauth2::new(account.email.clone(), access_token);\n        let transport = SmtpTransport::starttls_relay(&config.smtp_server)\n            ?.credentials(auth)\n            .port(587)\n            .build();\n        Ok(transport)\n    } else {\n        // Existing password auth\n    }\n}\n```",
        "testStrategy": "Integration test with smtp test server, verify XOAUTH2 SMTP auth succeeds, test with expired tokens triggers refresh",
        "priority": "high",
        "dependencies": [
          "46",
          "47"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-10T20:19:05.564Z"
      },
      {
        "id": "49",
        "title": "Update Account Store for OAuth Fields",
        "description": "Implement R8: Extend StoredAccount struct and account_store.rs for OAuth support",
        "details": "Update `src/dashboard/services/account_store.rs`:\n\n```rust\n#[derive(Serialize, Deserialize)]\npub struct StoredAccount {\n    // existing fields...\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub oauth_provider: Option<String>,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub oauth_access_token: Option<String>, // encrypted\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub oauth_refresh_token: Option<String>, // encrypted\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    pub oauth_token_expiry: Option<DateTime<Utc>>,\n}\n\nimpl AccountStore {\n    pub async fn sync_oauth_account(&self, account: &Account) -> Result<()> {\n        let stored = self.load().await?;\n        if let Some(mut stored_acc) = stored.accounts.iter_mut()\n            .find(|a| a.email == account.email) {\n            stored_acc.oauth_provider = account.oauth_provider.clone();\n            // sync other oauth fields\n            self.save(&stored).await?;\n        }\n    }\n}\n```",
        "testStrategy": "Unit tests for JSON serialization of OAuth fields, test file sync preserves encrypted tokens, test missing fields handled gracefully",
        "priority": "medium",
        "dependencies": [
          "45"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-10T20:13:49.993Z"
      },
      {
        "id": "50",
        "title": "Implement Frontend Microsoft OAuth UI",
        "description": "Implement R7: Add OAuth button and UI updates to Svelte WebUI",
        "details": "In `webui/src/routes/accounts/+page.svelte`:\n\n```svelte\n<script>\n    let authUrl = '';\n    async function getMicrosoftAuthUrl() {\n        const response = await fetch('/api/oauth/microsoft/authorize?state=' + crypto.randomUUID());\n        const data = await response.json();\n        authUrl = data.url;\n        window.location.href = authUrl;\n    }\n</script>\n\n<button class=\"microsoft-oauth-btn\" on:click={getMicrosoftAuthUrl}>\n     Sign in with Microsoft\n</button>\n\n{#if account.oauth_provider === 'microsoft'}\n    <div class=\"oauth-badge\">Microsoft OAuth </div>\n    <button class=\"re-auth-btn\">Re-authorize (tokens expired)</button>\n{/if}\n\n<style>\n    .microsoft-oauth-btn { background: #0078D4; color: white; }\n</style>\n```",
        "testStrategy": "Cypress/Playwright E2E tests: click OAuth button redirects to Microsoft, callback returns to accounts page with new account, verify badge display",
        "priority": "medium",
        "dependencies": [
          "45"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-10T20:46:34.498Z"
      },
      {
        "id": "51",
        "title": "Add Comprehensive OAuth Unit Tests",
        "description": "Implement R9: Add unit tests for all OAuth2 functionality",
        "details": "Create `tests/oauth_tests.rs`:\n\n```rust\n#[tokio::test]\nasync fn test_oauth_url_generation() {\n    let service = MicrosoftOAuthService::new(config);\n    let url = service.authorize_url(\"test-state\");\n    assert!(url.contains(\"scope=https%3A%2F%2Foutlook.office365.com%2FIMAP.AccessAsUser.All\"));\n    assert!(url.contains(\"code_challenge_method=S256\"));\n}\n\n#[tokio::test]\nasync fn test_xoauth2_format() {\n    let token = generate_xoauth2_token(\"test@example.com\", \"abc123\");\n    assert_eq!(token, \"dXNlcj10ZXN0QGV4YW1wbGUuY29tAHB1dGg9QmVhcmVyIGFiYzEyMAA=\");\n}\n\n#[tokio::test]\nasync fn test_token_refresh() {\n    // Mock expired token, verify refresh called\n}\n```",
        "testStrategy": "Run full test suite: verify 100% coverage on oauth_service.rs, xoauth2.rs, test edge cases (expired refresh tokens, network failures)",
        "priority": "medium",
        "dependencies": [
          "46",
          "47",
          "48",
          "49"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-10T20:24:52.724Z"
      },
      {
        "id": "52",
        "title": "Fix Read/Unread Flag Synchronization",
        "description": "Fix the critical bug where all emails are marked as 'Seen' despite being unread on the server. Ensure proper IMAP flag synchronization using BODY.PEEK[] to avoid marking emails as read during fetch.",
        "details": "1. Modify IMAP fetch commands to use BODY.PEEK[] instead of BODY[] to prevent marking emails as read during sync:\n```rust\n// In sync module\nlet fetch_command = format!(\"{}:{} (FLAGS BODY.PEEK[])\", start_uid, end_uid);\n```\n2. Update flag parsing logic to correctly read \\Seen flag from server response\n3. Implement proper flag storage in cache database with deduplication\n4. Add unit tests to verify flags are preserved during sync\n5. Update get_folder_stats to correctly count unread emails based on absence of \\Seen flag",
        "testStrategy": "1. Create test IMAP account with known read/unread email counts\n2. Run sync and verify unread count matches server state\n3. Verify emails remain unread on server after sync\n4. Test get_folder_stats returns accurate unread counts\n5. Regression test to ensure no duplicate flags in arrays",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-12T12:09:20.096Z"
      },
      {
        "id": "53",
        "title": "Enable Multi-Folder Synchronization",
        "description": "Extend the email synchronization system to support caching of subfolders beyond just INBOX, including critical folders like INBOX/resumes, Sent Items, and INBOX/Contracts.",
        "details": "1. Add folder configuration to sync settings:\n```rust\nstruct SyncConfig {\n    folders_to_sync: Vec<String>, // e.g., [\"INBOX\", \"INBOX/resumes\", \"Sent Items\"]\n    sync_all_folders: bool,\n}\n```\n2. Modify sync_account function to iterate through configured folders\n3. Update database schema to properly handle folder hierarchy\n4. Add sync_folder(account_id, folder_name) API endpoint\n5. Implement folder sync status tracking\n6. Add UI controls for folder selection in admin panel",
        "testStrategy": "1. Test syncing individual subfolders via API\n2. Verify folder hierarchy is preserved in cache\n3. Test sync_all_folders option syncs entire folder tree\n4. Verify get_folder_stats works for all synced folders\n5. Performance test with large folder structures (50+ folders)",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-12T12:18:17.743Z"
      },
      {
        "id": "54",
        "title": "Fix Attachment Detection and Metadata Parsing",
        "description": "Resolve the has_attachments flag inconsistency and implement proper MIME part parsing to accurately detect and store attachment metadata during email synchronization.",
        "details": "1. Implement robust MIME parser using mail-parser crate:\n```rust\nuse mail_parser::{Message, MimeHeaders};\n\nfn parse_attachments(raw_email: &[u8]) -> Vec<AttachmentMetadata> {\n    let message = Message::parse(raw_email).unwrap();\n    let mut attachments = Vec::new();\n    \n    for part in message.parts() {\n        if part.is_attachment() {\n            attachments.push(AttachmentMetadata {\n                filename: part.attachment_name().unwrap_or(\"unnamed\").to_string(),\n                mime_type: part.content_type().unwrap_or(\"application/octet-stream\"),\n                size: part.len(),\n                part_id: part.part_id(),\n            });\n        }\n    }\n    attachments\n}\n```\n2. Update database schema to store attachment metadata\n3. Fix has_attachments flag calculation\n4. Ensure consistency across all API endpoints",
        "testStrategy": "1. Test with emails containing various attachment types (PDF, images, documents)\n2. Verify has_attachments flag is consistent across list_cached_emails and get_email_by_uid\n3. Test inline vs attached content distinction\n4. Verify attachment metadata is correctly stored and retrieved\n5. Test with multipart/mixed and multipart/alternative messages",
        "priority": "high",
        "dependencies": [
          "52"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-12T12:22:29.670Z"
      },
      {
        "id": "55",
        "title": "Implement Attachment Metadata API Endpoints",
        "description": "Create new API endpoints to expose attachment metadata including filenames, MIME types, sizes, and enable filtering emails by attachment type.",
        "details": "1. Implement get_attachment_metadata endpoint:\n```rust\n#[derive(Serialize)]\nstruct AttachmentInfo {\n    attachment_id: String,\n    filename: String,\n    mime_type: String,\n    size: u64,\n}\n\nasync fn get_attachment_metadata(uid: u64, folder: String) -> Vec<AttachmentInfo>\n```\n2. Implement search_emails_by_attachment endpoint with MIME type filtering:\n```rust\nasync fn search_emails_by_attachment(\n    mime_types: Vec<String>, // e.g., [\"image/*\", \"application/pdf\"]\n    folder: String,\n    limit: Option<usize>\n) -> Vec<EmailSummary>\n```\n3. Add attachment count and total size to email responses\n4. Implement wildcard MIME type matching (e.g., image/*)",
        "testStrategy": "1. Test get_attachment_metadata returns correct data for emails with multiple attachments\n2. Verify MIME type filtering works with wildcards\n3. Test performance with large attachment queries\n4. Verify empty results for emails without attachments\n5. Test edge cases like emails with 50+ attachments",
        "priority": "medium",
        "dependencies": [
          "54"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-12T12:29:17.577Z"
      },
      {
        "id": "56",
        "title": "Add Flag-Based Email Filtering",
        "description": "Implement filtering capabilities for emails based on IMAP flags (Seen/Unseen, Flagged, etc.) to support unread email workflows and other flag-based queries.",
        "details": "1. Add flag filter parameters to list_cached_emails:\n```rust\npub struct EmailFilter {\n    flags_include: Option<Vec<String>>, // Must have these flags\n    flags_exclude: Option<Vec<String>>, // Must not have these flags\n    unread_only: Option<bool>, // Shorthand for excluding \\Seen\n}\n```\n2. Implement list_emails_by_flag endpoint:\n```rust\nasync fn list_emails_by_flag(\n    flag: String, // e.g., \"Seen\", \"Flagged\", \"Answered\"\n    include: bool, // true = has flag, false = doesn't have flag\n    folder: String,\n    limit: Option<usize>\n) -> Vec<EmailSummary>\n```\n3. Add database indexes on flags for performance\n4. Support standard IMAP flags: \\Seen, \\Answered, \\Flagged, \\Deleted, \\Draft",
        "testStrategy": "1. Test filtering unread emails (no \\Seen flag)\n2. Verify multiple flag combinations work correctly\n3. Test performance with large datasets\n4. Verify flag exclusion logic\n5. Test with custom flags if supported by server",
        "priority": "medium",
        "dependencies": [
          "52"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-12T12:34:53.161Z"
      },
      {
        "id": "57",
        "title": "Expose Email Thread Headers and Implement Thread Grouping",
        "description": "Add support for email threading by exposing In-Reply-To and References headers, and implement thread grouping functionality for conversation tracking.",
        "details": "1. Update email parsing to extract thread headers:\n```rust\nstruct EmailHeaders {\n    message_id: String,\n    in_reply_to: Option<String>,\n    references: Option<Vec<String>>,\n}\n```\n2. Implement thread ID calculation algorithm:\n```rust\nfn calculate_thread_id(headers: &EmailHeaders) -> String {\n    // Use oldest message-id in References chain, or current message-id\n    if let Some(refs) = &headers.references {\n        refs.first().unwrap_or(&headers.message_id).clone()\n    } else {\n        headers.in_reply_to.as_ref().unwrap_or(&headers.message_id).clone()\n    }\n}\n```\n3. Add get_email_thread endpoint to retrieve full conversation\n4. Update database schema to store thread relationships\n5. Implement thread-aware search",
        "testStrategy": "1. Test with known email threads to verify correct grouping\n2. Test thread calculation with various header combinations\n3. Verify orphaned emails get their own thread ID\n4. Test performance of thread queries\n5. Verify thread ordering is chronological",
        "priority": "medium",
        "dependencies": [
          "53"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-12T12:46:34.605Z"
      },
      {
        "id": "58",
        "title": "Implement Domain-Based Search and Address Aggregation",
        "description": "Create functionality to search emails by sender/recipient domain and generate aggregated reports of email addresses and domains for analytics.",
        "details": "1. Implement domain extraction and indexing:\n```rust\nfn extract_domain(email: &str) -> Option<String> {\n    email.split('@').nth(1).map(|d| d.to_lowercase())\n}\n```\n2. Add search_by_domain endpoint:\n```rust\nasync fn search_by_domain(\n    domain: String,\n    search_in: Vec<String>, // [\"from\", \"to\", \"cc\"]\n    folder: String\n) -> Vec<EmailSummary>\n```\n3. Implement get_email_address_report:\n```rust\n#[derive(Serialize)]\nstruct AddressReport {\n    unique_addresses: Vec<AddressCount>,\n    unique_domains: Vec<DomainCount>,\n    total_addresses: usize,\n}\n```\n4. Add database indexes on email domains\n5. Implement batch processing for large folders",
        "testStrategy": "1. Test domain extraction with various email formats\n2. Verify domain search is case-insensitive\n3. Test aggregation report accuracy\n4. Performance test with 20k+ emails\n5. Test with international domains",
        "priority": "medium",
        "dependencies": [
          "53"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-12T12:50:16.012Z"
      },
      {
        "id": "59",
        "title": "Implement Attachment Download Functionality",
        "description": "Add capability to download email attachments by implementing secure attachment retrieval with proper access controls and content delivery.",
        "details": "1. Implement download_attachment endpoint:\n```rust\nasync fn download_attachment(\n    uid: u64,\n    attachment_id: String,\n    folder: String,\n    account_id: String\n) -> Result<AttachmentData, Error> {\n    // Verify user has access to account\n    // Fetch email from cache or IMAP\n    // Extract specific MIME part\n    // Return base64 encoded content or file stream\n}\n```\n2. Add attachment caching strategy:\n```rust\nstruct AttachmentCache {\n    max_size_mb: u64,\n    ttl_seconds: u64,\n}\n```\n3. Implement streaming for large attachments\n4. Add virus scanning integration point\n5. Support both base64 and direct file download",
        "testStrategy": "1. Test downloading various file types\n2. Verify access control prevents unauthorized downloads\n3. Test with large attachments (>10MB)\n4. Verify content integrity with checksums\n5. Test cache hit/miss scenarios",
        "priority": "low",
        "dependencies": [
          "55"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-12T12:54:25.356Z"
      },
      {
        "id": "60",
        "title": "Fix OAuth Redirect UX Issue",
        "description": "Resolve the UI bug where successful OAuth authentication redirects to a raw JSON response instead of returning to the RustyMail interface.",
        "details": "1. Modify OAuth callback handler to redirect to UI:\n```rust\nasync fn oauth_callback(query: OAuthResponse) -> impl Responder {\n    // Process OAuth response\n    let result = process_oauth_token(query).await;\n    \n    // Redirect to UI with status\n    if result.success {\n        HttpResponse::Found()\n            .header(\"Location\", \"/accounts?oauth=success&email={}\", result.email)\n            .finish()\n    } else {\n        HttpResponse::Found()\n            .header(\"Location\", \"/accounts?oauth=failed&error={}\", result.error)\n            .finish()\n    }\n}\n```\n2. Update frontend to handle OAuth status parameters\n3. Add success/error toast notifications\n4. Implement proper error handling for OAuth failures",
        "testStrategy": "1. Test successful OAuth flow returns to UI\n2. Test failed OAuth shows appropriate error\n3. Verify no sensitive data in URL parameters\n4. Test with multiple OAuth providers\n5. Verify browser back button behavior",
        "priority": "low",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-12T12:00:33.516Z"
      },
      {
        "id": "61",
        "title": "Implement Email Synopsis Generation API",
        "description": "Create an API endpoint that generates concise 3-5 line summaries of emails, particularly useful for unread email overviews and quick scanning.",
        "details": "1. Implement get_email_synopsis endpoint:\n```rust\nasync fn get_email_synopsis(\n    uid: u64,\n    folder: String,\n    max_lines: Option<usize>, // Default: 3\n    use_ai: Option<bool> // Use AI or simple extraction\n) -> Synopsis {\n    if use_ai {\n        // Integration with LLM API\n        let prompt = format!(\"Summarize in {} lines: {}\", max_lines, email_body);\n        call_llm_api(prompt).await\n    } else {\n        // Simple extraction: subject + first N sentences\n        extract_summary(email_body, max_lines)\n    }\n}\n```\n2. Add bulk synopsis generation for unread emails\n3. Implement caching for generated summaries\n4. Add configuration for AI provider (OpenAI/Claude/local)\n5. Support multiple languages",
        "testStrategy": "1. Test synopsis quality with various email types\n2. Verify length constraints are respected\n3. Test AI fallback to simple extraction\n4. Performance test bulk generation\n5. Test with HTML-heavy emails",
        "priority": "low",
        "dependencies": [
          "56"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-12T12:37:29.150Z"
      },
      {
        "id": "62",
        "title": "Upgrade sqlx from 0.7 to 0.8+",
        "description": "Upgrade sqlx dependency from version 0.7 to 0.8+ to address critical security vulnerabilities RUSTSEC-2024-0363 (binary protocol cast overflow) and RUSTSEC-2023-0071 (RSA timing attack via sqlx-mysql), while also resolving unmaintained transitive dependencies paste and proc-macro-error.",
        "details": "1. Update Cargo.toml dependencies:\n```toml\n[dependencies]\nsqlx = { version = \"0.8.2\", features = [\"runtime-tokio-rustls\", \"postgres\", \"mysql\", \"sqlite\", \"macros\", \"migrate\", \"chrono\", \"uuid\"] }\n```\n\n2. Migration changes required:\n   a) Query macro syntax updates:\n   ```rust\n   // Old (0.7)\n   let row = sqlx::query!(\"SELECT * FROM users WHERE id = ?\", id)\n       .fetch_one(&pool).await?;\n   \n   // New (0.8)\n   let row = sqlx::query!(\"SELECT * FROM users WHERE id = $1\", id)\n       .fetch_one(&pool).await?;\n   ```\n   \n   b) Connection pool API changes:\n   ```rust\n   // Old (0.7)\n   let pool = PgPoolOptions::new()\n       .max_connections(5)\n       .connect(&database_url).await?;\n   \n   // New (0.8)\n   let pool = PgPoolOptions::new()\n       .max_connections(5)\n       .acquire_timeout(Duration::from_secs(3))\n       .connect(&database_url).await?;\n   ```\n   \n   c) Migration runner updates:\n   ```rust\n   // Old (0.7)\n   sqlx::migrate!(\"./migrations\")\n       .run(&pool).await?;\n   \n   // New (0.8)\n   sqlx::migrate!(\"./migrations\")\n       .set_ignore_missing(true)\n       .run(&pool).await?;\n   ```\n\n3. Update all database query macros throughout the codebase:\n   - Search for `query!`, `query_as!`, `query_scalar!` macros\n   - Update parameter placeholders from `?` to `$1`, `$2`, etc. for PostgreSQL\n   - Keep `?` for MySQL/SQLite if used\n\n4. Update error handling:\n   ```rust\n   // New error types in 0.8\n   use sqlx::error::ErrorKind;\n   match err.kind() {\n       ErrorKind::UniqueViolation => // handle duplicate key\n       ErrorKind::ForeignKeyViolation => // handle FK constraint\n       _ => // other errors\n   }\n   ```\n\n5. Review and update any custom type implementations:\n   - Check `FromRow`, `Type`, `Encode`, `Decode` trait implementations\n   - Update for any API changes in 0.8\n\n6. Update migration files if needed:\n   - Review migrations/001-004 for any sqlx-specific syntax\n   - Ensure compatibility with new migration runner\n\n7. Address breaking changes in connection handling:\n   - Review connection lifecycle management\n   - Update any custom connection wrappers\n   - Check transaction handling code\n\n8. Clean build and resolve compilation errors:\n   ```bash\n   cargo clean\n   cargo build\n   cargo sqlx prepare --check\n   ```",
        "testStrategy": "1. Run full test suite to catch any query macro compilation errors:\n   ```bash\n   cargo test --all-features\n   ```\n\n2. Verify database migrations still apply correctly:\n   ```bash\n   cargo sqlx migrate run\n   cargo sqlx migrate info\n   ```\n\n3. Test connection pool behavior under load:\n   - Create stress test spawning 100+ concurrent queries\n   - Verify connection timeout handling\n   - Check pool exhaustion behavior\n\n4. Validate security fixes are applied:\n   ```bash\n   cargo audit\n   # Verify RUSTSEC-2024-0363 and RUSTSEC-2023-0071 are resolved\n   ```\n\n5. Test all database operations:\n   - Account CRUD operations\n   - Email synchronization queries\n   - Attachment metadata queries\n   - AI model configuration queries\n\n6. Performance regression testing:\n   - Compare query execution times before/after upgrade\n   - Monitor connection pool metrics\n   - Check for any memory leaks with valgrind\n\n7. Integration testing with live database:\n   - Test OAuth account creation/updates\n   - Verify email sync still works correctly\n   - Test concurrent operations\n\n8. Verify transitive dependencies are updated:\n   ```bash\n   cargo tree | grep -E \"paste|proc-macro-error\"\n   # Should show no results or updated versions\n   ```",
        "status": "deferred",
        "dependencies": [
          "1"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-02-14T10:58:28.427Z"
      },
      {
        "id": "63",
        "title": "Upgrade async-imap from 0.8 to 0.11+",
        "description": "Upgrade async-imap dependency from version 0.8 to 0.11+ to address unmaintained async-std and unsound ouroboros dependencies, while ensuring critical XOAUTH2 authentication behavior is preserved including the greeting consumption workaround.",
        "details": "1. **Update Cargo.toml dependencies**:\n```toml\n[dependencies]\nasync-imap = \"0.11.1\"\n# Remove async-std if it was a direct dependency\n# Verify tokio is used as the async runtime\n```\n\n2. **Critical XOAUTH2 authenticate() verification**:\n   - The current implementation has a workaround for greeting consumption that MUST be preserved\n   - Review the authenticate() method implementation in 0.11.1 to ensure it still:\n     a) Properly consumes server greetings before authentication\n     b) Handles the XOAUTH2 SASL mechanism correctly\n     c) Maintains compatibility with our token format from `generate_xoauth2_token()`\n\n3. **Update IMAP connection logic** in `src/dashboard/services/imap.rs`:\n```rust\n// Verify the connection pattern still works\npub async fn connect_imap(account: &mut Account, config: &Config) -> Result<ImapStream> {\n    // Check if async-imap 0.11+ still supports our connection approach\n    let mut imap = async_imap::connect(config.imap_server, tls_stream).await?;\n    \n    // CRITICAL: Verify greeting consumption workaround still functions\n    // The empty login trick may need adjustment\n    imap.login(\"\", \"\").await.map_err(|_| anyhow::anyhow!(\"Skip login\"))?;\n    \n    if account.oauth_provider == Some(\"microsoft\".to_string()) {\n        // Ensure XOAUTH2 authentication still works\n        let xoauth2_token = generate_xoauth2_token(&account.email, &access_token);\n        imap.authenticate(\"XOAUTH2\", xoauth2_token).await?;\n    }\n}\n```\n\n4. **API changes to address**:\n   - Check for any changes in the `Session` type or its methods\n   - Verify `select()`, `fetch()`, `search()`, and other IMAP commands still have the same signatures\n   - Update any error handling if error types have changed\n   - Check if the TLS stream setup needs modifications\n\n5. **Remove ouroboros workarounds** if any exist in the codebase:\n   - Search for any self-referential struct patterns that were using ouroboros\n   - Replace with safe alternatives provided by async-imap 0.11+\n\n6. **Update all MCP tools using IMAP**:\n   - Review and update any IMAP usage in MCP tool implementations\n   - Ensure all tools maintain their current functionality",
        "testStrategy": "1. **Verify XOAUTH2 authentication behavior**:\n   - Create integration test specifically for XOAUTH2 auth flow\n   - Test with real Microsoft OAuth tokens to ensure greeting consumption works\n   - Verify the authenticate() method properly handles the SASL XOAUTH2 mechanism\n   - Test error cases (invalid tokens, expired tokens)\n\n2. **Test all IMAP operations**:\n   - Login with username/password (non-OAuth accounts)\n   - OAuth XOAUTH2 authentication for Microsoft accounts\n   - Folder selection and listing\n   - Email fetching (headers and full messages)\n   - Search functionality\n   - Flag operations (mark read/unread)\n\n3. **Test all MCP tools that use IMAP**:\n   - Run each MCP tool that interacts with IMAP\n   - Verify email listing, reading, searching still work\n   - Test with both OAuth and non-OAuth accounts\n\n4. **Performance and stability testing**:\n   - Test connection pooling behavior\n   - Verify no memory leaks with long-running connections\n   - Test reconnection after network interruptions\n\n5. **Regression testing**:\n   ```bash\n   cargo test --all-features\n   cargo test --test imap_integration_tests\n   ```\n\n6. **Manual testing checklist**:\n   - Connect to Gmail with OAuth\n   - Connect to Outlook/Office365 with OAuth\n   - Connect to standard IMAP server with password\n   - Verify the greeting consumption workaround still prevents authentication failures",
        "status": "deferred",
        "dependencies": [
          "47",
          "46"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-02-14T10:58:29.978Z"
      },
      {
        "id": "64",
        "title": "Upgrade validator from 0.18 to 0.20+",
        "description": "Upgrade validator dependency from version 0.18 to 0.20+ to address security vulnerability RUSTSEC-2024-0421 (idna punycode bypass via transitive dependency) and resolve unmaintained proc-macro-error transitive dependency, while ensuring all validation attributes and derive macros continue to function correctly.",
        "details": "1. **Update Cargo.toml dependencies**:\n```toml\n[dependencies]\nvalidator = { version = \"0.20.0\", features = [\"derive\"] }\n# If using validator_derive separately, update it too:\nvalidator_derive = \"0.20.0\"\n```\n\n2. **Review breaking changes between 0.18 and 0.20**:\n   - The `#[validate]` attribute syntax has changed in some cases\n   - Custom validation functions now require different signatures\n   - Some validation attributes have been renamed or restructured\n   - The `ValidationError` type has new fields and methods\n\n3. **Common migration patterns**:\n   a) Update custom validators:\n   ```rust\n   // Old (0.18)\n   fn validate_custom(value: &str) -> Result<(), ValidationError> {\n       if value.len() < 5 {\n           return Err(ValidationError::new(\"too_short\"));\n       }\n       Ok(())\n   }\n   \n   // New (0.20+)\n   fn validate_custom(value: &str) -> Result<(), ValidationError> {\n       if value.len() < 5 {\n           let mut err = ValidationError::new(\"too_short\");\n           err.message = Some(\"Value must be at least 5 characters\".into());\n           return Err(err);\n       }\n       Ok(())\n   }\n   ```\n\n   b) Update struct validation attributes:\n   ```rust\n   // Check if any of these patterns need updating:\n   #[derive(Validate)]\n   struct User {\n       #[validate(length(min = 1, max = 100))]\n       username: String,\n       \n       #[validate(email)]\n       email: String,\n       \n       #[validate(range(min = 18, max = 150))]\n       age: u8,\n       \n       #[validate(url)]\n       website: Option<String>,\n       \n       #[validate(custom = \"validate_custom\")]\n       custom_field: String,\n   }\n   ```\n\n4. **Search and update all validation usage**:\n   ```bash\n   # Find all files using validator derives\n   rg \"#\\[derive\\(.*Validate.*\\)\\]\" --type rust\n   \n   # Find all validation attribute usage\n   rg \"#\\[validate\\(\" --type rust\n   \n   # Find custom validation functions\n   rg \"fn validate_\" --type rust\n   ```\n\n5. **Update error handling if needed**:\n   ```rust\n   // Check if error extraction has changed\n   match user.validate() {\n       Ok(_) => {},\n       Err(e) => {\n           // New version might have different error iteration\n           for (field, errors) in e.field_errors() {\n               for error in errors {\n                   println!(\"{}: {}\", field, error.message.as_ref().unwrap_or(&error.code));\n               }\n           }\n       }\n   }\n   ```\n\n6. **Address the security vulnerabilities**:\n   - RUSTSEC-2024-0421 is in the `idna` crate used transitively\n   - The proc-macro-error crate is unmaintained and used by older validator versions\n   - Version 0.20+ should have updated dependencies that resolve both issues\n\n7. **Check for any regex validation changes**:\n   ```rust\n   // If using regex validation, ensure patterns still work\n   #[validate(regex = \"PATTERN\")]\n   // or\n   #[validate(regex(path = \"REGEX_CONSTANT\"))]\n   ```",
        "testStrategy": "1. **Compile and type-check all validation code**:\n   ```bash\n   cargo check --all-features\n   cargo build --all-features\n   ```\n\n2. **Run existing validation tests**:\n   ```bash\n   cargo test --all-features -- --test-threads=1\n   # Pay special attention to any validation-related test failures\n   ```\n\n3. **Verify security vulnerabilities are resolved**:\n   ```bash\n   cargo audit\n   # Ensure RUSTSEC-2024-0421 no longer appears\n   # Verify proc-macro-error is no longer in dependency tree\n   cargo tree | grep proc-macro-error\n   cargo tree | grep idna\n   ```\n\n4. **Test each validation type used in the codebase**:\n   - Create a test file with examples of all validation patterns used\n   - Test email validation still works correctly\n   - Test length constraints (min/max)\n   - Test numeric ranges\n   - Test URL validation\n   - Test any custom validators\n   - Test nested struct validation\n\n5. **Integration testing**:\n   - Test API endpoints that accept validated input\n   - Ensure validation error responses have correct format\n   - Test that invalid data is properly rejected\n   - Verify error messages are still user-friendly\n\n6. **Performance comparison**:\n   - Run benchmarks if available to ensure no significant performance regression\n   - Test validation of large datasets if applicable\n\n7. **Manual testing of critical paths**:\n   - Test user registration/login if it uses validation\n   - Test any forms or API endpoints that rely on validation\n   - Verify client-side error display still works with new error format",
        "status": "deferred",
        "dependencies": [
          "1"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-02-14T10:58:31.522Z"
      },
      {
        "id": "65",
        "title": "Upgrade Vite from 6.x to 7.x in frontend",
        "description": "Upgrade Vite dependency from version 6.x to 7.x in the frontend to address GHSA-67mh-4wv8-2f99 (esbuild dev server request vulnerability, moderate severity), ensuring vite.config.ts compatibility with any breaking changes.",
        "details": "1. **Update package.json dependencies**:\n```json\n{\n  \"devDependencies\": {\n    \"vite\": \"^7.0.0\",\n    \"@vitejs/plugin-react\": \"^5.0.0\"  // or @sveltejs/vite-plugin-svelte if using Svelte\n  }\n}\n```\n\n2. **Review Vite 7.x breaking changes**:\n   - Check for deprecated config options in vite.config.ts\n   - Update any plugin configurations that may have changed APIs\n   - Review build.rollupOptions if custom Rollup config is used\n   - Verify server.proxy configurations still work as expected\n   - Check for any changes to CSS handling or preprocessor options\n\n3. **Common migration updates needed**:\n   ```typescript\n   // vite.config.ts\n   import { defineConfig } from 'vite'\n   \n   export default defineConfig({\n     // If using legacy options, update them:\n     // Old: build.polyfillDynamicImport (removed in v7)\n     // New: Use @vitejs/plugin-legacy if needed\n     \n     // Check server configuration\n     server: {\n       port: 3000,\n       // Verify proxy still works\n       proxy: {\n         '/api': 'http://localhost:8080'\n       }\n     },\n     \n     // Update any deprecated build options\n     build: {\n       // target: 'esnext' is now the default\n       // cssCodeSplit: true is now the default\n     }\n   })\n   ```\n\n4. **Update npm scripts if needed**:\n   - Vite 7 may have new CLI options or changed defaults\n   - Review package.json scripts for any deprecated flags\n\n5. **Clear caches and reinstall**:\n   ```bash\n   rm -rf node_modules package-lock.json\n   npm install\n   ```\n\n6. **Note**: This is a dev-only tooling upgrade that does not affect the shipped production code. The vulnerability GHSA-67mh-4wv8-2f99 is in the esbuild dev server and only affects development environments.",
        "testStrategy": "1. **Verify clean installation**:\n   ```bash\n   cd webui\n   rm -rf node_modules package-lock.json\n   npm install\n   npm list vite  # Confirm version 7.x is installed\n   ```\n\n2. **Test development server**:\n   ```bash\n   npm run dev\n   ```\n   - Verify the dev server starts without errors\n   - Check that HMR (Hot Module Replacement) works correctly\n   - Test proxy configurations to backend API endpoints\n   - Ensure no console warnings about deprecated options\n\n3. **Test production build**:\n   ```bash\n   npm run build\n   npm run preview\n   ```\n   - Verify build completes without errors\n   - Check build output size hasn't significantly changed\n   - Test the preview server to ensure built app works correctly\n\n4. **Regression testing**:\n   - Navigate through all major UI routes\n   - Test OAuth flow (Task 50 functionality)\n   - Verify all API calls work through the proxy\n   - Check that CSS and assets load correctly\n   - Test any dynamic imports or code splitting\n\n5. **Security verification**:\n   - Run `npm audit` to confirm GHSA-67mh-4wv8-2f99 is resolved\n   - Verify no new vulnerabilities were introduced\n\n6. **Plugin compatibility**:\n   - If using Svelte, verify @sveltejs/vite-plugin-svelte works with Vite 7\n   - Test any other Vite plugins for compatibility issues",
        "status": "deferred",
        "dependencies": [
          "50"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-02-14T10:58:33.104Z"
      },
      {
        "id": "66",
        "title": "Add IMAP connection status indicator to Email tab",
        "description": "Implement a compact connection status badge on the Email tab that displays IMAP connection health, particularly for OAuth accounts, with a warning icon and clickable link for failed connections that navigates to re-authorization.",
        "details": "Integrate the existing ConnectionStatusIndicator component into the EmailList view to provide real-time connection status visibility:\n\n1. **Import and integrate ConnectionStatusIndicator**:\n   ```tsx\n   // In EmailList.tsx\n   import { ConnectionStatusIndicator } from './ConnectionStatusIndicator';\n   ```\n\n2. **Add connection status next to account selector**:\n   ```tsx\n   // Inside EmailList component, near the account selector/folder dropdown\n   <div className=\"flex items-center gap-2\">\n     <AccountSelector />\n     {currentAccount && (\n       <ConnectionStatusIndicator\n         accountId={currentAccount.id}\n         compact={true}\n         onReauthorize={() => {\n           // Navigate to Accounts tab or trigger re-auth\n           navigate('/dashboard/accounts');\n           // Or directly open edit dialog with re-auth\n         }}\n       />\n     )}\n   </div>\n   ```\n\n3. **Utilize existing backend endpoint**:\n   - The component should use `GET /api/dashboard/accounts/{id}/connection-status`\n   - Poll this endpoint periodically (e.g., every 30 seconds) when the Email tab is active\n   - Stop polling when tab is inactive to save resources\n\n4. **Handle OAuth-specific failures**:\n   ```tsx\n   // In ConnectionStatusIndicator, enhance to show OAuth-specific messages\n   if (connectionStatus.error?.includes('OAuth') || connectionStatus.error?.includes('401')) {\n     return (\n       <Tooltip content=\"OAuth token expired. Click to re-authorize.\">\n         <button\n           onClick={onReauthorize}\n           className=\"flex items-center gap-1 text-amber-600 hover:text-amber-700\"\n         >\n           <ExclamationTriangleIcon className=\"h-4 w-4\" />\n           <span className=\"text-xs\">Reconnect</span>\n         </button>\n       </Tooltip>\n     );\n   }\n   ```\n\n5. **Leverage currentAccount context**:\n   - Use `currentAccount.connection_status` field for initial state\n   - Update this field when polling returns new status\n   - Ensure status updates trigger re-renders appropriately\n\n6. **Navigation and re-authorization flow**:\n   - On click, either navigate to `/dashboard/accounts` tab\n   - Or better: directly open the account edit dialog with focus on re-authorization\n   - Pass account ID in navigation state for direct dialog opening\n\n7. **Visual design considerations**:\n   - Keep indicator compact to not clutter the UI\n   - Use color coding: green (connected), amber (warning/expired), red (error)\n   - Include subtle animation for \"checking\" state\n   - Ensure accessibility with proper ARIA labels",
        "testStrategy": "1. **Visual verification**:\n   - Verify indicator appears next to account selector on Email tab\n   - Check that it displays correctly in compact mode\n   - Ensure proper spacing and alignment with existing UI elements\n\n2. **Connection status testing**:\n   - Test with a working IMAP connection - should show green/connected state\n   - Manually expire OAuth token in database and verify amber warning appears\n   - Disconnect network and verify red error state displays\n   - Test that status updates within 30 seconds of connection change\n\n3. **OAuth-specific scenarios**:\n   - Create test account with expired OAuth token\n   - Verify warning icon appears with appropriate tooltip message\n   - Click indicator and confirm navigation to Accounts tab\n   - Test that re-authorization flow can be triggered from the indicator\n\n4. **Performance testing**:\n   - Verify polling stops when navigating away from Email tab\n   - Check that polling resumes when returning to Email tab\n   - Monitor network requests to ensure no excessive API calls\n   - Test with multiple accounts to ensure correct status per account\n\n5. **Edge cases**:\n   - Test with no current account selected\n   - Verify graceful handling of API endpoint failures\n   - Test rapid account switching and status updates\n   - Verify component cleanup on unmount",
        "status": "done",
        "dependencies": [
          "49"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-02-14T12:44:56.982Z"
      },
      {
        "id": "67",
        "title": "Change folder dropdown to source folders from cache DB instead of live IMAP",
        "description": "Modify the email folder dropdown in EmailList.tsx to primarily use cached folder names from the database instead of live IMAP queries, ensuring folder visibility even when IMAP authentication fails.",
        "details": "Implement a cache-first approach for the folder dropdown to align with RustyMail's architecture where the cache is the operational source of truth:\n\n1. **Create new backend endpoint GET /api/dashboard/cached-folders**:\n   ```rust\n   #[get(\"/api/dashboard/cached-folders\")]\n   async fn get_cached_folders(\n       account_id: web::Query<AccountId>,\n       pool: web::Data<SqlitePool>,\n   ) -> Result<HttpResponse, Error> {\n       let folders = sqlx::query!(\n           r#\"\n           SELECT DISTINCT folder, COUNT(*) as email_count\n           FROM emails\n           WHERE account_id = ?\n           GROUP BY folder\n           ORDER BY folder\n           \"#,\n           account_id.0\n       )\n       .fetch_all(pool.get_ref())\n       .await?;\n       \n       let folder_list: Vec<FolderInfo> = folders\n           .into_iter()\n           .map(|row| FolderInfo {\n               name: row.folder,\n               email_count: row.email_count,\n           })\n           .collect();\n       \n       Ok(HttpResponse::Ok().json(folder_list))\n   }\n   ```\n\n2. **Add FolderInfo struct**:\n   ```rust\n   #[derive(Serialize, Deserialize)]\n   struct FolderInfo {\n       name: String,\n       email_count: i64,\n   }\n   ```\n\n3. **Register the new endpoint in main.rs**:\n   ```rust\n   .service(get_cached_folders)\n   ```\n\n4. **Update EmailList.tsx to use cached folders as primary source**:\n   - Modify the folder fetching logic to first call `/api/dashboard/cached-folders`\n   - Keep the existing `/api/dashboard/folders` call as secondary/comparison data\n   - Update the state management to handle both cached and live folder lists\n   \n   ```typescript\n   const fetchFolders = async () => {\n       try {\n           // Primary: Get cached folders\n           const cachedResponse = await fetch(`/api/dashboard/cached-folders?account_id=${accountId}`);\n           const cachedFolders = await cachedResponse.json();\n           setFolders(cachedFolders);\n           \n           // Secondary: Try to get live folders for comparison\n           try {\n               const liveResponse = await fetch(`/api/dashboard/folders?account_id=${accountId}`);\n               if (liveResponse.ok) {\n                   const liveFolders = await liveResponse.json();\n                   // Optionally merge or compare with cached folders\n                   // Could show sync status indicators\n               }\n           } catch (liveError) {\n               // Live IMAP failed, but we still have cached folders\n               console.warn('Live IMAP folder fetch failed, using cached folders only');\n           }\n       } catch (error) {\n           console.error('Failed to fetch cached folders:', error);\n       }\n   };\n   ```\n\n5. **Handle edge cases**:\n   - Empty cache scenario (new account with no synced emails yet)\n   - Folder names with special characters or hierarchy separators\n   - Performance optimization for accounts with many folders\n   - Consider adding folder metadata like last sync time\n\n6. **Optional enhancements**:\n   - Add visual indicators to show which folders are from cache vs live\n   - Show sync status for each folder\n   - Add ability to trigger folder sync from the UI",
        "testStrategy": "Verify the cache-first folder implementation with comprehensive testing:\n\n1. **Test cached folder endpoint**:\n   - Insert test emails with various folder names into the database\n   - Call GET /api/dashboard/cached-folders and verify all distinct folders are returned\n   - Verify email counts are accurate for each folder\n   - Test with special folder names (spaces, unicode, hierarchy separators)\n   - Test performance with 100+ distinct folders\n\n2. **Test frontend integration**:\n   - Mock the cached-folders endpoint to return test data\n   - Verify folder dropdown populates correctly from cached data\n   - Simulate IMAP auth failure and confirm folders still display\n   - Test that folder selection still filters emails correctly\n\n3. **Test fallback behavior**:\n   - Test with empty cache (no emails in database)\n   - Verify graceful handling when cached endpoint fails\n   - Test merge logic if implementing live/cached comparison\n\n4. **Integration testing**:\n   - Create test account with known folder structure\n   - Sync some folders using multi-folder sync (Task 53)\n   - Expire OAuth token to simulate auth failure\n   - Verify folder dropdown shows all synced folders from cache\n   - Verify INBOX is not the only folder shown\n\n5. **Performance testing**:\n   - Test query performance with 1M+ emails across 50+ folders\n   - Verify no N+1 queries or performance degradation\n   - Test concurrent access from multiple sessions",
        "status": "done",
        "dependencies": [
          "53"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-02-14T12:44:56.985Z"
      },
      {
        "id": "68",
        "title": "Add folder sync status indicators to the folder dropdown",
        "description": "Enhance the folder dropdown to display cached email counts, last sync timestamps, and visual distinction between locally cached folders and IMAP-only folders, providing users visibility into folder sync status and available local data.",
        "details": "Extend the folder dropdown implementation from task 67 to include rich metadata about each folder's sync status:\n\n1. **Update backend cached-folders endpoint to include metadata**:\n   ```rust\n   #[derive(Serialize)]\n   struct CachedFolderInfo {\n       folder_name: String,\n       email_count: i64,\n       last_sync_timestamp: Option<DateTime<Utc>>,\n       is_cached: bool,\n   }\n   \n   #[get(\"/api/dashboard/cached-folders\")]\n   async fn get_cached_folders_with_metadata(\n       account_id: web::Query<AccountId>,\n       pool: web::Data<SqlitePool>,\n   ) -> Result<HttpResponse, Error> {\n       // Query cached folders with counts\n       let cached_folders = sqlx::query!(\n           r#\"\n           SELECT \n               folder_name,\n               COUNT(*) as email_count,\n               MAX(received_date) as last_email_date\n           FROM emails\n           WHERE account_id = ?\n           GROUP BY folder_name\n           ORDER BY folder_name\n           \"#,\n           account_id.0\n       )\n       .fetch_all(&pool)\n       .await?;\n       \n       // Get sync timestamps from a sync_status table if available\n       let sync_times = get_folder_sync_times(account_id.0, &pool).await?;\n       \n       let folder_info: Vec<CachedFolderInfo> = cached_folders\n           .into_iter()\n           .map(|f| CachedFolderInfo {\n               folder_name: f.folder_name,\n               email_count: f.email_count,\n               last_sync_timestamp: sync_times.get(&f.folder_name).cloned(),\n               is_cached: true,\n           })\n           .collect();\n       \n       Ok(HttpResponse::Ok().json(folder_info))\n   }\n   ```\n\n2. **Add IMAP-only folder detection when connected**:\n   ```rust\n   // Extend endpoint to optionally include IMAP folders\n   async fn get_all_folders_with_status(\n       account_id: i64,\n       pool: &SqlitePool,\n       imap_session: Option<&ImapSession>,\n   ) -> Result<Vec<CachedFolderInfo>, Error> {\n       let mut all_folders = get_cached_folders_from_db(account_id, pool).await?;\n       \n       if let Some(session) = imap_session {\n           // Get IMAP folder list\n           let imap_folders = session.list(None, \"*\").await?;\n           \n           // Find folders that exist in IMAP but not in cache\n           for imap_folder in imap_folders {\n               if !all_folders.iter().any(|f| f.folder_name == imap_folder.name()) {\n                   all_folders.push(CachedFolderInfo {\n                       folder_name: imap_folder.name().to_string(),\n                       email_count: 0,\n                       last_sync_timestamp: None,\n                       is_cached: false,\n                   });\n               }\n           }\n       }\n       \n       all_folders\n   }\n   ```\n\n3. **Update frontend FolderDropdown component**:\n   ```tsx\n   interface FolderInfo {\n     folder_name: string;\n     email_count: number;\n     last_sync_timestamp?: string;\n     is_cached: boolean;\n   }\n   \n   // In FolderDropdown component\n   const formatFolderLabel = (folder: FolderInfo): string => {\n     let label = folder.folder_name;\n     \n     if (folder.is_cached && folder.email_count > 0) {\n       label += ` (${folder.email_count.toLocaleString()})`;\n       \n       if (folder.last_sync_timestamp) {\n         const syncTime = formatRelativeTime(folder.last_sync_timestamp);\n         label += `  ${syncTime}`;\n       }\n     }\n     \n     return label;\n   };\n   \n   const formatRelativeTime = (timestamp: string): string => {\n     const date = new Date(timestamp);\n     const now = new Date();\n     const diffMs = now.getTime() - date.getTime();\n     const diffMins = Math.floor(diffMs / 60000);\n     \n     if (diffMins < 60) return `synced ${diffMins}m ago`;\n     if (diffMins < 1440) return `synced ${Math.floor(diffMins / 60)}h ago`;\n     return `synced ${Math.floor(diffMins / 1440)}d ago`;\n   };\n   ```\n\n4. **Add visual styling for folder states**:\n   ```tsx\n   <SelectItem \n     value={folder.folder_name}\n     className={cn(\n       \"flex items-center justify-between\",\n       !folder.is_cached && \"opacity-60 italic\"\n     )}\n   >\n     <span className=\"flex items-center gap-2\">\n       {folder.folder_name}\n       {folder.is_cached && folder.email_count > 0 && (\n         <span className=\"text-xs text-muted-foreground\">\n           ({folder.email_count.toLocaleString()})\n         </span>\n       )}\n     </span>\n     {folder.is_cached && folder.last_sync_timestamp && (\n       <span className=\"text-xs text-muted-foreground ml-2\">\n         {formatRelativeTime(folder.last_sync_timestamp)}\n       </span>\n     )}\n     {!folder.is_cached && (\n       <span className=\"text-xs text-muted-foreground ml-2\">\n         (not synced)\n       </span>\n     )}\n   </SelectItem>\n   ```\n\n5. **Add sync status tracking table** (if not already exists):\n   ```sql\n   CREATE TABLE IF NOT EXISTS folder_sync_status (\n       account_id INTEGER NOT NULL,\n       folder_name TEXT NOT NULL,\n       last_sync_timestamp DATETIME NOT NULL,\n       sync_status TEXT DEFAULT 'success',\n       PRIMARY KEY (account_id, folder_name),\n       FOREIGN KEY (account_id) REFERENCES accounts(id)\n   );\n   ```\n\n6. **Update sync process to record timestamps**:\n   ```rust\n   // In sync_folder function\n   sqlx::query!(\n       \"INSERT OR REPLACE INTO folder_sync_status \n        (account_id, folder_name, last_sync_timestamp, sync_status) \n        VALUES (?, ?, ?, ?)\",\n       account_id,\n       folder_name,\n       Utc::now(),\n       \"success\"\n   )\n   .execute(&pool)\n   .await?;\n   ```",
        "testStrategy": "Verify the enhanced folder dropdown displays accurate sync status information:\n\n1. **Test cached folder metadata display**:\n   - Insert test emails into multiple folders with varying counts\n   - Verify dropdown shows correct email counts (e.g., \"Inbox (2,145)\")\n   - Test number formatting for large counts (1000+ emails)\n   - Verify empty folders show as folder name only without count\n\n2. **Test sync timestamp display**:\n   - Manually insert sync timestamps for various folders\n   - Verify relative time formatting: \"synced 5m ago\", \"synced 2h ago\", \"synced 3d ago\"\n   - Test edge cases: very recent syncs (<1 min), very old syncs (>30 days)\n   - Verify folders without sync history don't show timestamp\n\n3. **Test IMAP-only folder detection**:\n   - With IMAP connected, verify non-cached folders appear with \"(not synced)\" indicator\n   - Test visual distinction (opacity/italic styling) for unsynced folders\n   - Verify cached folders show as normal even when IMAP is connected\n   - Test with IMAP disconnected - only cached folders should appear\n\n4. **Test integration with ConnectionStatusIndicator**:\n   - When IMAP fails, verify dropdown still shows cached folders with metadata\n   - When IMAP reconnects, verify IMAP-only folders appear in dropdown\n   - Test switching between accounts maintains correct folder metadata\n\n5. **Performance testing**:\n   - Test with 50+ folders to ensure dropdown remains responsive\n   - Verify metadata queries don't slow down folder switching\n   - Test with folders containing 10,000+ emails\n\n6. **Visual regression testing**:\n   - Verify dropdown width accommodates longer labels with metadata\n   - Test text truncation for very long folder names with counts\n   - Verify proper alignment of counts and timestamps\n   - Test dark mode styling for all folder states",
        "status": "done",
        "dependencies": [
          "67",
          "53",
          "66"
        ],
        "priority": "medium",
        "subtasks": [],
        "updatedAt": "2026-02-14T12:46:08.593Z"
      },
      {
        "id": "69",
        "title": "Add cached_count to CachedFolder struct and API response",
        "description": "Enhance the CachedFolder struct to include a count of cached emails and update the API to return this information, enabling the UI to show cached vs total email counts",
        "details": "Backend (cache.rs):\n1. Add `pub cached_count: i32` field to the `CachedFolder` struct\n2. Modify `get_all_cached_folders_for_account()` function to include a subquery in the SQL:\n```rust\nlet query = r#\"\n    SELECT f.*, \n           (SELECT COUNT(*) FROM emails e WHERE e.folder_id = f.id) AS cached_count\n    FROM folders f\n    WHERE f.account_id = $1\n\"#;\n```\n3. Update the row mapping to populate the new field:\n```rust\ncached_count: row.get(\"cached_count\"),\n```\n\nFrontend (EmailList.tsx):\n1. Add `cached_count: number` to the `CachedFolderDetail` TypeScript interface\n2. Update the folder dropdown display logic:\n```typescript\n// Change from:\n({detail.total_messages.toLocaleString()})\n// To:\n({detail.cached_count.toLocaleString()} / {detail.total_messages.toLocaleString()})\n```",
        "testStrategy": "1. Run `cargo build && cargo test` to ensure Rust compilation and tests pass\n2. Make API call to `/api/dashboard/cached-folders` and verify response includes `cached_count` field for each folder\n3. Verify UI folder dropdown displays format like 'Inbox (350 / 1,600)' showing cached vs total counts\n4. Test with folders containing 0 cached emails to ensure proper handling",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-15T01:48:50.569Z"
      },
      {
        "id": "70",
        "title": "Create sync progress migration (010_add_sync_progress.sql)",
        "description": "Add database columns to track email sync progress in real-time, storing the number of emails synced and total emails to sync",
        "details": "Create migration file `migrations/010_add_sync_progress.sql`:\n```sql\n-- Add columns to track sync progress\nALTER TABLE sync_state ADD COLUMN emails_synced INTEGER DEFAULT 0;\nALTER TABLE sync_state ADD COLUMN emails_total INTEGER DEFAULT 0;\n\n-- Add index for performance when querying sync state\nCREATE INDEX idx_sync_state_account_folder ON sync_state(account_id, folder_id);\n```\n\nEnsure migration runner is configured to apply this migration on startup. The columns should default to 0 to maintain backward compatibility with existing records.",
        "testStrategy": "1. Apply migration to test database and verify columns are added successfully\n2. Check that existing sync_state records have emails_synced=0 and emails_total=0\n3. Verify migration rollback works correctly if needed\n4. Test that the application starts successfully with the new schema\n5. Verify index creation improves query performance for sync state lookups",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-15T01:50:31.437Z"
      },
      {
        "id": "71",
        "title": "Update sync binary to write progress during sync",
        "description": "Modify the sync binary to update sync progress in the database as it processes emails, providing real-time visibility into sync operations",
        "details": "In `src/bin/sync.rs`, modify the `sync_folder()` function:\n\n1. At the start of sync:\n```rust\n// After fetching UIDs from IMAP\nlet total_emails = uids.len() as i32;\nupdate_sync_progress(&pool, account_id, folder_id, \"Syncing\", 0, total_emails).await?;\n```\n\n2. After each batch is processed:\n```rust\n// Inside the batch processing loop\nlet emails_processed = batch_index * batch_size + current_batch.len();\nupdate_sync_progress(&pool, account_id, folder_id, \"Syncing\", emails_processed as i32, total_emails).await?;\n```\n\n3. At the end of sync (in `update_sync_state()`):\n```rust\n// Reset progress counters when sync completes\nsqlx::query!(\n    \"UPDATE sync_state SET sync_status = 'Idle', emails_synced = 0, emails_total = 0, last_sync = $3 WHERE account_id = $1 AND folder_id = $2\",\n    account_id, folder_id, Utc::now()\n).execute(pool).await?;\n```\n\n4. Add helper function:\n```rust\nasync fn update_sync_progress(\n    pool: &PgPool,\n    account_id: i32,\n    folder_id: i32,\n    status: &str,\n    synced: i32,\n    total: i32\n) -> Result<()> {\n    sqlx::query!(\n        \"UPDATE sync_state SET sync_status = $1, emails_synced = $2, emails_total = $3 WHERE account_id = $4 AND folder_id = $5\",\n        status, synced, total, account_id, folder_id\n    ).execute(pool).await?;\n    Ok(())\n}\n```",
        "testStrategy": "1. Run sync binary and monitor database updates during sync operation\n2. Verify sync_state table shows incremental progress updates\n3. Test with large folders (1000+ emails) to ensure progress updates are frequent enough\n4. Verify progress resets to 0/0 after sync completes\n5. Test error scenarios to ensure partial progress is recorded\n6. Monitor performance impact of frequent database updates",
        "priority": "high",
        "dependencies": [
          "70"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-15T01:53:47.322Z"
      },
      {
        "id": "72",
        "title": "Update SyncState struct and sync status API to include progress fields",
        "description": "Extend the SyncState data structure and API endpoints to expose sync progress information to the frontend",
        "details": "1. Update `SyncState` struct in `src/dashboard/services/cache.rs`:\n```rust\n#[derive(Serialize, Deserialize, Debug)]\npub struct SyncState {\n    pub account_id: i32,\n    pub folder_id: i32,\n    pub sync_status: String,\n    pub last_sync: Option<DateTime<Utc>>,\n    pub last_uid_synced: i64,\n    pub emails_synced: i32,  // New field\n    pub emails_total: i32,    // New field\n}\n```\n\n2. Update `get_sync_state()` query:\n```rust\nlet sync_state = sqlx::query_as!(\n    SyncState,\n    r#\"SELECT account_id, folder_id, sync_status, last_sync, last_uid_synced, \n              emails_synced, emails_total \n       FROM sync_state \n       WHERE account_id = $1 AND folder_id = $2\"#,\n    account_id, folder_id\n).fetch_optional(pool).await?;\n```\n\n3. Update API response in `src/dashboard/api/handlers.rs` `get_sync_status()`:\n```rust\nlet response = json!({\n    \"status\": sync_state.sync_status,\n    \"last_sync\": sync_state.last_sync,\n    \"emails_synced\": sync_state.emails_synced,\n    \"emails_total\": sync_state.emails_total,\n    \"is_syncing\": sync_state.sync_status == \"Syncing\"\n});\n```",
        "testStrategy": "1. Compile and run tests: `cargo build && cargo test`\n2. Call `/api/sync/status` endpoint and verify response includes emails_synced and emails_total fields\n3. Test during active sync to ensure progress values are returned correctly\n4. Test when sync is idle to verify fields return 0\n5. Verify backward compatibility if sync_state records don't have these fields yet",
        "priority": "high",
        "dependencies": [
          "70"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-15T01:55:56.676Z"
      },
      {
        "id": "73",
        "title": "Add force re-sync CLI flag to sync binary",
        "description": "Implement a --force flag in the sync binary that allows users to re-download all emails by resetting the sync checkpoint",
        "details": "1. Update CLI struct in `src/bin/sync.rs`:\n```rust\n#[derive(Parser, Debug)]\n#[command(author, version, about, long_about = None)]\nstruct Cli {\n    /// Account ID to sync\n    #[arg(short, long)]\n    account_id: i32,\n    \n    /// Folder ID to sync (optional, syncs all if not specified)\n    #[arg(short, long)]\n    folder_id: Option<i32>,\n    \n    /// Force full re-sync by resetting sync checkpoint\n    #[arg(long, help = \"Force re-download all emails by resetting sync checkpoint\")]\n    force: bool,\n}\n```\n\n2. Pass force flag through the sync chain:\n```rust\n// In main()\nif let Some(folder_id) = cli.folder_id {\n    sync_folder(&pool, cli.account_id, folder_id, cli.force).await?;\n} else {\n    sync_all_folders(&pool, cli.account_id, cli.force).await?;\n}\n\n// Update function signatures\nasync fn sync_folder(pool: &PgPool, account_id: i32, folder_id: i32, force: bool) -> Result<()> {\n    if force {\n        // Reset last_uid_synced to 0 before starting sync\n        sqlx::query!(\n            \"UPDATE sync_state SET last_uid_synced = 0 WHERE account_id = $1 AND folder_id = $2\",\n            account_id, folder_id\n        ).execute(pool).await?;\n    }\n    // Continue with normal sync logic\n}\n```\n\n3. Update IMAP search criteria when force=true:\n```rust\nlet search_criteria = if force || last_uid_synced == 0 {\n    \"ALL\".to_string()\n} else {\n    format!(\"UID {}:*\", last_uid_synced + 1)\n};\n```",
        "testStrategy": "1. Build sync binary: `cargo build --bin sync`\n2. Test normal sync: `./target/debug/sync --account-id 1 --folder-id 1`\n3. Test force sync: `./target/debug/sync --account-id 1 --folder-id 1 --force`\n4. Verify force sync resets last_uid_synced to 0 in database\n5. Verify force sync re-downloads all emails even if already cached\n6. Test --help flag shows force option documentation",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-15T01:52:10.478Z"
      },
      {
        "id": "74",
        "title": "Add force parameter to sync trigger API endpoint",
        "description": "Extend the sync trigger API endpoint to accept a force parameter that passes the --force flag to the sync binary",
        "details": "In `src/dashboard/api/handlers.rs`, modify `trigger_email_sync()`:\n\n```rust\n#[derive(Deserialize)]\nstruct SyncParams {\n    account_id: i32,\n    folder_id: Option<i32>,\n    force: Option<bool>,  // New optional parameter\n}\n\npub async fn trigger_email_sync(\n    Query(params): Query<SyncParams>,\n    State(state): State<AppState>,\n) -> Result<impl IntoResponse, AppError> {\n    // Build command arguments\n    let mut args = vec![\n        \"--account-id\".to_string(),\n        params.account_id.to_string(),\n    ];\n    \n    if let Some(folder_id) = params.folder_id {\n        args.push(\"--folder-id\".to_string());\n        args.push(folder_id.to_string());\n    }\n    \n    // Add force flag if requested\n    if params.force.unwrap_or(false) {\n        args.push(\"--force\".to_string());\n    }\n    \n    // Spawn sync process\n    let mut cmd = Command::new(\"./target/release/sync\");\n    cmd.args(&args);\n    \n    match cmd.spawn() {\n        Ok(_) => Ok(Json(json!({\n            \"status\": \"sync_started\",\n            \"account_id\": params.account_id,\n            \"folder_id\": params.folder_id,\n            \"force\": params.force.unwrap_or(false)\n        }))),\n        Err(e) => Err(AppError::InternalServerError(format!(\"Failed to start sync: {}\", e)))\n    }\n}\n```\n\nUpdate route registration if needed to ensure query parameters are parsed correctly.",
        "testStrategy": "1. Test normal sync trigger: `POST /api/sync/trigger?account_id=1&folder_id=1`\n2. Test force sync trigger: `POST /api/sync/trigger?account_id=1&folder_id=1&force=true`\n3. Verify sync binary is spawned with correct arguments using process monitoring\n4. Test with force=false explicitly to ensure it doesn't add the flag\n5. Test error handling when sync binary is not found or fails to start\n6. Verify API response includes force parameter status",
        "priority": "medium",
        "dependencies": [
          "73"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-15T01:57:24.901Z"
      },
      {
        "id": "75",
        "title": "Create useSyncStatus hook for frontend",
        "description": "Implement a React hook that polls the sync status API and provides real-time sync progress updates to UI components",
        "details": "Create `frontend/src/hooks/useSyncStatus.ts`:\n\n```typescript\nimport { useState, useEffect, useCallback } from 'react';\nimport { useQuery } from '@tanstack/react-query';\n\ninterface SyncStatus {\n  status: string;\n  last_sync: string | null;\n  emails_synced: number;\n  emails_total: number;\n  is_syncing: boolean;\n}\n\ninterface UseSyncStatusReturn {\n  isSyncing: boolean;\n  emailsSynced: number;\n  emailsTotal: number;\n  lastSync: Date | null;\n  error: Error | null;\n  refetch: () => void;\n}\n\nexport function useSyncStatus(accountId: number, folderId?: number): UseSyncStatusReturn {\n  const [pollInterval, setPollInterval] = useState<number | false>(false);\n  \n  const { data, error, refetch } = useQuery<SyncStatus>({\n    queryKey: ['syncStatus', accountId, folderId],\n    queryFn: async () => {\n      const params = new URLSearchParams({ account_id: accountId.toString() });\n      if (folderId) params.append('folder_id', folderId.toString());\n      \n      const response = await fetch(`/api/sync/status?${params}`);\n      if (!response.ok) throw new Error('Failed to fetch sync status');\n      return response.json();\n    },\n    refetchInterval: pollInterval,\n    refetchIntervalInBackground: true,\n  });\n  \n  // Enable polling when syncing, disable when idle\n  useEffect(() => {\n    if (data?.is_syncing) {\n      setPollInterval(2000); // Poll every 2 seconds during sync\n    } else {\n      setPollInterval(false); // Stop polling when idle\n    }\n  }, [data?.is_syncing]);\n  \n  return {\n    isSyncing: data?.is_syncing ?? false,\n    emailsSynced: data?.emails_synced ?? 0,\n    emailsTotal: data?.emails_total ?? 0,\n    lastSync: data?.last_sync ? new Date(data.last_sync) : null,\n    error: error as Error | null,\n    refetch,\n  };\n}\n```\n\nExport from hooks index file for easy importing.",
        "testStrategy": "1. Create test component that uses the hook and verify it renders sync status\n2. Mock API responses to test different sync states (idle, syncing, error)\n3. Verify polling starts when is_syncing=true and stops when is_syncing=false\n4. Test error handling when API calls fail\n5. Verify memory leaks don't occur when component unmounts during active polling\n6. Test with different account/folder ID combinations",
        "priority": "medium",
        "dependencies": [
          "72"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-15T01:58:36.250Z"
      },
      {
        "id": "76",
        "title": "Create SyncStatusPanel component",
        "description": "Build a comprehensive UI component that displays sync progress, status, and provides sync control buttons including force re-sync functionality",
        "details": "Create `frontend/src/components/SyncStatusPanel.tsx`:\n\n```typescript\nimport React, { useState } from 'react';\nimport { Button, Progress, Alert, Tooltip } from '@/components/ui';\nimport { RefreshCw, AlertCircle, CheckCircle } from 'lucide-react';\nimport { useSyncStatus } from '@/hooks/useSyncStatus';\nimport { formatDistanceToNow } from 'date-fns';\n\ninterface SyncStatusPanelProps {\n  accountId: number;\n  folderId?: number;\n  onSyncComplete?: () => void;\n}\n\nexport function SyncStatusPanel({ accountId, folderId, onSyncComplete }: SyncStatusPanelProps) {\n  const { isSyncing, emailsSynced, emailsTotal, lastSync, error } = useSyncStatus(accountId, folderId);\n  const [isTriggering, setIsTriggering] = useState(false);\n  \n  const triggerSync = async (force: boolean = false) => {\n    if (force && !confirm('This will re-download all emails. Continue?')) return;\n    \n    setIsTriggering(true);\n    try {\n      const params = new URLSearchParams({ account_id: accountId.toString() });\n      if (folderId) params.append('folder_id', folderId.toString());\n      if (force) params.append('force', 'true');\n      \n      const response = await fetch(`/api/sync/trigger?${params}`, { method: 'POST' });\n      if (!response.ok) throw new Error('Failed to trigger sync');\n    } catch (err) {\n      console.error('Sync trigger failed:', err);\n    } finally {\n      setIsTriggering(false);\n    }\n  };\n  \n  const progressPercent = emailsTotal > 0 ? (emailsSynced / emailsTotal) * 100 : 0;\n  \n  return (\n    <div className=\"bg-white rounded-lg shadow p-4 space-y-3\">\n      {/* Sync Status */}\n      <div className=\"flex items-center justify-between\">\n        <div className=\"flex items-center gap-2\">\n          {isSyncing ? (\n            <>\n              <RefreshCw className=\"h-4 w-4 animate-spin text-blue-500\" />\n              <span className=\"text-sm font-medium\">Syncing emails...</span>\n            </>\n          ) : (\n            <>\n              <CheckCircle className=\"h-4 w-4 text-green-500\" />\n              <span className=\"text-sm text-gray-600\">\n                {lastSync ? `Last synced ${formatDistanceToNow(lastSync)} ago` : 'Never synced'}\n              </span>\n            </>\n          )}\n        </div>\n        \n        {/* Action Buttons */}\n        <div className=\"flex gap-2\">\n          <Button\n            size=\"sm\"\n            variant=\"outline\"\n            onClick={() => triggerSync(false)}\n            disabled={isSyncing || isTriggering}\n          >\n            Sync\n          </Button>\n          \n          <Tooltip content=\"Re-download all emails\">\n            <Button\n              size=\"sm\"\n              variant=\"outline\"\n              onClick={() => triggerSync(true)}\n              disabled={isSyncing || isTriggering}\n              className=\"text-orange-600 hover:text-orange-700\"\n            >\n              Force Re-sync\n            </Button>\n          </Tooltip>\n        </div>\n      </div>\n      \n      {/* Progress Bar */}\n      {isSyncing && emailsTotal > 0 && (\n        <div className=\"space-y-1\">\n          <div className=\"flex justify-between text-xs text-gray-600\">\n            <span>Progress: {emailsSynced.toLocaleString()} / {emailsTotal.toLocaleString()}</span>\n            <span>{progressPercent.toFixed(0)}%</span>\n          </div>\n          <Progress value={progressPercent} className=\"h-2\" />\n        </div>\n      )}\n      \n      {/* Error Alert */}\n      {error && (\n        <Alert variant=\"destructive\" className=\"text-sm\">\n          <AlertCircle className=\"h-4 w-4\" />\n          <span>Sync error: {error.message}</span>\n        </Alert>\n      )}\n    </div>\n  );\n}\n```",
        "testStrategy": "1. Test component renders correctly with different sync states\n2. Verify progress bar shows correct percentage during sync\n3. Test sync button triggers API call with correct parameters\n4. Test force re-sync shows confirmation dialog and sends force=true\n5. Verify buttons are disabled during sync operations\n6. Test error display when sync status API fails\n7. Test last sync time formatting with various dates\n8. Verify component updates in real-time during active sync",
        "priority": "low",
        "dependencies": [
          "75",
          "74"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-15T01:59:46.804Z"
      },
      {
        "id": "77",
        "title": "Integrate SyncStatusPanel into EmailList and update folder dropdown",
        "description": "Integrate the new SyncStatusPanel component into the EmailList view and update the folder dropdown to display cached vs total email counts",
        "details": "Update `frontend/src/components/EmailList.tsx`:\n\n```typescript\n// Add imports\nimport { SyncStatusPanel } from './SyncStatusPanel';\n\n// Remove existing sync-related state and handlers\n// Remove: const [isSyncing, setIsSyncing] = useState(false);\n// Remove: handleSync function\n\n// In the component JSX, add SyncStatusPanel after the header\nexport function EmailList({ accountId }: EmailListProps) {\n  // ... existing code ...\n  \n  return (\n    <div className=\"flex flex-col h-full\">\n      {/* Existing header */}\n      <div className=\"border-b px-4 py-3\">\n        {/* ... existing header content ... */}\n      </div>\n      \n      {/* Add SyncStatusPanel */}\n      <SyncStatusPanel \n        accountId={accountId} \n        folderId={selectedFolder?.id}\n        onSyncComplete={() => {\n          // Refetch folders and emails after sync\n          refetchFolders();\n          refetchEmails();\n        }}\n      />\n      \n      {/* Update folder dropdown display */}\n      <Select value={selectedFolder?.id} onValueChange={handleFolderChange}>\n        <SelectTrigger>\n          <SelectValue>\n            {selectedFolder && folderDetails ? (\n              <span>\n                {selectedFolder.name} \n                <span className=\"text-gray-500 ml-1\">\n                  ({folderDetails.cached_count.toLocaleString()} / {folderDetails.total_messages.toLocaleString()})\n                </span>\n              </span>\n            ) : (\n              'Select folder'\n            )}\n          </SelectValue>\n        </SelectTrigger>\n        <SelectContent>\n          {folders?.map((folder) => {\n            const detail = folderDetails?.find(d => d.folder_id === folder.id);\n            return (\n              <SelectItem key={folder.id} value={folder.id}>\n                {folder.name}\n                {detail && (\n                  <span className=\"text-gray-500 ml-1\">\n                    ({detail.cached_count.toLocaleString()} / {detail.total_messages.toLocaleString()})\n                  </span>\n                )}\n              </SelectItem>\n            );\n          })}\n        </SelectContent>\n      </Select>\n      \n      {/* Rest of the component */}\n    </div>\n  );\n}\n```\n\nRemove the inline sync button and related logic since it's now handled by SyncStatusPanel.",
        "testStrategy": "1. Verify SyncStatusPanel renders in the EmailList header area\n2. Test folder dropdown shows format 'Inbox (350 / 1,600)' for each folder\n3. Verify sync operations triggered from panel update the email list\n4. Test that removing old sync button doesn't break any functionality\n5. Verify folder counts update after sync completes\n6. Test responsive layout with SyncStatusPanel at different screen sizes\n7. Ensure no duplicate sync triggers or race conditions\n8. Test that folder selection still works correctly with new display format",
        "priority": "low",
        "dependencies": [
          "69",
          "76"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-15T02:01:24.162Z"
      },
      {
        "id": "78",
        "title": "Fix MailboxInfo struct and From<AsyncImapMailbox> conversion",
        "description": "Add uid_validity and uid_next fields to MailboxInfo struct in src/imap/types.rs and fix the broken From<AsyncImapMailbox> conversion to properly extract exists, recent, unseen, uid_validity, uid_next from the async-imap Mailbox struct instead of zeroing them out.",
        "details": "1. **Update MailboxInfo struct** in `src/imap/types.rs`:\n```rust\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct MailboxInfo {\n    pub name: String,\n    pub delimiter: Option<String>,\n    pub flags: Vec<String>,\n    pub exists: u32,\n    pub recent: u32,\n    pub unseen: Option<u32>,\n    pub uid_validity: Option<u32>,  // New field\n    pub uid_next: Option<u32>,       // New field\n}\n```\n\n2. **Fix From<AsyncImapMailbox> implementation**:\n```rust\nimpl From<async_imap::types::Mailbox> for MailboxInfo {\n    fn from(mailbox: async_imap::types::Mailbox) -> Self {\n        Self {\n            name: mailbox.name().to_string(),\n            delimiter: mailbox.delimiter().map(|d| d.to_string()),\n            flags: mailbox.flags().iter().map(|f| f.to_string()).collect(),\n            exists: mailbox.exists,\n            recent: mailbox.recent,\n            unseen: mailbox.unseen,\n            uid_validity: mailbox.uid_validity,\n            uid_next: mailbox.uid_next,\n        }\n    }\n}\n```\n\n3. **Update From<AsyncImapName> implementation** to include new fields as None:\n```rust\nimpl From<async_imap::types::Name> for MailboxInfo {\n    fn from(name: async_imap::types::Name) -> Self {\n        Self {\n            name: name.name().to_string(),\n            delimiter: name.delimiter().map(|d| d.to_string()),\n            flags: name.attributes().iter().map(|a| format!(\"{:?}\", a)).collect(),\n            exists: 0,\n            recent: 0,\n            unseen: None,\n            uid_validity: None,  // New field\n            uid_next: None,      // New field\n        }\n    }\n}\n```\n\n4. **Review async-imap version compatibility**:\n   - Check that the async-imap version in use (0.8 or planned 0.11+) exposes uid_validity and uid_next fields on the Mailbox struct\n   - If fields are not available in current version, consider adding TODO comments for when upgrade happens\n\n5. **Update any code that constructs MailboxInfo manually** to include the new fields\n\n6. **Consider database schema implications**:\n   - If MailboxInfo is stored in database, may need migration to add columns\n   - Update any SQL queries that insert/select MailboxInfo data",
        "testStrategy": "1. **Compile and verify no build errors**: `cargo build`\n\n2. **Unit test the conversions**:\n```rust\n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    fn test_mailbox_conversion_extracts_all_fields() {\n        // Create mock AsyncImapMailbox with known values\n        // Convert to MailboxInfo\n        // Assert all fields including uid_validity and uid_next are properly extracted\n    }\n    \n    #[test]\n    fn test_name_conversion_sets_optional_fields_none() {\n        // Create mock AsyncImapName\n        // Convert to MailboxInfo\n        // Assert uid_validity and uid_next are None\n    }\n}\n```\n\n3. **Integration test with real IMAP connection**:\n   - Connect to IMAP server and SELECT a mailbox\n   - Verify returned MailboxInfo contains valid uid_validity and uid_next values\n   - Log the values to confirm they're not zero\n\n4. **Test serialization/deserialization**:\n   - Serialize MailboxInfo to JSON and verify new fields are included\n   - Deserialize from JSON and verify fields are properly restored\n\n5. **Regression test existing functionality**:\n   - Ensure folder listing still works correctly\n   - Verify email sync operations continue to function\n   - Check that any code depending on MailboxInfo still compiles and runs",
        "status": "done",
        "dependencies": [
          "63"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-02-16T08:01:32.512Z"
      },
      {
        "id": "79",
        "title": "Change select_folder to return MailboxInfo",
        "description": "Update AsyncImapOps trait signature in src/imap/session.rs from 'Result<(), ImapError>' to 'Result<MailboxInfo, ImapError>'. Update AsyncImapSessionWrapper::select_folder impl to create MailboxInfo from the async-imap Mailbox response, setting the name field to the folder name.",
        "details": "Modify the IMAP folder selection to return mailbox information instead of discarding it:\n\n1. **Update AsyncImapOps trait in `src/imap/session.rs`**:\n```rust\n#[async_trait]\npub trait AsyncImapOps: Send + Sync {\n    // Change from:\n    // async fn select_folder(&mut self, folder: &str) -> Result<(), ImapError>;\n    // To:\n    async fn select_folder(&mut self, folder: &str) -> Result<MailboxInfo, ImapError>;\n    \n    // Other methods remain unchanged...\n}\n```\n\n2. **Update AsyncImapSessionWrapper implementation**:\n```rust\n#[async_trait]\nimpl AsyncImapOps for AsyncImapSessionWrapper {\n    async fn select_folder(&mut self, folder: &str) -> Result<MailboxInfo, ImapError> {\n        let mailbox = self.session\n            .select(folder)\n            .await\n            .map_err(|e| ImapError::SelectError(e.to_string()))?;\n        \n        // Convert async-imap Mailbox to MailboxInfo\n        let mut mailbox_info = MailboxInfo::from(mailbox);\n        // Ensure the name field is set to the folder name we selected\n        mailbox_info.name = folder.to_string();\n        \n        Ok(mailbox_info)\n    }\n}\n```\n\n3. **Update ImapClient wrapper in `src/imap/client.rs`**:\n```rust\nimpl ImapClient {\n    pub async fn select_folder(&mut self, folder: &str) -> Result<MailboxInfo, ImapError> {\n        // Change from returning () to returning MailboxInfo\n        self.session.select_folder(folder).await\n    }\n}\n```\n\n4. **No changes needed for existing call sites**:\n   - All ~30 existing call sites currently use either `let _ = client.select_folder(folder).await?;` or just `client.select_folder(folder).await?;`\n   - These will continue to work, simply discarding the new return value\n   - The `?` operator will still propagate errors as before\n   - Examples of existing usage that require no changes:\n     ```rust\n     // In sync operations:\n     let _ = imap_client.select_folder(&folder_name).await?;\n     \n     // In email operations:\n     imap_client.select_folder(&folder).await?;\n     ```\n\n5. **Benefits of this change**:\n   - Future code can access mailbox metadata (exists, recent, unseen, uid_validity, uid_next) when selecting folders\n   - No breaking changes to existing code\n   - Sets foundation for more intelligent sync operations that can use mailbox metadata",
        "testStrategy": "Verify the select_folder changes work correctly without breaking existing functionality:\n\n1. **Compile and verify no build errors**:\n   ```bash\n   cargo build\n   cargo check\n   ```\n\n2. **Run existing tests to ensure no regressions**:\n   ```bash\n   cargo test\n   ```\n\n3. **Create a unit test for the new return value**:\n   ```rust\n   #[tokio::test]\n   async fn test_select_folder_returns_mailbox_info() {\n       // Setup mock IMAP session\n       let mut client = create_test_imap_client().await;\n       \n       // Select INBOX\n       let mailbox_info = client.select_folder(\"INBOX\").await.unwrap();\n       \n       // Verify MailboxInfo is populated\n       assert_eq!(mailbox_info.name, \"INBOX\");\n       assert!(mailbox_info.exists > 0);\n       assert!(mailbox_info.uid_validity.is_some());\n       assert!(mailbox_info.uid_next.is_some());\n   }\n   ```\n\n4. **Test existing call sites still work**:\n   - Run the sync binary: `cargo run --bin sync`\n   - Verify email operations still function correctly\n   - Check that folder selection in various parts of the codebase continues to work\n\n5. **Integration test with real IMAP server**:\n   - Connect to a test IMAP account\n   - Select various folders and verify MailboxInfo is populated correctly\n   - Ensure the folder name in MailboxInfo matches the requested folder\n\n6. **Verify error handling**:\n   - Test selecting non-existent folder still returns appropriate error\n   - Ensure ImapError::SelectError is properly propagated",
        "status": "done",
        "dependencies": [
          "78"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-02-16T08:02:38.274Z"
      },
      {
        "id": "80",
        "title": "Add update_folder_metadata() to sync.rs",
        "description": "Create a new function in src/bin/sync.rs that takes the MailboxInfo returned by select_folder and writes total_messages, unseen_messages, uidvalidity, uidnext, and last_sync to the folders table. Call this function after select_folder in sync_folder().",
        "details": "Create the `update_folder_metadata()` function in `src/bin/sync.rs`:\n\n```rust\nasync fn update_folder_metadata(\n    pool: &SqlitePool,\n    folder_id: i64,\n    mailbox_info: &MailboxInfo,\n) -> Result<()> {\n    let now = Utc::now();\n    \n    sqlx::query!(\n        r#\"\n        UPDATE folders \n        SET total_messages = ?,\n            unseen_messages = ?,\n            uidvalidity = ?,\n            uidnext = ?,\n            last_sync = ?\n        WHERE id = ?\n        \"#,\n        mailbox_info.exists as i64,\n        mailbox_info.unseen.unwrap_or(0) as i64,\n        mailbox_info.uid_validity.unwrap_or(0) as i64,\n        mailbox_info.uid_next.unwrap_or(0) as i64,\n        now,\n        folder_id\n    )\n    .execute(pool)\n    .await?;\n    \n    Ok(())\n}\n```\n\nThen modify the `sync_folder()` function to call this after `select_folder()`:\n\n```rust\n// In sync_folder() function, after the select_folder call:\nlet mailbox_info = session.select_folder(&folder.name).await?;\n\n// Add this line to update folder metadata\nupdate_folder_metadata(&pool, folder.id, &mailbox_info).await?;\n\n// Continue with existing sync logic...\n```\n\nKey considerations:\n- Handle optional fields from MailboxInfo (unseen, uid_validity, uid_next) with sensible defaults\n- Use the current timestamp for last_sync\n- Ensure the update happens before any errors could occur in the sync process\n- The function should be resilient to database errors but propagate them up",
        "testStrategy": "1. Verify the update_folder_metadata function compiles without errors\n2. Test with a folder that has messages - check that total_messages, unseen_messages are updated correctly in the database\n3. Test with an empty folder - verify it sets total_messages to 0\n4. Check that uidvalidity and uidnext are properly stored when present in MailboxInfo\n5. Verify last_sync timestamp is updated to current time after each sync\n6. Test error handling - simulate database write failure and ensure error propagates correctly\n7. Run a full sync and query the folders table to confirm all metadata fields are populated with non-zero values where appropriate\n8. Test that subsequent syncs update the metadata correctly, not just the first sync",
        "status": "done",
        "dependencies": [
          "70",
          "79"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-02-16T08:03:30.856Z"
      },
      {
        "id": "81",
        "title": "Fix MailboxInfo construction in all test files",
        "description": "Update all test code that constructs MailboxInfo to include the new uid_validity and uid_next fields. Files include src/imap/client_test.rs and tests/ directory. Also update the mock trait in client_test.rs if its select_folder signature differs from the trait.",
        "details": "1. **Update test constructions in src/imap/client_test.rs**:\n   - Search for all instances where MailboxInfo is constructed\n   - Add the new fields to each construction:\n   ```rust\n   MailboxInfo {\n       name: \"INBOX\".to_string(),\n       delimiter: Some(\"/\".to_string()),\n       flags: vec![],\n       exists: 10,\n       recent: 2,\n       unseen: Some(5),\n       uid_validity: Some(12345),  // Add this field\n       uid_next: Some(100),        // Add this field\n   }\n   ```\n\n2. **Update mock trait implementation if needed**:\n   - Check if the mock trait in client_test.rs has a select_folder method\n   - If it returns MailboxInfo, ensure the mock implementation includes the new fields\n   - Example mock update:\n   ```rust\n   async fn select_folder(&mut self, folder: &str) -> Result<MailboxInfo> {\n       Ok(MailboxInfo {\n           name: folder.to_string(),\n           delimiter: Some(\"/\".to_string()),\n           flags: vec![\"\\\\Answered\".to_string(), \"\\\\Flagged\".to_string()],\n           exists: 42,\n           recent: 3,\n           unseen: Some(7),\n           uid_validity: Some(98765),\n           uid_next: Some(200),\n       })\n   }\n   ```\n\n3. **Search and update test files in tests/ directory**:\n   - Use grep or IDE search: `grep -r \"MailboxInfo\" tests/`\n   - Update any test that constructs MailboxInfo objects\n   - Common test patterns to look for:\n     - Direct struct construction\n     - Builder patterns\n     - Test fixtures or helper functions\n\n4. **Update test helper functions**:\n   - Look for functions like `create_test_mailbox()` or `mock_mailbox_info()`\n   - Add appropriate test values for uid_validity and uid_next\n   - Consider using realistic values (e.g., uid_validity: Some(timestamp), uid_next: Some(last_uid + 1))\n\n5. **Fix compilation errors**:\n   - After adding the fields, run `cargo test --no-run` to catch any remaining construction sites\n   - The compiler will identify all places where MailboxInfo is constructed without the new fields",
        "testStrategy": "1. **Compile all tests without running**:\n   ```bash\n   cargo test --no-run\n   ```\n   - Verify no compilation errors related to MailboxInfo construction\n   - All struct literal constructions should include uid_validity and uid_next\n\n2. **Run unit tests in imap module**:\n   ```bash\n   cargo test --package email-assistant --lib imap::\n   ```\n   - Ensure all imap-related tests pass with the updated MailboxInfo\n\n3. **Run integration tests**:\n   ```bash\n   cargo test --test '*'\n   ```\n   - Verify all integration tests that use MailboxInfo still pass\n\n4. **Verify mock behavior**:\n   - If mock trait was updated, create a test that calls select_folder on the mock\n   - Assert that returned MailboxInfo contains non-None values for uid_validity and uid_next\n\n5. **Grep verification**:\n   ```bash\n   # Ensure no old-style MailboxInfo constructions remain\n   grep -r \"MailboxInfo {\" src/imap/client_test.rs tests/ | grep -v \"uid_validity\\|uid_next\"\n   ```\n   - This should return no results if all constructions are updated\n\n6. **Test with different scenarios**:\n   - Verify tests handle both Some and None cases for the optional fields\n   - Ensure test values are reasonable (e.g., uid_next > 0, uid_validity is a valid timestamp-like value)",
        "status": "done",
        "dependencies": [
          "78",
          "79"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-02-16T08:05:43.773Z"
      },
      {
        "id": "82",
        "title": "Build, test, and verify folder metadata functionality",
        "description": "Execute cargo build and cargo test to ensure all code compiles and tests pass, then rebuild and restart services via PM2. Verify the implementation by triggering a sync operation and confirming that the folders table contains accurate metadata including non-zero total_messages and populated uidvalidity/uidnext values, and that the frontend displays correct cached/total counts in the folder dropdown.",
        "details": "This task involves building, testing, and verifying the complete folder metadata functionality implemented in previous tasks:\n\n1. **Build and test the Rust codebase**:\n   ```bash\n   # Clean build to ensure all changes are compiled\n   cargo clean\n   cargo build --release\n   \n   # Run all tests to verify no regressions\n   cargo test\n   ```\n\n2. **Rebuild and restart services via PM2**:\n   ```bash\n   # Stop existing services\n   pm2 stop all\n   \n   # Rebuild the sync service binary\n   cargo build --release --bin sync\n   \n   # Rebuild the dashboard service\n   cargo build --release --bin dashboard\n   \n   # Restart services with PM2\n   pm2 start ecosystem.config.js\n   pm2 logs --lines 50  # Check for startup errors\n   ```\n\n3. **Trigger a sync operation**:\n   - Use the admin panel or API to trigger a full account sync\n   - Monitor sync logs to ensure folders are being selected and metadata is being updated\n   - Example API call:\n   ```bash\n   curl -X POST http://localhost:8080/api/sync/trigger?account_id=1\n   ```\n\n4. **Verify database folder metadata**:\n   ```sql\n   -- Check folders table has been populated with metadata\n   SELECT id, folder_name, total_messages, unseen_messages, \n          uidvalidity, uidnext, last_sync \n   FROM folders \n   WHERE account_id = 1;\n   \n   -- Verify non-zero message counts for folders with emails\n   SELECT folder_name, total_messages \n   FROM folders \n   WHERE total_messages > 0;\n   \n   -- Check UIDVALIDITY and UIDNEXT are populated\n   SELECT folder_name, uidvalidity, uidnext \n   FROM folders \n   WHERE uidvalidity IS NOT NULL AND uidnext IS NOT NULL;\n   ```\n\n5. **Verify frontend folder dropdown displays accurate counts**:\n   - Navigate to the email dashboard\n   - Open the folder dropdown\n   - Verify each folder shows:\n     - Correct cached email count (matching database)\n     - Total message count from IMAP metadata\n     - Format: \"Folder Name (cached/total)\"\n   - Check that recently synced folders show updated counts\n   - Verify visual distinction between cached and non-cached folders",
        "testStrategy": "1. **Build verification**:\n   - Confirm `cargo build --release` completes without errors\n   - Verify both sync and dashboard binaries are created in target/release/\n\n2. **Test suite verification**:\n   - Run `cargo test` and ensure all tests pass\n   - Pay special attention to tests related to:\n     - select_folder returning MailboxInfo\n     - update_folder_metadata function\n     - Folder metadata endpoints\n\n3. **Service restart verification**:\n   - Check PM2 status shows all services running: `pm2 status`\n   - Monitor logs for any startup errors: `pm2 logs --lines 100`\n   - Verify services are responding: `curl http://localhost:8080/health`\n\n4. **Sync operation verification**:\n   - Trigger sync and monitor logs for folder selection messages\n   - Verify log entries show \"Updating folder metadata for [folder_name]\"\n   - Check sync completes without errors\n\n5. **Database verification**:\n   - Query folders table and verify:\n     - All synced folders have non-zero total_messages (where applicable)\n     - uidvalidity is a positive integer for all folders\n     - uidnext is populated and greater than 0\n     - last_sync timestamp is recent (within last few minutes)\n   - Compare total_messages in DB with actual IMAP folder counts\n\n6. **Frontend verification**:\n   - Load email dashboard and check folder dropdown\n   - Verify format shows \"Inbox (1,234/1,500)\" style counts\n   - Select different folders and verify counts update\n   - Check that cached folders show different styling than non-cached\n   - Test with folders containing 0 emails to verify \"0/0\" display\n   - Verify number formatting for large counts (e.g., \"10.2K/15.3K\")",
        "status": "done",
        "dependencies": [
          "68",
          "79",
          "80",
          "81"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-02-16T08:08:20.805Z"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-02-16T08:08:20.806Z",
      "taskCount": 82,
      "completedCount": 77,
      "tags": [
        "master"
      ]
    }
  }
}